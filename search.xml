<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>mybatis-plus</title>
      <link href="/2024/12/17/Mybatisplus%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE/"/>
      <url>/2024/12/17/Mybatisplus%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>mybatis-plus</p><h3 id="1、mybatis-plus配置控制台打印sql-执行结果"><a href="#1、mybatis-plus配置控制台打印sql-执行结果" class="headerlink" title="1、mybatis-plus配置控制台打印sql 执行结果"></a>1、mybatis-plus配置控制台打印sql 执行结果</h3><pre><code>    mybatis-plus:        configuration:            log-impl: org.apache.ibatis.logging.stdout.StdOutImpl</code></pre><h3 id="2、mybatis-plus配置控制台打印sql-返回总数"><a href="#2、mybatis-plus配置控制台打印sql-返回总数" class="headerlink" title="2、mybatis-plus配置控制台打印sql 返回总数"></a>2、mybatis-plus配置控制台打印sql 返回总数</h3><pre><code>    logging:        level:            com.potion.sorting.testdemo.dao.mapper: debug</code></pre>]]></content>
      
      
      <categories>
          
          <category> mybatis-plus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mybatis-plus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>XXL-Job</title>
      <link href="/2024/09/11/XXL-Job/"/>
      <url>/2024/09/11/XXL-Job/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="XXL-JOB是一个轻量级分布式任务调度平台，提供可视化界面进行任务管理。"><a href="#XXL-JOB是一个轻量级分布式任务调度平台，提供可视化界面进行任务管理。" class="headerlink" title="XXL-JOB是一个轻量级分布式任务调度平台，提供可视化界面进行任务管理。"></a>XXL-JOB是一个轻量级分布式任务调度平台，提供可视化界面进行任务管理。</h2><h3 id="Xxl-job-原理"><a href="#Xxl-job-原理" class="headerlink" title="Xxl_job 原理"></a>Xxl_job 原理</h3><pre><code>Xxl_job总体分为两个部分：    调度中心：独立的一个轻量系统平台，将执行器注册到此平台上，创建实例以控制执行器中的业务执行时间和频率。     执行器：执行器就是我们自己的项目，可以通过 IP:端口 的形式注册到调度中心，我们通过在自己的项目里面写类（用@XxlJob注解标注）供给调度中心调用。</code></pre>]]></content>
      
      
      <categories>
          
          <category> XXL-Job </category>
          
      </categories>
      
      
        <tags>
            
            <tag> XXL-Job </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ELK</title>
      <link href="/2024/05/20/ELK/"/>
      <url>/2024/05/20/ELK/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="一、ELK-简介"><a href="#一、ELK-简介" class="headerlink" title="一、ELK 简介"></a>一、ELK 简介</h3><p> ELK指的是elasticsearch、logstash和Kibana。</p><pre><code>Elasticsearch: 是一个基于 Apache Lucene(TM) 的开源搜索引擎,简单点说就是用于建立索引并存储日志的工具。Logstash: 是一个应用程序,它可以对日志的传输、过滤、管理和搜索提供支持。我们一般用它来统一对应用程序日志进行收集管理，提供Web接口用于查询和统计Kibana: 用于更友好的展示分析日志的web平台,简单点说就是有图有真相,可以在上面生成各种各样的图表更直观的显示日志分析的成果。</code></pre><h3 id="二、logstash的基本原理"><a href="#二、logstash的基本原理" class="headerlink" title="二、logstash的基本原理"></a>二、logstash的基本原理</h3><pre><code>logstash分为三个步骤：inputs（必须的）→ filters（可选的）→ outputs（必须的），inputs生成时间，filters对其事件进行过滤和处理，outputs输出到输出端或者决定其存储在哪些组件里。inputs和outputs支持编码和解码。</code></pre><p><img src="/image/Logstash%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86.png" alt="效果图预览"></p><h3 id="三、logstash安装"><a href="#三、logstash安装" class="headerlink" title="三、logstash安装"></a>三、logstash安装</h3><p>   下载地址：<a href="https://www.elastic.co/cn/downloads/logstash" target="_blank" rel="noopener">https://www.elastic.co/cn/downloads/logstash</a><br>   解压即安装：<br>        tar -zxvf logstash-7.7.0.tar.gz<br>    logstash版本的HelloWorld：<br>        ./bin/logstash -e ‘input { stdin { } } output { stdout {} }’</p><h3 id="四、logstash配置文件"><a href="#四、logstash配置文件" class="headerlink" title="四、logstash配置文件"></a>四、logstash配置文件</h3><pre><code>logstash.yml：包含Logstash配置标志。您可以在此文件中设置标志，而不是在命令行中传递标志。在命令行上设置的任何标志都会覆盖logstash中的相应设置pipelines.yml：包含在单个Logstash实例中运行多个管道的框架和指令。jvm.options：包含JVM配置标志。使用此文件设置总堆空间的初始值和最大值。您还可以使用此文件为Logsta设置语言环境log4j2.properties：包含log4j 2库的默认设置start.options (Linux)：用于配置启动服务脚本logstash.yml文件详解：    node.name  #默认主机名，该节点的描述名字    path.data  #LOGSTASH_HOME/data ，Logstash及其插件用于任何持久需求的目录    pipeline.id #默认main，pipeline的id    pipeline.java_execution #默认true，使用java执行引擎    pipeline.workers #默认为主机cpu的个数，表示并行执行管道的过滤和输出阶段的worker的数量    pipeline.batch.size #默认125 表示单个工作线程在尝试执行过滤器和输出之前从输入中收集的最大事件数    pipeline.batch.delay #默认50 在创建管道事件时，在将一个小批分派给管道工作者之前，每个事件需要等待多长时间(毫秒)    pipeline.unsafe_shutdown  #默认false，当设置为true时，即使内存中仍有运行的事件，强制Logstash在关闭期间将会退出。默认情况下，Logstash将拒绝退出，直到所有接收到的事件都被推入输出。启用此选项可能导致关机期间数据丢失    pipeline.ordered #默认auto，设置管道事件顺序。true将强制对管道进行排序，如果有多个worker，则阻止logstash启动。如果为false，将禁用维持秩序所需的处理。订单顺序不会得到保证，但可以节省维护订单的处理成本    path.config #默认LOGSTASH_HOME/config  管道的Logstash配置的路径    config.test_and_exit #默认false，设置为true时，检查配置是否有效，然后退出。请注意，使用此设置不会检查grok模式的正确性    config.reload.automatic #默认false，当设置为true时，定期检查配置是否已更改，并在更改时重新加载配置。这也可以通过SIGHUP信号手动触发    config.reload.interval  #默认3s ，检查配置文件频率    config.debug #默认false 当设置为true时，将完全编译的配置显示为调试日志消息    queue.type #默认memory ，用于事件缓冲的内部排队模型。为基于内存中的遗留队列指定内存，或为基于磁盘的脱机队列(持久队列)指定持久内存    path.queue #默认path.data/queue  ,在启用持久队列时存储数据文件的目录路径    queue.page_capacity #默认64mb ，启用持久队列时(队列)，使用的页面数据文件的大小。队列数据由分隔为页面的仅追加数据文件组成    queue.max_events #默认0，表示无限。启用持久队列时，队列中未读事件的最大数量    queue.max_bytes  #默认1024mb，队列的总容量，以字节为单位。确保磁盘驱动器的容量大于这里指定的值    queue.checkpoint.acks #默认1024，当启用持久队列(队列)时，在强制执行检查点之前被隔离的事件的最大数量    queue.checkpoint.writes #默认1024，当启用持久队列(队列)时，强制执行检查点之前的最大写入事件数    queue.checkpoint.retry #默认false，启用后，对于任何失败的检查点写，Logstash将对每个尝试的检查点写重试一次。任何后续错误都不会重试。并且不推荐使用，除非是在那些特定的环境中    queue.drain #默认false，启用后，Logstash将等待，直到持久队列耗尽，然后关闭    path.dead_letter_queue#默认path.data/dead_letter_queue，存储dead-letter队列的目录    http.host #默认&quot;127.0.0.1&quot; 表示endpoint REST端点的绑定地址。    http.port #默认9600 表示endpoint REST端点的绑定端口。    log.level #默认info，日志级别fatal，error，warn，info，debug，trace，    log.format #默认plain 日志格式    path.logs  #默认LOGSTASH_HOME/logs 日志目录</code></pre><h3 id="五、logstash配置文件的格式"><a href="#五、logstash配置文件的格式" class="headerlink" title="五、logstash配置文件的格式"></a>五、logstash配置文件的格式</h3><pre><code>input {    ...    }filter {    ...    }output {    ...    }</code></pre><h3 id="六、配置的重新加载"><a href="#六、配置的重新加载" class="headerlink" title="六、配置的重新加载"></a>六、配置的重新加载</h3><pre><code>方法一：在启动的时候指定参数    bin/logstash -f apache.config --config.reload.automatic    Logstash每3秒检查一次配置更改。要更改此间隔，请使用--config.reload.interval &lt;interval&gt;选项，其中interval指定Logstash检查配置文件更改的频率（以秒为单位）,请注意，必须使用单位限定符（s）方法二：强制加载配置文件   kill -SIGHUP pid  #pid为logstash的pid    自动配置重新加载配置注意点：    当Logstash检测到配置文件中的更改时，它将通过停止所有输入来停止当前管道，并尝试创建使用更新后的配置的新管道。验证新配置的语法后，Logstash验证所有输入和输出都可以初始化（例如，所有必需的端口都已打开）。如果检查成功，则Logstash会将现有管道与新管道交换。如果检查失败，旧管道将继续运行，并且错误将传播到控制台。    在自动重新加载配置期间，不会重新启动JVM。管道的创建和交换都在同一过程中进行。    对grok模式文件的更改也将重新加载，但仅在配置文件中的更改触发重新加载（或重新启动管道）时。</code></pre><h3 id="七、实际配置"><a href="#七、实际配置" class="headerlink" title="七、实际配置"></a>七、实际配置</h3><pre><code>input {    file {        path =&gt; &quot;.../logs/log/demoLog.log&quot;        start_position =&gt; &quot;beginning&quot;        stat_interval =&gt; &quot;3&quot;        type =&gt; &quot;demo_log&quot;    }    }    output {    if [type] == &quot;demo_log&quot; {        elasticsearch {        hosts =&gt; [&quot;http://127.0.0.1:9200&quot;]        index =&gt; &quot;demo_log-%{+YYYY.MM.dd}&quot;        }    }}属性说明：    input：指定Logstash接收数据的输入插件，使用file插件作为输入。file插件用于读取并处理文件中的数据。    file：指定使用的输入插件是file插件。    path：指定要读取的文件路径。    start_position：指定从文件的哪个位置开始读取数据。设置为&quot;beginning&quot;表示从文件的开始位置开始读取数据    stat_interval：指定文件的状态检查间隔（以秒为单位）。设置为&quot;3&quot;表示每隔3秒检查一次文件状态，以判断是否有新数据。    type：指定数据的类型名称。设置为&quot;nginx-access-log&quot;表示数据的类型是Nginx访问日志。    output：指定Logstash处理完数据后的输出插件。使用elasticsearch插件将处理后的日志数据发送到Elasticsearch。    type：指定数据的类型名称。    elasticsearch：指定使用的输出插件是elasticsearch插件。    hosts：指定Elasticsearch集群的主机地址。Logstash将处理后的数据发送到位于&quot;192.168.140.100&quot;主机上，HTTP端口9200的ES节点    index：指定数据在Elasticsearch中的索引名称，比如【 filebeat-8.4.1-2023.07.02 】使用[@metadata][version]字段和当前日期来构建索引名称 可以根据采集数据的来源和版本动态创建索引。</code></pre>]]></content>
      
      
      <categories>
          
          <category> ELK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark</title>
      <link href="/2024/05/07/Spark/"/>
      <url>/2024/05/07/Spark/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="一、Spark-简介"><a href="#一、Spark-简介" class="headerlink" title="一、Spark 简介"></a>一、Spark 简介</h3><p>Spark是一个快速、灵活的大数据处理框架。它基于内存计算，可以处理实时数据流和批量数据。</p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FLink</title>
      <link href="/2024/05/01/FLink/"/>
      <url>/2024/05/01/FLink/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="一、Flink-简介"><a href="#一、Flink-简介" class="headerlink" title="一、Flink 简介"></a>一、Flink 简介</h3><p>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink被设计在所有常见的集群环境中运行，以内存执行速度和任意规模来执行计算。</p>]]></content>
      
      
      <categories>
          
          <category> FLink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive</title>
      <link href="/2024/04/25/Hive/"/>
      <url>/2024/04/25/Hive/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="一、Hive-简介"><a href="#一、Hive-简介" class="headerlink" title="一、Hive 简介"></a>一、Hive 简介</h3><p>Hive是一个在Hadoop中用来处理结构化数据的数据仓库基础工具。它架构在Hadoop之上，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。hive数据仓库工具能将结构化的数据文件映射为一张数据库表，并提供SQL查询功能，能将SQL语句转变成MapReduce任务来执行。<br><img src="/image/Hive%E6%9E%B6%E6%9E%84.jpg" alt="效果图预览"></p><p><img src="/image/Hive%E5%8D%95%E5%85%83%E4%BB%8B%E7%BB%8D.png" alt="效果图预览"></p><pre><code>Hive特点    它存储架构在一个数据库中并处理数据到HDFS。    它是专为OLAP设计。    它提供SQL类型语言查询叫HiveQL或HQL。    它是低学习成本，快速和可扩展的。</code></pre>]]></content>
      
      
      <categories>
          
          <category> Hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop</title>
      <link href="/2024/04/18/Hadoop/"/>
      <url>/2024/04/18/Hadoop/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="一、Hadoop-简介"><a href="#一、Hadoop-简介" class="headerlink" title="一、Hadoop 简介"></a>一、Hadoop 简介</h3><pre><code>Hadoop是一个开源框架，允许使用简单的编程模型在跨计算机集群的分布式环境中存储和处理大数据。它的设计是从单个服务器扩展到数千个机器，每个都提供本地计算和存储。</code></pre><p> <img src="/image/Hadoop%E6%9E%B6%E6%9E%84.png" alt="效果图预览"></p><pre><code>HDFS: 分布式文件存储YARN: 分布式资源管理MapReduce: 分布式计算Others: 利用YARN的资源管理功能实现其他的数据处理方式内部各个节点基本都是采用Master-Woker架构适合    大规模数据    流式数据（写一次，读多次）    商用硬件（一般硬件）不适合    低延时的数据访问    大量的小文件    频繁修改文件（基本就是写1次）</code></pre><h3 id="二、Hadoop-模块"><a href="#二、Hadoop-模块" class="headerlink" title="二、Hadoop 模块"></a>二、Hadoop 模块</h3><pre><code>Hadoop是一个在分布式环境中存储和处理大型数据的开源框架。它包含两个模块，一个是MapReduce，另外一个是Hadoop分布式文件系统（HDFS）。MapReduce：它是一种在大型集群上的并行编程模型，普通硬件可用于处理大型结构化，半结构化和非结构化数据。HDFS：Hadoop分布式文件系统是Hadoop的框架的一部分，用于存储和处理数据集。它提供了一个在普通硬件上运行的容错文件系统。Hadoop生态系统包含了用于协助Hadoop的不同的子项目（工具）模块，如Sqoop, Pig 和 Hive。    Sqoop: 它用来在HDFS和RDBMS之间导入和导出数据。    Pig: 它用来开发MapReduce操作的脚本程序语言的平台。    Hive: 它用来开发SQL类型脚本，用于做MapReduce操作的平台。注：有多种方法来执行MapReduce作业：    传统的方法是使用Java MapReduce程序结构化，半结构化和非结构化数据。    针对MapReduce的脚本的方式，使用Pig来处理结构化和半结构化数据。    Hive查询语言（HiveQL或HQL）采用Hive为MapReduce的处理结构化数据。</code></pre>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据</title>
      <link href="/2024/03/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
      <url>/2024/03/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="一、大数据生态"><a href="#一、大数据生态" class="headerlink" title="一、大数据生态"></a>一、大数据生态</h3><p><img src="/image/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F.png" alt="效果图预览"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务</title>
      <link href="/2024/03/15/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
      <url>/2024/03/15/%E5%BE%AE%E6%9C%8D%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><h3 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a>雪花算法</h3><pre><code>使用一个 64 bit 的 long 型的数字作为全局唯一 id。在分布式系统中的应用十分广泛，且ID 引入了时间戳，基本上保持自增。格式：1bit保留 + 41bit时间戳 + 10bit机器 + 12bit序列号第一位不使用，主要是为了避免部分场景变成负数；41位时间戳，也就是2的41次方，毫秒为单位，足够保存69年。这里一般存储1970年以来的毫秒数，建议各个系统根据需要自定义这个开始日期；10位机器码，理论上可以表示1024台机器，也可以拆分几位表示机房几位表示机器。这里默认采用本机IPv4地址最后两段以及进程Id一起作为机器码，确保机房内部不同机器，以及相同机器上的不同进程，拥有不同的机器码（非绝对，详细看下文）；12位序列号，表示范围0~4095，一直递增，即使毫秒数加一，这里也不会归零；</code></pre>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微服务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AQS实现原理</title>
      <link href="/2024/01/07/AQS%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
      <url>/2024/01/07/AQS%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="AbstractQueuedSynchronizer（AQS）是Java中用于构建同步器的基础框架。它提供了一个灵活的、可重用的同步器实现，可以用来构建各种同步工具，如ReentrantLock、Semaphore、CountDownLatch等。AQS的核心思想是基于FIFO等待队列，通过状态（state）来管理线程的同步。"><a href="#AbstractQueuedSynchronizer（AQS）是Java中用于构建同步器的基础框架。它提供了一个灵活的、可重用的同步器实现，可以用来构建各种同步工具，如ReentrantLock、Semaphore、CountDownLatch等。AQS的核心思想是基于FIFO等待队列，通过状态（state）来管理线程的同步。" class="headerlink" title="AbstractQueuedSynchronizer（AQS）是Java中用于构建同步器的基础框架。它提供了一个灵活的、可重用的同步器实现，可以用来构建各种同步工具，如ReentrantLock、Semaphore、CountDownLatch等。AQS的核心思想是基于FIFO等待队列，通过状态（state）来管理线程的同步。"></a>AbstractQueuedSynchronizer（AQS）是Java中用于构建同步器的基础框架。它提供了一个灵活的、可重用的同步器实现，可以用来构建各种同步工具，如ReentrantLock、Semaphore、CountDownLatch等。AQS的核心思想是基于FIFO等待队列，通过状态（state）来管理线程的同步。</h2><h3 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a>核心原理</h3><pre><code>  State（状态）： AQS 的同步状态是一个整数，表示被同步的资源的状态。不同的同步器会使用不同的方式来表示状态的含义，例如，ReentrantLock 使用 state 表示持有锁的线程的数量，Semaphore 使用 state 表示可用的许可数量等。  FIFO 等待队列： AQS 使用一个FIFO的等待队列来管理获取同步资源失败的线程。每个节点（Node）表示一个等待线程，节点中保存了等待状态、前驱节点、后继节点等信息。当一个线程尝试获取锁但失败时，它会被包装成一个节点并加入到等待队列中。  独占模式和共享模式： AQS 支持独占模式和共享模式。独占模式表示只有一个线程能够获取同步资源，如ReentrantLock 就是独占模式的同步器。共享模式表示多个线程可以同时获取同步资源，如Semaphore 就是共享模式的同步器。AQS 使用 acquire 和 release 方法来分别表示获取和释放同步资源。  acquire 方法： 当线程尝试获取同步资源时，它会调用 AQS 的 acquire 方法。acquire 方法会根据同步状态的不同情况进行处理，如果同步状态允许当前线程获取资源，则直接返回；否则，当前线程会被包装成节点并加入到等待队列中，然后进入自旋等待状态，直到获取到资源。  release 方法： 当线程释放同步资源时，它会调用 AQS 的 release 方法。release 方法会根据同步状态的不同情况进行处理，然后唤醒等待队列中的下一个线程，使其有机会获取资源。  独占锁和共享锁的实现： AQS 提供了独占锁的实现方法 tryAcquire 和 tryRelease，以及共享锁的实现方法 tryAcquireShared 和 tryReleaseShared。</code></pre>]]></content>
      
      
      <categories>
          
          <category> AQS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AQS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>canal</title>
      <link href="/2023/12/25/canal/"/>
      <url>/2023/12/25/canal/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="canal，译意为水道-管道-沟渠，主要用途是基于-MySQL-数据库增量日志解析，提供增量数据订阅和消费"><a href="#canal，译意为水道-管道-沟渠，主要用途是基于-MySQL-数据库增量日志解析，提供增量数据订阅和消费" class="headerlink" title=" canal，译意为水道/管道/沟渠，主要用途是基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费"></a> canal，译意为水道/管道/沟渠，主要用途是基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费</h2><h3 id="canal的工作原理"><a href="#canal的工作原理" class="headerlink" title="canal的工作原理"></a>canal的工作原理</h3><pre><code>canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )；canal 解析 binary log 对象(原始为 byte 流)；</code></pre><p>   <img src="/image/cannal%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="效果图预览"> </p><h3 id="Canal安装"><a href="#Canal安装" class="headerlink" title="Canal安装"></a>Canal安装</h3><pre><code>1.从官网上下载Canal服务器，地址：https://github.com/alibaba/canal/releases2.创建一个canal文件夹，上传压缩包并解压修改canal配置文件    vi conf/example/instance.properties3.修改mysql配置vi /etc/my.cnf     log-bin=mysql-bin             #添加这一行就ok     binlog-format=ROW           #选择row模式     server-id=1       #配置mysql replaction需要定义，不能和canal的slaveI重复    binlog-do-db=micromall4.执行mysql 创建canal用户    create user canal identified by &#39;canal&#39;;    GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#39;canal&#39;@&#39;%&#39;;    FLUSH PRIVILEGES;    查看是否授权成功：       select * from user  where  user=&#39;canal&#39;;5、启动canal    cd bin    ./startup.sh</code></pre><h3 id="测试Canal"><a href="#测试Canal" class="headerlink" title="测试Canal"></a>测试Canal</h3><pre><code>逻辑：    mysql开启主从同步    启动Canal，拿到mysql的binlog日志    消息中间件获取binlog日志添加依赖&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt;    &lt;artifactId&gt;canal.client&lt;/artifactId&gt;    &lt;version&gt;1.1.0&lt;/version&gt;&lt;/dependency&gt;import java.net.InetSocketAddress;import java.util.List;import com.alibaba.otter.canal.client.CanalConnectors;import com.alibaba.otter.canal.client.CanalConnector;import com.alibaba.otter.canal.common.utils.AddressUtils;import com.alibaba.otter.canal.protocol.Message;import com.alibaba.otter.canal.protocol.CanalEntry.Column;import com.alibaba.otter.canal.protocol.CanalEntry.Entry;import com.alibaba.otter.canal.protocol.CanalEntry.EntryType;import com.alibaba.otter.canal.protocol.CanalEntry.EventType;import com.alibaba.otter.canal.protocol.CanalEntry.RowChange;import com.alibaba.otter.canal.protocol.CanalEntry.RowData;public class SimpleCanalClientExample {    public static void main(String args[]) {        // 创建链接        CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress(&quot;127.0.0.1&quot;,                11111), &quot;example&quot;, &quot;&quot;, &quot;&quot;);        int batchSize = 1000;        int emptyCount = 0;        try {            connector.connect();            connector.subscribe(&quot;.*\\..*&quot;);            connector.rollback();            int totalEmptyCount = 120;            while (emptyCount &lt; totalEmptyCount) {                Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据                long batchId = message.getId();                int size = message.getEntries().size();                if (batchId == -1 || size == 0) {                    emptyCount++;                    System.out.println(&quot;empty count : &quot; + emptyCount);                    try {                        Thread.sleep(1000);                    } catch (InterruptedException e) {                    }                } else {                    emptyCount = 0;                    // System.out.printf(&quot;message[batchId=%s,size=%s] \n&quot;, batchId, size);                    printEntry(message.getEntries());                }                connector.ack(batchId); // 提交确认                // connector.rollback(batchId); // 处理失败, 回滚数据            }            System.out.println(&quot;empty too many times, exit&quot;);        } finally {            connector.disconnect();        }    }    private static void printEntry(List&lt;Entry&gt; entrys) {        for (Entry entry : entrys) {            if (entry.getEntryType() == EntryType.TRANSACTIONBEGIN || entry.getEntryType() == EntryType.TRANSACTIONEND) {                continue;            }            RowChange rowChage = null;            try {                rowChage = RowChange.parseFrom(entry.getStoreValue());            } catch (Exception e) {                throw new RuntimeException(&quot;ERROR ## parser of eromanga-event has an error , data:&quot; + entry.toString(),                        e);            }            EventType eventType = rowChage.getEventType();            System.out.println(String.format(&quot;================&amp;gt; binlog[%s:%s] , name[%s,%s] , eventType : %s&quot;,                    entry.getHeader().getLogfileName(), entry.getHeader().getLogfileOffset(),                    entry.getHeader().getSchemaName(), entry.getHeader().getTableName(),                    eventType));            for (RowData rowData : rowChage.getRowDatasList()) {                if (eventType == EventType.DELETE) {                    printColumn(rowData.getBeforeColumnsList());                } else if (eventType == EventType.INSERT) {                    printColumn(rowData.getAfterColumnsList());                } else {                    System.out.println(&quot;-------&amp;gt; before&quot;);                    printColumn(rowData.getBeforeColumnsList());                    System.out.println(&quot;-------&amp;gt; after&quot;);                    printColumn(rowData.getAfterColumnsList());                }            }        }    }    private static void printColumn(List&lt;Column&gt; columns) {        for (Column column : columns) {            System.out.println(column.getName() + &quot; : &quot; + column.getValue() + &quot;    update=&quot; + column.getUpdated());        }    }}</code></pre><h3 id="接入中间件"><a href="#接入中间件" class="headerlink" title="接入中间件"></a>接入中间件</h3><pre><code>目的：修改mysql数据后，把消息同步到RocketMQ修改instance 配置文件    vi conf/example/instance.properties# mq configcanal.mq.topic=example# dynamic topic route by schema or table regex#canal.mq.dynamicTopic=mytest1.user,mytest2\\..*,.*\\..*canal.mq.partition=0# hash partition config#canal.mq.partitionsNum=3#canal.mq.partitionHash=test.table:id^name,.*\\..*#################################################</code></pre><p>   instance.properties完整版<br>        #################################################<br>        ## mysql serverId , v1.0.26+ will autoGen<br>        # canal.instance.mysql.slaveId=0<br>        # enable gtid use true/false<br>        canal.instance.gtidon=false<br>        # position info<br>        #canal.instance.master.address=192.168.65.232:3306<br>        canal.instance.master.address=192.168.65.232:3306<br>        canal.instance.master.journal.name=<br>        canal.instance.master.position=<br>        canal.instance.master.timestamp=<br>        canal.instance.master.gtid=<br>        # rds oss binlog<br>        canal.instance.rds.accesskey=<br>        canal.instance.rds.secretkey=<br>        canal.instance.rds.instanceId=<br>        # table meta tsdb info<br>        canal.instance.tsdb.enable=true<br>        #canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdb<br>        #canal.instance.tsdb.dbUsername=canal<br>        #canal.instance.tsdb.dbPassword=canal<br>        #canal.instance.standby.address =<br>        #canal.instance.standby.journal.name =<br>        #canal.instance.standby.position =<br>        #canal.instance.standby.timestamp =<br>        #canal.instance.standby.gtid=<br>        # username/password<br>        canal.instance.dbUsername=root<br>        canal.instance.dbPassword=root<br>        canal.instance.connectionCharset = UTF-8<br>        canal.instance.defaultDatabaseName=micromall<br>        # enable druid Decrypt database password<br>        canal.instance.enableDruid=false<br>        #canal.instance.pwdPublicKey=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5/zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2/JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ==<br>        # table regex<br>        #canal.instance.filter.regex=.<em>\..</em><br>        canal.instance.filter.regex=micromall.pms_product,micromall.sms_flash_promotion_product_relation<br>        # table black regex<br>        canal.instance.filter.black.regex=<br>        # mq config<br>        canal.mq.topic=productDetailChange<br>        # dynamic topic route by schema or table regex<br>        #canal.mq.dynamicTopic=mytest1.user,mytest2\..<em>,.*\..</em><br>        canal.mq.partition=0<br>        # hash partition config<br>        #canal.mq.partitionsNum=3<br>        #canal.mq.partitionHash=test.table:id^name,.<em>\..</em><br>        #################################################</p><pre><code>修改canal 配置文件    vi /usr/local/canal/conf/canal.properties###########################################################                    MQ     ################################################################ kafka/rocketmq 集群配置: 192.168.1.117:9092,192.168.1.118:9092,192.168.1.119:9092canal.mq.servers = 192.168.1.150:9876canal.mq.retries = 0canal.mq.batchSize = 16384canal.mq.maxRequestSize = 1048576canal.mq.lingerMs = 1canal.mq.bufferMemory = 33554432#消息生产组名canal.mq.producerGroup = Canal-Producer# Canal的batch size, 默认50K, 由于kafka最大消息体限制请勿超过1M(900K以下)canal.mq.canalBatchSize = 30# Canal get数据的超时时间, 单位: 毫秒, 空为不限超时canal.mq.canalGetTimeout = 100# 是否为flat json格式对象canal.mq.flatMessage = truecanal.mq.compressionType = nonecanal.mq.acks = all# use transaction for kafka flatMessage batch producecanal.mq.transaction = false#canal.mq.properties. =canal.properties完整版    #################################################    #########         common argument        #############     #################################################    #canal.manager.jdbc.url=jdbc:mysql://127.0.0.1:3306/canal_manager?useUnicode=true&amp;characterEncoding=UTF-8    #canal.manager.jdbc.username=root    #canal.manager.jdbc.password=121212    canal.id = 1    canal.ip =    canal.port = 11111    canal.metrics.pull.port = 11112    canal.zkServers =    # flush data to zk    canal.zookeeper.flush.period = 1000    canal.withoutNetty = false    # tcp, kafka, RocketMQ    canal.serverMode = RocketMQ    # flush meta cursor/parse position to file    canal.file.data.dir = ${canal.conf.dir}    canal.file.flush.period = 1000    ## memory store RingBuffer size, should be Math.pow(2,n)    canal.instance.memory.buffer.size = 16384    ## memory store RingBuffer used memory unit size , default 1kb    canal.instance.memory.buffer.memunit = 1024     ## meory store gets mode used MEMSIZE or ITEMSIZE    canal.instance.memory.batch.mode = MEMSIZE    canal.instance.memory.rawEntry = true    ## detecing config    canal.instance.detecting.enable = false    #canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()    canal.instance.detecting.sql = select 1    canal.instance.detecting.interval.time = 3    canal.instance.detecting.retry.threshold = 3    canal.instance.detecting.heartbeatHaEnable = false    # support maximum transaction size, more than the size of the transaction will be cut into multiple transactions delivery    canal.instance.transaction.size =  1024    # mysql fallback connected to new master should fallback times    canal.instance.fallbackIntervalInSeconds = 60    # network config    canal.instance.network.receiveBufferSize = 16384    canal.instance.network.sendBufferSize = 16384    canal.instance.network.soTimeout = 30    # binlog filter config    canal.instance.filter.druid.ddl = true    canal.instance.filter.query.dcl = false    canal.instance.filter.query.dml = false    canal.instance.filter.query.ddl = false    canal.instance.filter.table.error = false    canal.instance.filter.rows = false    canal.instance.filter.transaction.entry = false    # binlog format/image check    canal.instance.binlog.format = ROW,STATEMENT,MIXED     canal.instance.binlog.image = FULL,MINIMAL,NOBLOB    # binlog ddl isolation    canal.instance.get.ddl.isolation = false    # parallel parser config    canal.instance.parser.parallel = true    ## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()    #canal.instance.parser.parallelThreadSize = 16    ## disruptor ringbuffer size, must be power of 2    canal.instance.parser.parallelBufferSize = 256    # table meta tsdb info    canal.instance.tsdb.enable = true    canal.instance.tsdb.dir = ${canal.file.data.dir:../conf}/${canal.instance.destination:}    canal.instance.tsdb.url = jdbc:h2:${canal.instance.tsdb.dir}/h2;CACHE_SIZE=1000;MODE=MYSQL;    canal.instance.tsdb.dbUsername = canal    canal.instance.tsdb.dbPassword = canal    # dump snapshot interval, default 24 hour    canal.instance.tsdb.snapshot.interval = 24    # purge snapshot expire , default 360 hour(15 days)    canal.instance.tsdb.snapshot.expire = 360    # aliyun ak/sk , support rds/mq    canal.aliyun.accessKey =    canal.aliyun.secretKey =    #################################################    #########         destinations        #############     #################################################    canal.destinations = example    # conf root dir    canal.conf.dir = ../conf    # auto scan instance dir add/remove and start/stop instance    canal.auto.scan = true    canal.auto.scan.interval = 5    #canal.instance.tsdb.spring.xml = classpath:spring/tsdb/h2-tsdb.xml    #canal.instance.tsdb.spring.xml = classpath:spring/tsdb/mysql-tsdb.xml    canal.instance.global.mode = spring    canal.instance.global.lazy = false    #canal.instance.global.manager.address = 127.0.0.1:1099    #canal.instance.global.spring.xml = classpath:spring/memory-instance.xml    canal.instance.global.spring.xml = classpath:spring/file-instance.xml    #canal.instance.global.spring.xml = classpath:spring/default-instance.xml    ##################################################    #########              MQ              #############    ##################################################    ##################################################    #########                    MQ     #############    ##################################################    # kafka/rocketmq 集群配置: 192.168.1.117:9092,192.168.1.118:9092,192.168.1.119:9092    canal.mq.servers = 127.0.0.1:9876    canal.mq.retries = 0    canal.mq.batchSize = 16384    canal.mq.maxRequestSize = 1048576    canal.mq.lingerMs = 1    canal.mq.bufferMemory = 33554432    #消息生产组名    canal.mq.producerGroup = canalProducer    # Canal的batch size, 默认50K, 由于kafka最大消息体限制请勿超过1M(900K以下)    canal.mq.canalBatchSize = 30    # Canal get数据的超时时间, 单位: 毫秒, 空为不限超时    canal.mq.canalGetTimeout = 100    # 是否为flat json格式对象    canal.mq.flatMessage = true    canal.mq.compressionType = none    canal.mq.acks = all    # use transaction for kafka flatMessage batch produce    canal.mq.transaction = false    #canal.mq.properties. =</code></pre><p><img src="/image/%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.png" alt="效果图预览"> </p><h3 id="Canal内部原理"><a href="#Canal内部原理" class="headerlink" title="Canal内部原理"></a>Canal内部原理</h3><p><img src="/image/canal%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86.png" alt="效果图预览"><br>        server代表一个canal运行实例，对应于一个jvm<br>        instance对应于一个数据队列 （1个server对应1…n个instance)</p><pre><code>instance模块：    eventParser (数据源接入，模拟slave协议和master进行交互，协议解析)    eventSink (Parser和Store链接器，进行数据过滤，加工，分发的工作)    eventStore (数据存储)    metaManager (增量订阅&amp;消费信息管理器)mysql&gt; show variables like &#39;binlog_format&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| binlog_format | ROW   |+---------------+-------+1 row in set (0.00 sec) 解析开始：    com.alibaba.otter.canal.parse.inbound.AbstractEventParser#start</code></pre><h3 id="Canal集群高可用"><a href="#Canal集群高可用" class="headerlink" title="Canal集群高可用"></a>Canal集群高可用</h3><pre><code> canal的ha分为两部分，canal server和canal client分别有对应的ha实现    canal server: 为了减少对mysql dump的请求，不同server上的instance要求同一时间只能有一个处于running，其他的处于standby状态.    canal client: 为了保证有序性，一份instance同一时间只能由一个canal client进行get/ack/rollback操作，否则客户端接收无法保证有序。    整个HA机制的控制主要是依赖了zookeeper的几个特性，watcher和EPHEMERAL节点(和session生命周期绑定)。</code></pre><p> <img src="/image/canal%E9%9B%86%E7%BE%A4.png" alt="效果图预览"><br>        大致步骤：<br>            canal server要启动某个canal instance时都先向zookeeper进行一次尝试启动判断 (实现：创建EPHEMERAL节点，谁创建成功就允许谁启动)<br>            创建zookeeper节点成功后，对应的canal server就启动对应的canal instance，没有创建成功的canal instance就会处于standby状态<br>            一旦zookeeper发现canal server A创建的节点消失后，立即通知其他的canal server再次进行步骤1的操作，重新选出一个canal server启动instance.<br>            canal client每次进行connect时，会首先向zookeeper询问当前是谁启动了canal instance，然后和其建立链接，一旦链接不可用，会重新尝试connect.<br>            Canal Client的方式和canal server方式类似，也是利用zookeeper的抢占EPHEMERAL节点的方式进行控制.</p>]]></content>
      
      
      <categories>
          
          <category> canal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> canal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>neo4j图数据</title>
      <link href="/2023/12/20/neo4j%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
      <url>/2023/12/20/neo4j%E5%9B%BE%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Neo4j-Things，not-string"><a href="#Neo4j-Things，not-string" class="headerlink" title=" Neo4j - Things，not string"></a> Neo4j - Things，not string</h2><p>历史悠久且长期处于图数据库领域的主力地位，其功能强大，性能也不错，单节点的服务器可承载上亿级的节点和关系。社区版最多支持 320 亿个节点、320 亿个关系和 640亿个属性。<br>优点：Neo4j有自己的后端存储，不必如同JanusGraph等一样还要依赖另外的数据库存储。 Neo4j在每个节点中存储了每个边的指针，因而遍历时效率相当高。<br>缺点：企业版付费。开源的社区版本只支持单机，不支持分布式。社区版只能部署成单实例，企业版可以部署成高可用集群，从而可以解决高并发量的问题；社区版不能做集群，单个实例故障时影响系统正常运行。社区版只支持冷备份，即需要停止服务后才能进行备份。</p><h3 id="一、-三要素"><a href="#一、-三要素" class="headerlink" title="一、 三要素"></a>一、 三要素</h3><pre><code>在知识图谱中，通过三元组 &lt;实体 × 关系 × 属性&gt; 集合的形式来描述事物之间的关系：实体：又叫作本体，指客观存在并可相互区别的事物，可以是具体的人、事、物，也可以是抽象的概念或联系，实体是知识图谱中最基本的元素关系：在知识图谱中，边表示知识图谱中的关系，用来表示不同实体间的某种联系属性：知识图谱中的实体和关系都可以有各自的属性</code></pre><h3 id="二、-Neo4j安装"><a href="#二、-Neo4j安装" class="headerlink" title="二、 Neo4j安装"></a>二、 Neo4j安装</h3><pre><code>底层依赖于关键的图数据库，在这里我们选择 Neo4j，它是一款高性能的 nosql 图形数据库，能够将结构化的数据存储在图而不是表中。下载地址：https://Neo4j.com/download/other-releases/需要注意的是，Neo4j 4.x 以上的版本都需要依赖 jdk11 环境，所以如果运行环境是 jdk8 的话，只能下载 3.x 版本就行，下载解压完成后，在bin目录下通过命令启动</code></pre><h4 id="2-1-Neo4j环境Linux下搭建"><a href="#2-1-Neo4j环境Linux下搭建" class="headerlink" title="2.1 Neo4j环境Linux下搭建"></a>2.1 Neo4j环境Linux下搭建</h4><pre><code>(1).切换到Linux下 到安装目录neo4j 上传安装包 或者 下载安装包使用 ftp 工具上传neo4j-community-3.5.17.tar 到 liunx 下或者 wget https://neo4j.com/artifact.php?name=neo4j-community-3.5.17-unix.tar.gz(2). 解压tar -xvf neo4j-community-3.5.17.tar(3). 修改配置文件 neo4j.confvi conf/neo4j.conf主要是修改 允许远程访问的地址 把对应的注释打开即可dbms.connectors.default_listen_address=0.0.0.0(4).开放对应的访问端口 默认要开放7474 和 7687或者直接关闭防火墙（生产环境上不会直接关防火墙）firewall-cmd --zone=public --add-port=7474/tcp --permanentfirewall-cmd --zone=public --add-port=7687/tcp --permanentsystemctl reload firewalld(5).启动（安装jdk8及以上否则启动报错）./bin/neo4j start(6).使用浏览器 访问服务器上的 neo4jhttp://XXXX:7474 用户名 密码默认的账号是 neo4j 密码 neo4j 这里第一次登录的话会要求修改密码</code></pre><h4 id="2-2-Neo4j-CQL"><a href="#2-2-Neo4j-CQL" class="headerlink" title="2.2 Neo4j CQL"></a>2.2 Neo4j CQL</h4><pre><code>CQL代表Cypher查询语言。 像关系型数据库具有查询语言SQL，Neo4j使用CQL作为查询语言。Neo4j CQL：它是Neo4j图形数据库的查询语言。它是一种声明性模式匹配语言。它遵循SQL语法。它的语法是非常简单且人性化、可读的格式。</code></pre><h5 id="2-2-1-CREATE"><a href="#2-2-1-CREATE" class="headerlink" title="2.2.1 CREATE"></a>2.2.1 CREATE</h5><pre><code>CREATE (&lt;node-name&gt;:&lt;label-name&gt;[{&lt;property1-name&gt;:&lt;property1-Value&gt;........&lt;propertyn-name&gt;:&lt;propertyn-Value&gt;}])例如：CREATE (person:Person {cid:1,name:&quot;范闲&quot;,age:24,gender:0,character:&quot;A&quot;,money:1000});CREATE (person:Person {cid:2,name:&quot;林婉儿&quot;,age:20,gender:1,character:&quot;B&quot;,money:800});CREATE (person:Person {cid:3,name:&quot;庆帝&quot;,age:49,gender:0,character:&quot;A&quot;,money:8900});</code></pre><h5 id="2-2-2-MATCH-RETURN"><a href="#2-2-2-MATCH-RETURN" class="headerlink" title="2.2.2 MATCH RETURN"></a>2.2.2 MATCH RETURN</h5><pre><code>MATCH(&lt;node-name&gt;:&lt;label-name&gt;)RETURN&lt;node-name&gt;.&lt;property1-name&gt;,...&lt;node-name&gt;.&lt;propertyn-name&gt;例如：MATCH(person:Person) return person;MATCH(person:Person) return person.name,person.age;</code></pre><h5 id="2-2-3-关系创建"><a href="#2-2-3-关系创建" class="headerlink" title="2.2.3 关系创建"></a>2.2.3 关系创建</h5><h6 id="2-2-3-1使用现有节点创建没有属性的关系"><a href="#2-2-3-1使用现有节点创建没有属性的关系" class="headerlink" title="2.2.3.1使用现有节点创建没有属性的关系"></a>2.2.3.1使用现有节点创建没有属性的关系</h6><pre><code>MATCH (&lt;node1-name&gt;:&lt;node1-label-name&gt;),(&lt;node2-name&gt;:&lt;node2-label-name&gt;)CREATE(&lt;node1-name&gt;)-[&lt;relationship-name&gt;:&lt;relationship-label-name&gt;]-&gt;(&lt;node2-name&gt;)RETURN 相应的内容创建关系match(person:Person {name:&quot;范闲&quot;}) ,(person2:Person {name:&quot;林婉儿&quot;})create(person)-[r:Couple]-&gt;(person2);查询关系match p = (person:Person {name:&quot;范闲&quot;})-[r:Couple]-&gt;(person2:Person) return pmatch (p1:Person {name:&quot;范闲&quot;})-[r:Couple]-(p2:Person) return p1,p2match (p1:Person {name:&quot;范闲&quot;})-[r:Couple]-(p2:Person) return r</code></pre><h6 id="2-2-3-2使用现有节点创建有属性的关系"><a href="#2-2-3-2使用现有节点创建有属性的关系" class="headerlink" title="2.2.3.2使用现有节点创建有属性的关系"></a>2.2.3.2使用现有节点创建有属性的关系</h6><pre><code>MATCH (&lt;node1-label-name&gt;:&lt;node1-name&gt;),(&lt;node2-label-name&gt;:&lt;node2-name&gt;)CREATE(&lt;node1-label-name&gt;)-[&lt;relationship-label-name&gt;:&lt;relationship-name&gt;{&lt;define-properties-list&gt;}]-&gt;(&lt;node2-label-name&gt;)RETURN &lt;relationship-label-name&gt;其中&lt;define-properties-list&gt; 是分配给新创建关系的属性（名称 - 值对）的列表。{&lt;property1-name&gt;:&lt;property1-value&gt;,&lt;property2-name&gt;:&lt;property2-value&gt;,...&lt;propertyn-name&gt;:&lt;propertyn-value&gt;}</code></pre><h6 id="2-2-3-3使用新节点创建没有属性的关系"><a href="#2-2-3-3使用新节点创建没有属性的关系" class="headerlink" title="2.2.3.3使用新节点创建没有属性的关系"></a>2.2.3.3使用新节点创建没有属性的关系</h6><pre><code>CREATE(&lt;node1-label-name&gt;:&lt;node1-name&gt;)-[&lt;relationship-label-name&gt;:&lt;relationship-name&gt;]-&gt;(&lt;node1-label-name&gt;:&lt;node1-name&gt;)create(person1:Person {cid:4,name:&quot;长公主&quot;,age:49,gender:1,character:&quot;A&quot;,money:5000})-[r:Friend]-&gt;(person2:Person {cid:7,name:&quot;九品射手燕小乙&quot;,age:48,gender:0,character:&quot;B&quot;,money:1000});</code></pre><h6 id="2-2-3-4使用新节点创建没有属性的关系"><a href="#2-2-3-4使用新节点创建没有属性的关系" class="headerlink" title="2.2.3.4使用新节点创建没有属性的关系"></a>2.2.3.4使用新节点创建没有属性的关系</h6><pre><code>CREATE(&lt;node1-label-name&gt;:&lt;node1-name&gt;{&lt;define-properties-list&gt;})-[&lt;relationship-label-name&gt;:&lt;relationship-name&gt;{&lt;define-properties-list&gt;}]-&gt;(&lt;node1-label-name&gt;:&lt;node1-name&gt;{&lt;define-properties-list&gt;});create (person1:Person {cid:9,name:&quot;靖王子&quot;,age:23,gender:0,character:&quot;A&quot;,money:3000})-[r:Friend {date:&quot;11-02-2000&quot;}]-&gt;(person2:Person {cid:8,name:&quot;二皇子&quot;,age:24,gender:0,character:&quot;B&quot;,money:6000});关系和节点的属性可以使用的类型</code></pre><h5 id="2-2-4-WHERE-子句"><a href="#2-2-4-WHERE-子句" class="headerlink" title="2.2.4 WHERE 子句"></a>2.2.4 WHERE 子句</h5><pre><code>简单的WHERE子句WHERE &lt;condition&gt;复杂的WHERE子句WHERE &lt;condition&gt; &lt;boolean-operator&gt; &lt;condition&gt;</code></pre><h5 id="2-2-5DELETE-子句-和-REMOVE子句"><a href="#2-2-5DELETE-子句-和-REMOVE子句" class="headerlink" title="2.2.5DELETE 子句 和 REMOVE子句"></a>2.2.5DELETE 子句 和 REMOVE子句</h5><pre><code>DELETE 子句: 删除节点。删除节点及相关节点和关系。REMOVE子句: 删除节点或关系的标签,删除节点或关系的属性。match p = (:Person {name:&quot;林婉儿&quot;})-[r:Couple]-(:Person) delete r;MATCH (person:Person {name:&quot;小美女&quot;})REMOVE person.cid;REMOVE子句主要用于删除节点或关系的属性，这点跟DELETE有些差别。DELETE是删除节点或关系，但不删除属性。DELETE和REMOVE命令之间的主要区别 -DELETE操作用于删除节点和关联关系。REMOVE操作用于删除标签和属性。REMOVE命令用于    删除节点或关系的标签    删除节点或关系的属性CQL DELETE和REMOVE命令之间的相似性 -这两个命令不应单独使用。两个命令都应该与MATCH命令一起使用。</code></pre><h5 id="2-2-6-SET子句"><a href="#2-2-6-SET子句" class="headerlink" title="2.2.6 SET子句"></a>2.2.6 SET子句</h5><pre><code>向现有节点或关系添加新属性，更新属性值 .MATCH (person:Person {cid:1})SET person.money = 3456,person.age=25</code></pre><h5 id="2-2-7-ORDER-BY-子句"><a href="#2-2-7-ORDER-BY-子句" class="headerlink" title="2.2.7 ORDER BY 子句"></a>2.2.7 ORDER BY 子句</h5><pre><code>“ORDER BY”子句，对MATCH查询返回的结果进行排序。我们可以按升序或降序对行进行排序。默认情况下，它按升序对行进行排序。 如果我们要按降序对它们进行排序，我们需要使用DESC子句。MATCH (person:Person) RETURN person.name,person.money ORDER BY person.money DESC;</code></pre><h5 id="2-2-8-SKIP-和-LIMIT"><a href="#2-2-8-SKIP-和-LIMIT" class="headerlink" title="2.2.8 SKIP 和 LIMIT"></a>2.2.8 SKIP 和 LIMIT</h5><pre><code>Neo4j CQL已提供“SKIP”子句来过滤或限制查询返回的行数。 它修整了CQL查询结果集顶部的结果。Neo4j CQL已提供“LIMIT”子句来过滤或限制查询返回的行数。 它修剪CQL查询结果集底部的结果。MATCH (person:Person)RETURN ID(person),person.name,person.moneyORDER BY person.money DESC skip 4 limit 2</code></pre><h5 id="2-2-9-DISTINCT-排重"><a href="#2-2-9-DISTINCT-排重" class="headerlink" title="2.2.9 DISTINCT 排重"></a>2.2.9 DISTINCT 排重</h5><pre><code>这个函数的用法就像SQL中的distinct关键字，返回的是所有不同值。MATCH (p:Person) RETURN Distinct(p.cid);</code></pre><h5 id="2-2-10-操作符"><a href="#2-2-10-操作符" class="headerlink" title="2.2.10 操作符"></a>2.2.10 操作符</h5><pre><code>操作符是对Cypher查询进行算术运算，逻辑运算等。</code></pre><h6 id="2-2-10-1-通用操作符"><a href="#2-2-10-1-通用操作符" class="headerlink" title="2.2.10.1 通用操作符"></a>2.2.10.1 通用操作符</h6><pre><code> distinct 用于移除重复值， n.property 用于访问属性，[]是变量的列表 CREATE (a:Person { name: &#39;Anne&#39;, eyeColor: &#39;blue&#39; }),(b:Person { name: &#39;Bill&#39;, eyeColor: &#39;brown&#39; }),(c:Person { name: &#39;Carol&#39;, eyeColor: &#39;blue&#39; })WITH [a, b, c] AS psUNWIND ps AS pRETURN DISTINCT p.eyeColor</code></pre><h6 id="2-2-10-2-数学操作符"><a href="#2-2-10-2-数学操作符" class="headerlink" title="2.2.10.2 数学操作符"></a>2.2.10.2 数学操作符</h6><pre><code>加减乘除：+,-,*,/取模：%取幂：^</code></pre><h6 id="2-2-10-3-比较运算符"><a href="#2-2-10-3-比较运算符" class="headerlink" title="2.2.10.3 比较运算符"></a>2.2.10.3 比较运算符</h6><pre><code>等于：=不等于：&lt;&gt;小于、大于、小于等于、大于等于：&lt;、&gt;、&lt;=、&gt;=IS NULL和 IS NOT NULL</code></pre><h6 id="2-2-10-4-逻辑运算符"><a href="#2-2-10-4-逻辑运算符" class="headerlink" title="2.2.10.4 逻辑运算符"></a>2.2.10.4 逻辑运算符</h6><pre><code>与（AND）,或（OR）,异或（XOR）,非（NOT）WITH [2, 4, 7, 9, 12] AS numberlistUNWIND numberlist AS numberWITH numberWHERE number = 4 OR (number &gt; 6 AND number &lt; 10)RETURN number</code></pre><h6 id="2-2-10-5-字符串"><a href="#2-2-10-5-字符串" class="headerlink" title="2.2.10.5 字符串"></a>2.2.10.5 字符串</h6><pre><code>字符串拼接：+匹配正则：=~WITH [&#39;mouse&#39;, &#39;chair&#39;, &#39;door&#39;, &#39;house&#39;] AS wordlistUNWIND wordlist AS wordWITH wordWHERE word =~ &#39;.*ous.*&#39;RETURN word对于字符串，使用 STARTS WITH、ENDS WITH和CONTAINS 过滤字符串：WITH [&#39;John&#39;, &#39;Mark&#39;, &#39;Jonathan&#39;, &#39;Bill&#39;] AS somenamesUNWIND somenames AS namesWITH names AS candidateWHERE candidate STARTS WITH &#39;Jo&#39;RETURN candidate</code></pre><h6 id="2-2-10-6-列表操作"><a href="#2-2-10-6-列表操作" class="headerlink" title="2.2.10.6 列表操作"></a>2.2.10.6 列表操作</h6><pre><code>+，列表追加IN：检查成员[]：索引，特殊地，[start .. end]，从start开始，递增1，但是不包括endRETURN [1,2,3,4,5]+[6,7] AS myListWITH [2, 3, 4, 5] AS numberlistUNWIND numberlist AS numberWITH numberWHERE number IN [2, 3, 8]RETURN numberWITH [&#39;Anne&#39;, &#39;John&#39;, &#39;Bill&#39;, &#39;Diane&#39;, &#39;Eve&#39;] AS namesRETURN names[1..3] AS result</code></pre><h6 id="2-2-10-7-访问属性"><a href="#2-2-10-7-访问属性" class="headerlink" title="2.2.10.7 访问属性"></a>2.2.10.7 访问属性</h6><pre><code>使用 . 号访问属性MATCH (n) WHERE 21 &lt; n.age AND n.age &lt;= 30 RETURN n</code></pre><h3 id="三、-Springboot整合-Neo4j"><a href="#三、-Springboot整合-Neo4j" class="headerlink" title="三、 Springboot整合 Neo4j"></a>三、 Springboot整合 Neo4j</h3><h4 id="3-1-引入依赖"><a href="#3-1-引入依赖" class="headerlink" title="3.1 引入依赖"></a>3.1 引入依赖</h4><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-neo4j&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><h4 id="3-2-增加配置"><a href="#3-2-增加配置" class="headerlink" title="3.2 增加配置"></a>3.2 增加配置</h4><pre><code>spring:    data:        neo4j:            uri: bolt://XX:7687            username: 用户民            password: 密码</code></pre><h4 id="3-3-核心代码"><a href="#3-3-核心代码" class="headerlink" title="3.3 核心代码"></a>3.3 核心代码</h4><h4 id="3-3-1设置节点"><a href="#3-3-1设置节点" class="headerlink" title="3.3.1设置节点"></a>3.3.1设置节点</h4><pre><code>@Data@Node(&quot;Organization&quot;)public class Organization {    @Id    @GeneratedValue    private Long id;    @Property(name = &quot;orgName&quot;)    private String orgName;    @Relationship(type = &quot;父&quot;, direction = Relationship.Direction.OUTGOING)    private Organization parentOrganization;}</code></pre><h4 id="3-3-2-设置Repository"><a href="#3-3-2-设置Repository" class="headerlink" title="3.3.2 设置Repository"></a>3.3.2 设置Repository</h4><pre><code>@EnableNeo4jRepositoriespublic interface OrganizationRepository extends Neo4jRepository&lt;Organization,Long&gt; {}</code></pre><h4 id="3-3-3设置事务"><a href="#3-3-3设置事务" class="headerlink" title="3.3.3设置事务"></a>3.3.3设置事务</h4><pre><code>@Configuration@EnableNeo4jRepositories(basePackages = &quot;com.cloud.cmp.neo4j.mapper&quot;)@EnableTransactionManagementpublic class Neo4jConfig {}</code></pre><h3 id="四、数据同步"><a href="#四、数据同步" class="headerlink" title="四、数据同步"></a>四、数据同步</h3><h4 id="4-1Apoc安装"><a href="#4-1Apoc安装" class="headerlink" title="4.1Apoc安装"></a>4.1Apoc安装</h4><pre><code>APOC 是 neo4j 自带一款强大的功能组件。它引入了用户自定义过程和函数概念，某些Cypher本身不能轻易实现的自定义功能可以由 APOC 完成。它是用Java实现的，Apoc 库由许多(大约450个)过程和函数组成，用于在数据集成、图形算法或数据转换等领域帮助完成许多不同的任务。APOC依赖于Neo4j的内部api，在Neo4j时，需要使用匹配的APOC版本，确保Neo4j和APOC之间的前两个版本号匹配。</code></pre><h5 id="4-1-1下载APOC"><a href="#4-1-1下载APOC" class="headerlink" title="4.1.1下载APOC"></a>4.1.1下载APOC</h5><pre><code>在Neo4j的APOC手册中有APOC的下载地址，通过链接下载指定的APOC版本，本次选用apoc-3.5.0.11-all.jar。</code></pre><h5 id="4-1-2安装APOC"><a href="#4-1-2安装APOC" class="headerlink" title="4.1.2安装APOC"></a>4.1.2安装APOC</h5><pre><code>下载APOC的jar文件后，将jar文件复制到Neo4j的plugins目录下。</code></pre><h5 id="4-1-3修改配置文件"><a href="#4-1-3修改配置文件" class="headerlink" title="4.1.3修改配置文件"></a>4.1.3修改配置文件</h5><pre><code>在neo4j.conf 配置文件中添加：dbms.security.procedures.unrestricted=apoc.*</code></pre><h5 id="4-1-4重启Neo4j服务"><a href="#4-1-4重启Neo4j服务" class="headerlink" title="4.1.4重启Neo4j服务"></a>4.1.4重启Neo4j服务</h5><pre><code>Kill -9 25961 ./neo4j start</code></pre><h5 id="4-1-5在可视化界面运行"><a href="#4-1-5在可视化界面运行" class="headerlink" title="4.1.5在可视化界面运行"></a>4.1.5在可视化界面运行</h5><pre><code>return apoc.version(); 出现对应的版本号，证明安装成功。</code></pre><h4 id="4-2常用函数"><a href="#4-2常用函数" class="headerlink" title="4.2常用函数"></a>4.2常用函数</h4><h5 id="4-2-1-UPPER-函数"><a href="#4-2-1-UPPER-函数" class="headerlink" title="4.2.1 UPPER 函数"></a>4.2.1 UPPER 函数</h5><pre><code>UPPER 用于将所有字母更改为大写字母。Match (n:Person) return UPPER (n.name);</code></pre><h5 id="4-2-2-LOWER函数"><a href="#4-2-2-LOWER函数" class="headerlink" title="4.2.2 LOWER函数"></a>4.2.2 LOWER函数</h5><pre><code>LOWER 用于将所有字母改为小写字母。Match (n:Person) return LOWER(n.name);</code></pre><h5 id="4-2-3-SUBSTRING3函数"><a href="#4-2-3-SUBSTRING3函数" class="headerlink" title="4.2.3 SUBSTRING3函数"></a>4.2.3 SUBSTRING3函数</h5><pre><code>SUBSTRING 用于获取给定String的子字符串。Match (n:Person) return SUBSTRING(n.id,2,0),n.id;</code></pre><h5 id="4-2-4-REPLACE-函数"><a href="#4-2-4-REPLACE-函数" class="headerlink" title="4.2.4 REPLACE 函数"></a>4.2.4 REPLACE 函数</h5><pre><code>REPLAC 用于替换一个字符串的子字符串。</code></pre><h5 id="4-2-5-聚合函数"><a href="#4-2-5-聚合函数" class="headerlink" title="4.2.5 聚合函数"></a>4.2.5 聚合函数</h5><pre><code>COUNT —— 它返回由MATCH命令返回的行数。MAX —— 它从MATCH命令返回的一组行返回最大值。MIN —— 它返回由MATCH命令返回的一组行的最小值。SUM —— 它返回由MATCH命令返回的所有行的求和值。AVG —— 它返回由MATCH命令返回的所有行的平均值。</code></pre><h4 id="4-3-Neo4j-驱动程序"><a href="#4-3-Neo4j-驱动程序" class="headerlink" title="4.3 Neo4j 驱动程序"></a>4.3 Neo4j 驱动程序</h4><h5 id="4-3-1-引入pom文件"><a href="#4-3-1-引入pom文件" class="headerlink" title="4.3.1 引入pom文件"></a>4.3.1 引入pom文件</h5><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.neo4j.driver&lt;/groupId&gt;    &lt;artifactId&gt;neo4j-java-driver&lt;/artifactId&gt;    &lt;version&gt;1.5.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><h5 id="4-3-2-创建驱动程序的数据库对象"><a href="#4-3-2-创建驱动程序的数据库对象" class="headerlink" title="4.3.2 创建驱动程序的数据库对象"></a>4.3.2 创建驱动程序的数据库对象</h5><pre><code>1) 向数据库对象请求一个新的驱动程序。2) 向驱动程序对象请求一个新会。；3) 请求会话对象创建事务。4) 使用事务对象运行语句，它返回一个表示结果的对象。5) 处理结果。6) 关闭会话。  </code></pre>]]></content>
      
      
      <categories>
          
          <category> 图数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DDD领域驱动设计实现</title>
      <link href="/2023/07/20/DDD%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/"/>
      <url>/2023/07/20/DDD%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><p>领域驱动设计（Domain-driven Design，DDD）是一种软件设计方法，该方法的核心思想是将业务领域作为设计和开发的中心，强调对业务领域的深入理解、业务语言的建模以及领域对象的设计和实现。翻译成大白话就是：是一种解决复杂软件的思维方式，是一种思想；以业务为主导，自顶向下的进行业务领域划分,业务模型驱动架构设计。</p><a id="more"></a><h3 id="一、DDD设计阶段包括两部分"><a href="#一、DDD设计阶段包括两部分" class="headerlink" title="一、DDD设计阶段包括两部分"></a>一、DDD设计阶段包括两部分</h3><h4 id="1-1战略设计定义"><a href="#1-1战略设计定义" class="headerlink" title="1.1战略设计定义"></a>1.1战略设计定义</h4><pre><code>战略设计主要从业务视角出发，包括了业务场景分析、领域建模、划分边界上下文三个阶段。限界上下文可以作为微服务设计的参考边界。限界上下文可以作为微服务设计的参考边界。</code></pre><h4 id="1-2战术设计定义"><a href="#1-2战术设计定义" class="headerlink" title="1.2战术设计定义"></a>1.2战术设计定义</h4><pre><code>战术设计则从技术视角出发，侧重于领域模型的技术实现，完成软件开发和落地，战术设计包括：聚合根、实体、值对象、领域服务、应用服务和资源库等代码逻辑的技术设计和技术设计。</code></pre><h3 id="二、战略设计"><a href="#二、战略设计" class="headerlink" title="二、战略设计"></a>二、战略设计</h3><pre><code>战略设计是 DDD 过程中的核心步骤</code></pre><h4 id="2-1业务分析"><a href="#2-1业务分析" class="headerlink" title="2.1业务分析"></a>2.1业务分析</h4><pre><code>在这个阶段我们所有做的就是进行全面的业务梳理，把业务中涉及到的所有细节都梳理出来，为后续进行领域建模分析提供足够的、全面的业务输入。战略设计 经常使用到的业务场景分析方法主要包括    用例分析法    事件风暴法：        事件风暴是一项团队活动，领域专家与项目团队通过头脑风暴的形式，罗列出领域中所有的领域事件，整合之后形成最终的领域事件集合，然后对每一个事件，标注出导致该事件的命令，再为每一个事件标注出命令发起方的角色。命令可以是用户发起，也可以是第三方系统调用或者定时器触发等，最后对事件进行分类，整理出实体、聚合、聚合根以及限界上下文。而事件风暴正是 DDD 战略设计中经常使用的一种方法，它可以快速分析和分解复杂的业务领域，完成领域建模。    四色建模法</code></pre><h4 id="2-2领域建模"><a href="#2-2领域建模" class="headerlink" title="2.2领域建模"></a>2.2领域建模</h4><pre><code>DDD领域模型 细分为两步骤。    第一步是发散，产生很多实体、命令、事件等领域对象，    第二步是收敛，我们从不同的维度对进行聚类形成聚合，建立最终领域模型， 这是一个收敛的过程。</code></pre><h5 id="2-2-1发散阶段：领域对象分析"><a href="#2-2-1发散阶段：领域对象分析" class="headerlink" title="2.2.1发散阶段：领域对象分析"></a>2.2.1发散阶段：领域对象分析</h5><pre><code> 领域对象分析，也就 实体、值对象、领域事件、领域命令的分析。</code></pre><h5 id="2-2-2收敛阶段：构建业务聚合"><a href="#2-2-2收敛阶段：构建业务聚合" class="headerlink" title="2.2.2收敛阶段：构建业务聚合"></a>2.2.2收敛阶段：构建业务聚合</h5><pre><code> 完成领域对象分析之后，需要构建业务聚合。 想要构建聚合，那么首先就要在实体中找到聚合根。 聚合根的特点：    聚合根一定是实体，那么它具有全局唯一的标识，    聚合根是具备生命周期的    聚合根需要专门的模块来进行管理。</code></pre><h4 id="2-3领域建模划分边界上下文"><a href="#2-3领域建模划分边界上下文" class="headerlink" title="2.3领域建模划分边界上下文"></a>2.3领域建模划分边界上下文</h4><pre><code>获得了整个业务流程中的所有聚合后，我们需要更具业务语义上下文将具体的聚合划分到对应的上下文中，</code></pre><h3 id="三、战术设计"><a href="#三、战术设计" class="headerlink" title="三、战术设计"></a>三、战术设计</h3><pre><code>在战略设计阶段，通过事件风暴法对整体的业务进行了全部的梳理，同时构建了领域模型，以及划分了边界下文。那么接下来我们就要将领域模型映射到工程结构，以及代码中实现最终的实现落地。</code></pre><h4 id="3-1微服务拆分"><a href="#3-1微服务拆分" class="headerlink" title="3.1微服务拆分"></a>3.1微服务拆分</h4><pre><code>根据已经划分的边界上下文，拆分成微服务。</code></pre><h4 id="3-2领域分层"><a href="#3-2领域分层" class="headerlink" title="3.2领域分层"></a>3.2领域分层</h4><pre><code>在领域分层方面，可以按照cola分层结构来进行，使用cola框架进行说明。</code></pre><h4 id="3-3代码结构"><a href="#3-3代码结构" class="headerlink" title="3.3代码结构"></a>3.3代码结构</h4><pre><code> 领域对象进行进一步的细化之后，同时把对应的领域服务敲定之后，可以把这些分析后的内容映射成工程分层后的代码了。  </code></pre><h3 id="四、领域层设计"><a href="#四、领域层设计" class="headerlink" title="四、领域层设计"></a>四、领域层设计</h3><pre><code>领域模型 Model定义、分类、生命周期Model（模型）：承载着业务的属性和具体的行为，是业务表达的方式，是DDD的内核。    Model（模型）是一个类中有属性、属性有Get/Set方法，    并且业务的行为（Action）操作也是在模型类中（充血模型）    模型分为Entity、Value Object、Service这三种类型</code></pre><h4 id="4-1-Model分类"><a href="#4-1-Model分类" class="headerlink" title="4.1 Model分类"></a>4.1 Model分类</h4><pre><code>Entity (实体)    有特定的标识，标识着这个Model在系统中全局唯一    内部值可以是变化的，可能存在生命周期 (比如订单对象，状态值是连续变化的)    有状态的Value ObjectValue Object （值对象）    内部值是不变的，不存在生命周期 (比如地址对象不存在生命周期)    无状态对象Service （服务）    无状态对象    当一个属性或行为放在Entity、Value Object中模棱两可或不合适的时候就需要以Service的形式来呈现.三种模型复杂度：Service &gt; Entity &gt; ValueObject，优先选择简单模型</code></pre><h4 id="4-2Model的生命周期"><a href="#4-2Model的生命周期" class="headerlink" title="4.2Model的生命周期"></a>4.2Model的生命周期</h4><pre><code>Factory （工厂）：用来创建Model，以及帮助Repository (数据源)注入到Model中Aggreagte （聚合根）：封装Model，一个Mode中l可能包含其他Model（类似一个对象中包含其他对象的引用，实际概念更复杂）    聚合是用来封装真正的不变性，而不是简单的将对象组合在一起；    聚合应尽量设计的小；    聚合之间的关联通过ID，而不是对象引用；    聚合内强一致性，聚合之间最终一致性。Repository (数据源)：    数据源的访问网关层    Model通过Repository来对接不同的数据源</code></pre><h3 id="五、ECS架构"><a href="#五、ECS架构" class="headerlink" title="五、ECS架构"></a>五、ECS架构</h3><pre><code>Entity：用来代表任何一个游戏对象，但是在ECS里一个Entity最重要的仅仅是他的EntityID，一个Entity里包含多个ComponentComponent：       是真正的数据，ECS架构把一个个的实体对象拆分为更加细化的组件，比如位置、素材、状态等，也就是说一个Entity实际上只是一个Bag of Components。System（或者ComponentSystem，组件系统）：        是真正的行为，一个游戏里可以有很多个不同的组件系统，每个组件系统都只负责一件事，可以依次处理大量的相同组件，而不需要去理解具体的Entity。    所以一个ComponentSystem理论上可以有更加高效的组件处理效率，甚至可以实现并行处理，从而提升CPU利用率。 ECS的一些核心性能优化包括将同类型组件放在同一个Array中，然后Entity仅保留到各自组件的pointer，这样能更好的利用CPU的缓存，减少数据的加载成本，以及SIMD的优化等。public class Entity {    public Vector position; // 此处Vector是一个Component, 指向的是MovementSystem.list里的一个    }    public class MovementSystem {    List&lt; Vector&gt; list;    // System的行为    public void update(float delta) {        for(Vector pos : list) { // 这个loop直接走了CPU缓存，性能很高，同时可以用SIMD优化        pos.x = pos.x + delta;        pos.y = pos.y + delta;        }    }}@Testpublic void test() {    MovementSystem system = new MovementSystem();    system.list = new List&lt;&gt;() { new Vector(0, 0) };    Entity entity = new Entity(list.get(0));    system.update(0.1);    assertTrue(entity.position.x == 0.1);}</code></pre><h3 id="六、DDD领域层的一些设计规范"><a href="#六、DDD领域层的一些设计规范" class="headerlink" title="六、DDD领域层的一些设计规范"></a>六、DDD领域层的一些设计规范</h3><pre><code>基于继承关系的OOP代码：    OOP的代码最好写，也最容易理解，所有的规则代码都写在对象里，但是当领域规则变得越来越复杂时，其结构会限制它的发展。    新的规则有可能会导致代码的整体重构。基于组件化的ECS代码：    ECS代码有最高的灵活性、可复用性、及性能，但极具弱化了实体类的内聚，所有的业务逻辑都写在了服务里，会导致业务的一致性无法保障，对商业系统会有较大的影响。基于领域对象 + 领域服务的DDD架构：     DDD的规则其实最复杂，同时要考虑到实体类的内聚和保证不变性（Invariants），也要考虑跨对象规则代码的归属，甚至要考虑到具体领域服务的调用方式，理解成本比较高。尽量通过一些设计规范，来降低DDD领域层的设计成本。</code></pre><h4 id="6-1实体类（Entity）"><a href="#6-1实体类（Entity）" class="headerlink" title="6.1实体类（Entity）"></a>6.1实体类（Entity）</h4><pre><code>大多数DDD架构的核心都是实体类，实体类包含了两块大的内容    领域里的状态    以及对状态操作Entity最重要的设计原则是保证实体的一致性，也就是说要确保无论外部怎么操作，一个实体内部的属性都不能出现相互冲突，状态不一致的情况。实体设计原则如下：    创建即一致        constructor参数要包含所有必要属性，或者在constructor里有合理的默认值。        使用Factory模式来降低调用方复杂度    尽量避免public setter        因为set单一参数会导致状态不一致的情况；        @ Setter(AccessLevel.PRIVATE) // 确保不生成public setter    通过聚合根保证父子实体的一致性        子实体不能单独存在，只能通过聚合根的方法获取到。任何外部的对象都不能直接保留子实体的引用        子实体没有独立的Repository，不可以单独保存和取出，必须要通过聚合根的Repository实例化        子实体可以单独修改自身状态，但是多个子实体之间的状态一致性需要聚合根来保障    不可以强依赖其他聚合根实体或领域服务        只保存外部实体的ID：强烈建议使用强类型的ID对象，而不是Long型ID。强类型的ID对象不单单能自我包含验证代码，保证ID值的正确性，同时还能确保各种入参不会因为参数顺序变化而出bug。        针对于“无副作用”的外部依赖，通过方法入参的方式传入      任何实体的行为只能直接影响到本实体（和其子实体）</code></pre><h3 id="七、四层架构模式"><a href="#七、四层架构模式" class="headerlink" title="七、四层架构模式"></a>七、四层架构模式</h3><pre><code>    User Interface为用户界面层（对外访问层API），负责向用户显示信息和解释用户命令。    Application为应用层，定义软件要完成的任务，并且指挥表达领域概念的对象来解决问题。    Domain为领域层（或模型层），负责表达业务概念，业务状态信息以及业务规则。    Infrastructure层为基础实施层，向其他层提供通用的技术能力。</code></pre><h4 id="7-1接口层的组成"><a href="#7-1接口层的组成" class="headerlink" title="7.1接口层的组成"></a>7.1接口层的组成</h4><pre><code>   网络协议的转化：通常这个已经由各种框架给封装掉了，我们需要构建的类要么是被注解的bean，要么是继承了某个接口的bean。    统一鉴权：比如在一些需要AppKey+Secret的场景，需要针对某个租户做鉴权的，包括一些加密串的校验    Session管理：一般在面向用户的接口或者有登陆态的，通过Session或者RPC上下文可以拿到当前调用的用户，以便传递给下游服务。    限流配置：对接口做限流避免大流量打到下游服务    前置缓存：针对变更不是很频繁的只读场景，可以前置结果缓存到接口层    异常处理：通常在接口层要避免将异常直接暴露给调用端，所以需要在接口层做统一的异常捕获，转化为调用端可以理解的数据格式    日志：在接口层打调用日志，用来做统计和debug等。一般微服务框架可能都直接包含了这些功能。</code></pre><h4 id="7-2-应用层"><a href="#7-2-应用层" class="headerlink" title="7.2 应用层"></a>7.2 应用层</h4><pre><code>    ApplicationService应用服务：最核心的类，负责业务流程的编排，但本身不负责任何业务逻辑。    DTO Assembler：负责将内部领域模型转化为可对外的DTO。    Command、Query、Event对象：作为ApplicationService的入参。    返回的DTO：作为ApplicationService的出参。</code></pre>]]></content>
      
      
      <categories>
          
          <category> DDD领域驱动设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD领域驱动设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DDD领域驱动设计架构</title>
      <link href="/2023/07/18/DDD%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E6%9E%B6%E6%9E%84/"/>
      <url>/2023/07/18/DDD%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><p>领域驱动设计（Domain-driven Design，DDD）是一种软件设计方法，该方法的核心思想是将业务领域作为设计和开发的中心，强调对业务领域的深入理解、业务语言的建模以及领域对象的设计和实现。翻译成大白话就是：是一种解决复杂软件的思维方式，是一种思想；以业务为主导，自顶向下的进行业务领域划分,业务模型驱动架构设计。</p><a id="more"></a><h3 id="一、基础概念"><a href="#一、基础概念" class="headerlink" title="一、基础概念"></a>一、基础概念</h3><h4 id="1-1领域"><a href="#1-1领域" class="headerlink" title="1.1领域"></a>1.1领域</h4><pre><code>  领域就是用来确定范围的，范围即边界，这也是 DDD 在设计中不断强调边界的原因。  简言之，DDD 的领域就是这个边界内要解决的业务问题域。  领域可以进一步划分为子领域。我们把划分出来的多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围。领域可以拆分为多个子领域。一个领域相当于一个问题域，领域拆分为子域的过程就是大问题拆分为小问题的过程。  领域不断划分的过程中，领域会细分为不同的子域，子域可以根据自身重要性和功能属性划分为三类子域，它们分别是：核心域、通用域和支撑域。  核心域，它是业务成功的主要因素和公司的核心竞争力。没有太多个性化的诉求，同时被多个子域使用的通用功能子域是通用域。还有一种功能子域是必需的，但既不包含决定产品和公司核心竞争力的功能，也不包含通用功能的子域，它就是支撑域。</code></pre><h4 id="1-2限界上下文"><a href="#1-2限界上下文" class="headerlink" title="1.2限界上下文"></a>1.2限界上下文</h4><pre><code> 限界就是领域的边界，而上下文则是语义环境。通过领域的限界上下文，我们就可以在统一的领域边界内用统一的语言进行交流，简单来说限界上下文可以理解为语义环境。 限界上下文的定义就是：用来封装通用语言和领域对象，提供上下文环境，保证在领域之内的一些术语、业务相关对象等（通用语言）有一个确切的含义，没有二义性。 理论上限界上下文就是微服务的边界。我们将限界上下文内的领域模型映射到微服务，就完成了从问题域到软件的解决方案。  遵守以下规范：     同限界上下文内的聚合之间的领域服务可直接调用。     两个限界上下文的交互必须通过应用服务层抽离 接口-&gt;适配层 适配。  限界上下文之间的映射关系：     合作关系（Partnership）：两个上下文紧密合作的关系，一荣俱荣，一损俱损。     共享内核（Shared Kernel）：两个上下文依赖部分共享的模型。     客户方-供应方开发（Customer-Supplier Development）：上下文之间有组织的上下游依赖。     遵奉者（Conformist）：下游上下文只能盲目依赖上游上下文。     防腐层（Anticorruption Layer）：一个上下文通过一些适配和转换与另一个上下文交互。     开放主机服务（Open Host Service）：定义一种协议来让其他上下文来对本上下文进行访问。     发布语言（Published Language）：通常与OHS一起使用，用于定义开放主机的协议。     大泥球（Big Ball of Mud）：混杂在一起的上下文关系，边界不清晰。     另谋他路（SeparateWay）：两个完全没有任何联系的上下文。</code></pre><h3 id="二、贫血模型和充血模型"><a href="#二、贫血模型和充血模型" class="headerlink" title="二、贫血模型和充血模型"></a>二、贫血模型和充血模型</h3><h4 id="2-1贫血模型"><a href="#2-1贫血模型" class="headerlink" title="2.1贫血模型"></a>2.1贫血模型</h4><pre><code>  贫血模型具有一堆属性和set get方法，存在的问题就是通过 pojo 这个对象上看不出业务有哪些逻辑，一个 pojo 可能被多个模块调用，只能去上层各种各样的service 来调用，这样以后当梳理这个实体有什么业务，只能一层一层去搜 service，也就是贫血失忆症，不够面向对象。</code></pre><h4 id="2-2充血模型"><a href="#2-2充血模型" class="headerlink" title="2.2充血模型"></a>2.2充血模型</h4><pre><code>  如 user 用户有改密码，改手机号，修改登录失败次数等操作，都内聚在这个 user 实体中，每个实体的业务都是清晰的，就是充血模型，充血模型的内存计算会多一些，内聚核心业务逻辑处理。  说白了就是，不只是有贫血模型中的setter getter方法，还有其他的一些业务方法，这才是面向对象的本质，通过 user 实体就能看出有哪些业务存在。</code></pre><h3 id="三、实体和值对象"><a href="#三、实体和值对象" class="headerlink" title="三、实体和值对象"></a>三、实体和值对象</h3><p>   实体和值对象这两个概念都是领域模型中的领域对象。实体和值对象是组成领域模型的基础单元。</p><h4 id="3-1实体"><a href="#3-1实体" class="headerlink" title="3.1实体"></a>3.1实体</h4><p>   在代码模型中，实体的表现形式是实体类，这个类包含了实体的属性和方法，通过这些方法实现实体自身的业务逻辑。<br>   在 DDD 里，这些实体类通常采用充血模型，与这个实体相关的所有业务逻辑都在实体类的方法中实现，跨多个实体的领域逻辑则在领域服务中实现。<br>   实体以 DO（领域对象）的形式存在，每个实体对象都有唯一的 ID。<br>   在领域模型映射到数据模型时，一个实体可能对应 0 个、1 个或者多个数据库持久化对象。</p><p>   实体特性：<br>      具有唯一标识<br>      持久化<br>      可变</p><h4 id="3-2值对象"><a href="#3-2值对象" class="headerlink" title="3.2值对象"></a>3.2值对象</h4><pre><code>简单来说，值对象本质上就是一个集。</code></pre><p>   人员实体原本包括：姓名、年龄、性别以及人员所在的省、市、县等属性。这样显示地址相关的属性就很零碎了，可以将“省、市、县等属性”拿出来构成一个“地址属性集合”，这个集合就是值对象了。</p><p>   值对象拥有以下特征：<br>      它度量或者描述了领城中的一件东西。<br>      它可以作为不变量。<br>      度量和描述改变时，可以用另一个值对象予以替换。<br>      它可以和其他值对象进行相等性比较。<br>      它不会对协作对象造成副作用。</p><p>   值对象与实体一起构成聚合。值对象逻辑上是实体属性的一部分，用于描述实体的特征。值对象创建后就不允许修改了，只能用另外一个值对象来整体替换。</p><h4 id="3-3聚合"><a href="#3-3聚合" class="headerlink" title="3.3聚合"></a>3.3聚合</h4><p>   实体和值对象是很基础的领域对象。实体一般对应业务对象，它具有业务属性和业务行为；而值对象主要是属性集合，对实体的状态和特征进行描述。但实体和值对象都只是个体化的对象，它们的行为表现出来的是个体的能力。</p><p>   聚合就是由业务和逻辑紧密关联的实体和值对象组合而成的，聚合是数据修改和持久化的基本单元，每一个聚合对应一个仓储，实现数据的持久化。</p><p>   聚合在 DDD 分层架构里属于领域层，领域层包含了多个聚合，共同实现核心业务逻辑。</p><h4 id="3-4聚合根"><a href="#3-4聚合根" class="headerlink" title="3.4聚合根"></a>3.4聚合根</h4><p>   首先它作为实体本身，拥有实体的属性和业务行为，实现自身的业务逻辑。其次它作为聚合的管理者，在聚合内部负责协调实体和值对象按照固定的业务规则协同完成共同的业务逻辑。</p><p>   以聚合根 ID 关联的方式接受外部任务和请求，在上下文内实现聚合之间的业务协同。也就是说，聚合之间通过聚合根 ID 关联引用，如果需要访问其它聚合的实体，就要先访问聚合根，再导航到聚合内部实体，外部对象不能直接访问聚合内实体。</p><h4 id="3-5领域服务"><a href="#3-5领域服务" class="headerlink" title="3.5领域服务"></a>3.5领域服务</h4><p>   一些重要的领域行为或操作，可以归类为领域服务。<br>   它既不是实体，也不是值对象的范畴。</p><h4 id="3-6领域事件"><a href="#3-6领域事件" class="headerlink" title="3.6领域事件"></a>3.6领域事件</h4><p>   领域事件可以是业务流程的一个步骤。<br>   一个完整的领域事件 = 事件发布 + 事件存储 + 事件分发 + 事件处理。</p><p>   事件发布：构建一个事件，需要唯一标识，然后发布；<br>   事件存储：发布事件前需要存储，因为接收后的事件也会存储，可用于重试或对账等；就是每次执行一次具体的操作时，把行为记录下来，执行持久化。<br>   事件分发：服务内的应用服务或者领域服务直接发布给订阅者，服务外需要借助消息中间件，比如Kafka，RabbitMQ等，支持同步或者异步。<br>   事件处理：先将事件存储，然后再处理。</p><p>   实际开发中事件存储和事件处理不是必须的</p><h4 id="3-7工厂模式"><a href="#3-7工厂模式" class="headerlink" title="3.7工厂模式"></a>3.7工厂模式</h4><p>   在创建对象时，有些聚合需要实体或值对象较多，或者关系比较复杂，为了确保聚合内所有对象都能同时被创建，同时避免在聚合根中加入与其本身领域无关的内容，一般会将这些内容交给Factory处理。</p><p>   Factory的主要作用：封装聚合内复杂对象的创建过程，完成聚合根、实体、值对象的创建。</p><h4 id="3-8仓储模式"><a href="#3-8仓储模式" class="headerlink" title="3.8仓储模式"></a>3.8仓储模式</h4><p>   为了避免基础层数据处理逻辑渗透到领域层的业务代码中，导致领域层和基础层形成紧密耦合关系，引入Repository层。</p><p>   Repository分为Interface和Implement，领域层依赖Repository接口。</p><h3 id="四、DDD分层架构"><a href="#四、DDD分层架构" class="headerlink" title="四、DDD分层架构"></a>四、DDD分层架构</h3><p>   DDD 的分层架构在不断发展。最早是传统的四层架构；再后来领域层和应用层之间增加了上下文环境（Context）层，五层架构（DCI）就此形成了。<br><img src="/image/DDD4%E5%B1%82.png" alt="效果图预览"><br>    DDD分层架构中的要素其实和三层架构类似，只是在DDD分层架构中，这些要素被重新归类，重新划分了层，确定了层与层之间的交互规则和职责边界。<br><img src="/image/DDD%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB.png" alt="效果图预览"> </p><p>   用户接口层<br>      用户接口层是前端应用和微服务之间服务访问和数据交换的桥梁。它处理前端发送的 Restful 请求和解析用户输入的配置文件等，将数据传递给应用层。或获取应用服务的数据后，进行数据组装，向前端提供数据服务。主要服务形态是 Facade 服务。</p><pre><code>  Facade 服务分为接口和实现两个部分。完成服务定向，DO 与 DTO 数据的转换和组装，实现前端与应用层数据的转换和交换。     一般包括用户接口、Web 服务、rpc请求，mq消息等外部输入均被视为外部输入的请求。对外暴露API，具体形式不限于RPC、Rest API、消息等。     一般都很薄，提供必要的参数校验和异常捕获流程。     一般会提供VO或者DTO到Entity或者ValueObject的转换，用于前后端调用的适配，当然dto可以直接使用command和query，视情况而定。  用户接口层很重要，在于前后端调用的适配。若你的微服务要面向很多应用或渠道提供服务，而每个渠道的入参出参都不一样，你不太可能开发出太多应用服务，这样Facade接口就起很好的作用了，包括DO和DTO对象的组装和转换等。</code></pre><p>   应用层<br>      应用层是很薄的一层，理论上不应该有业务规则或逻辑，主要面向用例和流程相关的操作。但应用层又位于领域层之上，因为领域层包含多个聚合，所以它可以协调多个聚合的服务和领域对象完成服务编排和组合，协作完成业务操作。除了同步方法调用外，还可以发布或者订阅领域事件，权限校验、事务控制，一个事务对应一个聚合根。</p><pre><code>  应用层负责不同聚合之间的服务和数据协调，负责微服务之间的事件发布和订阅。  通过应用服务对外暴露微服务的内部功能，这样就可以隐藏领域层核心业务逻辑的复杂性以及内部实现机制。  应用层的主要服务形态有：应用服务、事件发布和订阅服务。应用服务内用于组合和编排的服务，主要来源于领域服务，也可以是外部微服务的应用服务。</code></pre><p>   领域层<br>      领域层包含聚合根、实体、值对象、领域服务等领域模型中的领域对象。</p><pre><code>  特别解释一下其中几个领域对象的关系，以便你在设计领域层的时候能更加清楚。  首先，领域模型的业务逻辑主要是由实体和领域服务来实现的，其中实体会采用充血模型来实现所有与之相关的业务功能。  其次，实体和领域对象在实现业务逻辑上不是同级的，当领域中的某些功能，单一实体（或者值对象）不能实现时，领域服务就会出马，它可以组合聚合内的多个实体（或者值对象），实现复杂的业务逻辑。  领域层主要的服务形态有实体方法和领域服务。实体采用充血模型，在实体类内部实现实体相关的所有业务逻辑，实现的形式是实体类中的方法。实体是微服务的原子业务逻辑单元。在设计时我们主要考虑实体自身的属性和业务行为，实现领域模型的核心基础能力。不必过多考虑外部操作和业务流程，这样才能保证领域模型的稳定性。  DDD 提倡富领域模型，尽量将业务逻辑归属到实体对象上，实在无法归属的部分则设计成领域服务。  领域服务会对多个实体或实体方法进行组装和编排，实现跨多个实体的复杂核心业务逻辑。对于严格分层架构，如果单个实体的方法需要对应用层暴露，则需要通过领域服务封装后才能暴露给应用服务。</code></pre><p>   基础层<br>      基础层也叫基础设施层，基础层是贯穿所有层的，它的作用就是为其它各层提供通用的技术和基础服务，包括第三方工具、驱动、消息中间件、网关、文件、缓存以及数据库等，比较常见的功能还是提供数据库持久化。</p><pre><code>  基础层的服务形态主要是仓储服务。仓储服务包括接口和实现两部分。仓储接口服务供应用层或者领域层服务调用，仓储实现服务，完成领域对象的持久化或数据初始化。  DDD分层架构的数据库等基础资源访问，采用了仓储（Repository）设计模式，通过依赖到置实现各层对基础资源的解耦。  仓储又分为两部分：仓储接口和仓储实现。     仓储接口放在领域层中，仓储实现放在基础层。原来三层架构通用的第三方工具包、驱动、Common、Utility、Config等通用的公共的资源类统一放到了基础层。     在传统架构设计中，由于上层应用对数据库的强耦合，很多公司在架构演进中最担忧的可能就是换数据库了，因为一旦更换数据库，就可能需要重写大部分的代码，这对应用来说是致命的。那采用依赖倒置的设计以后应用层就可以通过解耦来保持独立的核心业务。</code></pre><p>   防腐层:<br>      解决方案就是在两个系统之间加入一个中间层，隔离第三方系统的依赖，对第三方系统进行通讯转换和语义隔离，这个中间层，叫它防腐层。<br><img src="/image/DDD%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8.jpg" alt="效果图预览"> </p><h3 id="五、领域事件驱动"><a href="#五、领域事件驱动" class="headerlink" title="五、领域事件驱动"></a>五、领域事件驱动</h3><p>   领域事件驱动包括微服务内和微服务之间的事件。微服务内通过事件总线（EventBus）完成聚合之间的异步处理。微服务之间通过消息中间件完成。异步化的领域事件驱动机制是一种间接的服务访问方式。当应用服务业务逻辑处理完成后，如果发生领域事件，可调用事件发布服务，完成事件发布。当接收到订阅的主题数据时，事件订阅服务会调用事件处理领域服务，完成进一步的业务操作。</p><h3 id="六、服务依赖"><a href="#六、服务依赖" class="headerlink" title="六、服务依赖"></a>六、服务依赖</h3><p>   DDD 分层架构有一个重要的原则：每层只能与位于其下方的层发生耦合。<br>   在严格分层架构中，领域服务只能被应用服务调用，而应用服务只能被用户接口层调用，服务是逐层对外封装或组合的，依赖关系清晰。</p><h3 id="七、服务封装"><a href="#七、服务封装" class="headerlink" title="七、服务封装"></a>七、服务封装</h3><p>   在严格分层架构模式下，不允许服务的跨层调用，每个服务只能调用它的下一层服务。服务从下到上依次为：实体方法、领域服务、应用服务和接口服务。如果需要实现服务的跨层调用，建议采用服务逐层封装的方式。</p><h3 id="八、实体方法的封装"><a href="#八、实体方法的封装" class="headerlink" title="八、实体方法的封装"></a>八、实体方法的封装</h3><pre><code>  实体方法是最底层的原子业务逻辑。如果单一实体的方法需要被跨层调用，你可以将它封装成领域服务，这样封装的领域服务就可以被应用服务调用和编排了。如果它还需要被用户接口层调用，你还需要将这个领域服务封装成应用服务。经过逐层服务封装，实体方法就可以暴露给上面不同的层，实现跨层调用。  封装时服务前面的名字可以保持一致，可以用 DomainService 或 *AppService 后缀来区分领域服务或应用服务。</code></pre><h3 id="九、领域服务的组合和封装"><a href="#九、领域服务的组合和封装" class="headerlink" title="九、领域服务的组合和封装"></a>九、领域服务的组合和封装</h3><p>   领域服务会对多个实体和实体方法进行组合和编排，供应用服务调用。如果它需要暴露给用户接口层，领域服务就需要封装成应用服务。</p><h3 id="十、应用服务的组合和编排"><a href="#十、应用服务的组合和编排" class="headerlink" title="十、应用服务的组合和编排"></a>十、应用服务的组合和编排</h3><p>   应用服务会对多个领域服务进行组合和编排，暴露给用户接口层，供前端应用调用。</p><p>   在应用服务组合和编排时，需要关注一个现象：多个应用服务可能会对多个同样的领域服务重复进行同样业务逻辑的组合和编排。当出现这种情况时，你就需要分析是不是领域服务可以整合了。你可以将这几个不断重复组合的领域服务，合并到一个领域服务中实现。这样既省去了应用服务的反复编排，也实现了服务的演进。这样领域模型将会越来越精炼，更能适应业务的要求。</p><pre><code>应用服务类放在应用层 Service 目录结构下。领域事件的发布和订阅类放在应用层 Eve</code></pre><h3 id="十一、DDD建模步骤"><a href="#十一、DDD建模步骤" class="headerlink" title="十一、DDD建模步骤"></a>十一、DDD建模步骤</h3><p>   设计领域模型的一般步骤如下：<br>      根据需求划分出初步的领域和限界上下文，以及上下文之间的关系。<br>      进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象。<br>      对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根。<br>      为聚合根设计仓储，并思考实体或值对象的创建方式。<br>      在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构。</p><h3 id="十二、DDD代码模型"><a href="#十二、DDD代码模型" class="headerlink" title="十二、DDD代码模型"></a>十二、DDD代码模型</h3><p>   微服务—级目录是按照DDD分层架构的分层职责来定义的。在代码模型里分别为用户接口层、应用层、领域层和基础层，分别建立了interfaces、application、domain 和 infrastructure 四个—级代码目录。</p><p>   Interfaces（用户接口层）∶它主要存放用户接口层与前端交互、展现数据相关的代码。前端应用通过这一层的接口，向应用服务获取展现所需的数据。这一层主要用来处理用户发送的Restful请求，解析用户输入的配置文件，并将数据传递给Application层。数据的组装、数据传输格式以及Facade接口等代码都会放在这一层目录里。<br>   Application（应用层）︰它主要存放应用层服务组合和编排相关的代码。应用服务向下基于微服务内的领域服务或外部微服务的应用服务完成服务的编排和组合，向上为用户接口层提供各种应用数据展现支持服务。应用服务和事件等代码会放在这一层目录里。<br>   Domain（领域层）︰它主要存放领域层核心业务逻辑相关的代码。领域层可以包含多个聚合代码包，它们共同实现领域模型的核心业务逻辑。聚合以及聚合内的实体、方法、领域服务和事件等代码会放在这一层目录里。<br>   Infrastructure（基础层）∶它主要存放基础资源服务相关的代码，为其它各层提供的通用技术能力、三方软件包、数据库服务、配置和基础资源服务的代码都会放在这一层目录里。</p><h4 id="12-1用户接口层"><a href="#12-1用户接口层" class="headerlink" title="12.1用户接口层"></a>12.1用户接口层</h4><p>   Interfaces 的代码目录结构有：assembler、dto 和 facade 三类。<br>      Assembler：实现 DTO 与领域对象之间的相互转换和数据交换。一般来说 Assembler 与DTO 总是一同出现。<br>      DTO：它是数据传输的载体，内部不存在任何业务逻辑，我们可以通过 DTO 把内部的领域对象与外界隔离。<br>      Facade：提供较粗粒度的调用接口，将用户请求委派给一个或多个应用服务进行处理。</p><h4 id="12-2应用层"><a href="#12-2应用层" class="headerlink" title="12.2应用层"></a>12.2应用层</h4><p>   Application 的代码目录结构有：event 和 service。</p><pre><code>  Event（事件）：这层目录主要存放事件相关的代码。它包括两个子目录：publish 和subscribe。前者主要存放事件发布相关代码，后者主要存放事件订阅相关代码（事件处理相关的核心业务逻辑在领域层实现）。  Service（应用服务）：这层的服务是应用服务。应用服务会对多个领域服务或外部应用服务进行封装、编排和组合，对外提供粗粒度的服务。应用服务主要实现服务组合和编排，是一段独立的业务逻辑。你可以将所有应用服务放在一个应用服务类里，也可以把一个应用服务设计为一个应用服务类，以防应用服务类代码量过大。</code></pre><h4 id="12-3领域层"><a href="#12-3领域层" class="headerlink" title="12.3领域层"></a>12.3领域层</h4><p>   Domain 是由一个或多个聚合包构成，共同实现领域模型的核心业务逻辑。聚合内的代码模型是标准和统一的，包括：entity、event、repository 和 service 四个子目录。</p><pre><code>  Aggregate（聚合）：它是聚合软件包的根目录，可以根据实际项目的聚合名称命名，比如权限聚合。在聚合内定义聚合根、实体和值对象以及领域服务之间的关系和边界。聚合内实现高内聚的业务逻辑，它的代码可以独立拆分为微服务。以聚合为单位的代码放在一个包里的主要目的是为了业务内聚，而更大的目的是为了以后微服务之间聚合的重组。聚合之间清晰的代码边界，可以让你轻松地实现以聚合为单位的微服务重组，在微服务架构演进中有着很重要的作用。  Entity（实体）：它存放聚合根、实体、值对象以及工厂模式（Factory）相关代码。实体类采用充血模型，同一实体相关的业务逻辑都在实体类代码中实现。跨实体的业务逻辑代码在领域服务中实现。  Event（事件）：它存放事件实体以及与事件活动相关的业务逻辑代码。  Service（领域服务）：它存放领域服务代码。一个领域服务是多个实体组合出来的一段业务逻辑。你可以将聚合内所有领域服务都放在一个领域服务类中，你也可以把每一个领域服务设计为一个类。如果领域服务内的业务逻辑相对复杂，我建议你将一个领域服务设计为一个领域服务类，避免由于所有领域服务代码都放在一个领域服务类中，而出现代码臃肿的问题。领域服务封装多个实体或方法后向上层提供应用服务调用。  Repository（仓储）：它存放所在聚合的查询或持久化领域对象的代码，通常包括仓储接口和仓储实现方法。为了方便聚合的拆分和组合，我们设定了一个原则：一个聚合对应一个仓储。</code></pre><h4 id="12-4基础层"><a href="#12-4基础层" class="headerlink" title="12.4基础层"></a>12.4基础层</h4><p>   Infrastructure 的代码目录结构有：config 和 util 两个子目录。<br>      Config：主要存放配置相关代码。<br>      Util：主要存放平台、开发框架、消息、数据库、缓存、文件、总线、网关、第三方类库、通用算法等基础代码，你可以为不同的资源类别建立不同的子目录。</p><h3 id="十三、目录结构"><a href="#十三、目录结构" class="headerlink" title="十三、目录结构"></a>十三、目录结构</h3><pre><code>  │  │    ├─interface   用户接口层   │    │    └─controller    控制器，对外提供（Restful）接口  │    │    └─facade        外观模式，对外提供本地接口和dubbo接口  │    │    └─mq            mq消息，消费者消费外部mq消息  │    │   │    ├─application 应用层  │    │    ├─assembler     装配器  │    │    ├─dto           数据传输对象，xxxCommand/xxxQuery/xxxVo       │    │    │    ├─command  接受增删改的参数  │    │    │    ├─query    接受查询的参数  │    │    │    ├─vo       返回给前端的vo对象  │    │    ├─service       应用服务，负责领域的组合、编排、转发、转换和传递  │    │    ├─repository    查询数据的仓库接口  │    │    ├─listener      事件监听定义  │    │   │    ├─domain      领域层  │    │    ├─entity        领域实体  │    │    ├─valueobject   领域值对象  │    │    ├─service       领域服务  │    │    ├─repository    仓库接口，增删改的接口  │    │    ├─acl           防腐层接口  │    │    ├─event         领域事件  │    │   │    ├─infrastructure  基础设施层  │    │    ├─converter     实体转换器  │    │    ├─repository    仓库  │    │    │    ├─impl     仓库实现  │    │    │    ├─mapper   mybatis mapper接口  │    │    │    ├─po       数据库orm数据对象   │    │    ├─ack           实体转换器  │    │    ├─mq            mq消息  │    │    ├─cache         缓存  │    │    ├─util          工具类  │    │      │    </code></pre><h3 id="十四、对象转化"><a href="#十四、对象转化" class="headerlink" title="十四、对象转化"></a>十四、对象转化</h3><pre><code>  基础层     基础层的主要对象是 PO 对象。我们需要先建立 DO 和 PO 的映射关系。当 DO 数据需要持久化时，仓储服务会将 DO 转换为 PO 对象，完成数据库持久化操作。当 DO 数据需要初始化时，仓储服务从数据库获取数据形成 PO 对象，并将 PO 转换为 DO，完成数据初始化。大多数情况下 PO 和 DO 是一一对应的。但也有 DO 和 PO 多对多的情况，在 DO 和 PO数据转换时，需要进行数据重组  领域层     领域层的主要对象是 DO 对象。DO 是实体和值对象的数据和业务行为载体，承载着基础的核心业务逻辑。通过 DO 和 PO 转换，我们可以完成数据持久化和初始化。  应用层     应用层的主要对象是 DO 对象。如果需要调用其它微服务的应用服务，DO 会转换为DTO，完成跨微服务的数据组装和传输。用户接口层先完成 DTO 到 DO 的转换，然后应用服务接收 DO 进行业务处理。如果 DTO 与 DO 是一对多的关系，这时就需要进行 DO数据重组。  用户接口层     用户接口层会完成 DO 和 DTO 的互转，完成微服务与前端应用数据交互及转换。Facade服务会对多个 DO 对象进行组装，转换为 DTO 对象，向前端应用完成数据转换和传输。  前端应用     前端应用主要是 VO 对象。展现层使用 VO 进行界面展示，通过用户接口层与应用层采用DTO 对象进行数据交互。</code></pre>]]></content>
      
      
      <categories>
          
          <category> DDD领域驱动设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD领域驱动设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Arthas</title>
      <link href="/2023/06/18/Arthas/"/>
      <url>/2023/06/18/Arthas/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><h3 id="远程Debug操作步骤"><a href="#远程Debug操作步骤" class="headerlink" title="远程Debug操作步骤"></a>远程Debug操作步骤</h3><p>想要远程Debug需要确认本地与环境中的代码保持一致</p><p>接下来是远程debug的步骤，首先修改启动脚本，找到后台启动的shell命令，</p><p>在命令java后插入命令：</p><p>-Xdebug -Xrunjdwp:transport=dt_socket,address=7777,server=y,suspend=n，</p><p>-Xdebug</p><p>激活调试</p><p>-Xrunjdwp</p><p>并且指定要进行的连接的类别。transport=dt_socket选项告知调试程序要使用哪一种传输机制。指定 dt_socket选项使调试程序能够监听传入客户机连接</p><p>address</p><p>调试通信使用的 TCP端口号</p><p>server</p><p>JVM正在调试模式下运行</p><p>suspend</p><p>指示在建立调试程序连接之前服务器不保持等待。如果使用 suspend=y选项，则在执行开始时，应用程序服务器将暂停并且保持等待，直到调试程序连接到它为止。</p><p>然后重启服务，配置IDEA</p><p>选中Configurations，选择 + 号，选择remote JVM debug，为服务命名，输入要远程连接的ip和端口号，其中端口号指的是启动脚本里设置的地址，配置好之后点击debug即可。</p><p><img src="/image/debug%E9%85%8D%E7%BD%AE.png" alt="效果图预览"></p><p>远程debug调试虽然方便，但有个很致命的问题，就是需要重启服务，只能用于测试开发，不能再线上使用，下面来说一下Arthas，不用停止服务就可诊断问题的工具。</p><h3 id="Arthas文档"><a href="#Arthas文档" class="headerlink" title="Arthas文档"></a>Arthas文档</h3><p>简介<br>Arthas是一款线上监控诊断产品，通过全局视角实查看Java应用load、内存、gc、线程的状态信息，并能够在不修改应用代码的情况下，对业务问题进行诊断，包括查看方法调用的出入参，异常，检测方法执行好事，类加载信息等，大大提升线上问题排查效率。</p><p>处理问题流程   arthas黏连问题服务，通过dashboard查看STAT异常的，或者CPU占用率过高的线程的ID，通过thread 命令查看详情或者直接查看繁忙的线程情况，找到线程详情可以直接反编译分析问题，也可以使用trace查看方法的调用路径，或者使用stack查看被引用路径，最后找到最耗时的地方，jab反编译，分析代码问题</p><p>安装<br>当电脑可以访问公网的时候</p><p>curl -0 <a href="https://arthas.aliyun.com/arthas-boot.jar" target="_blank" rel="noopener">https://arthas.aliyun.com/arthas-boot.jar</a></p><p>启动/退出<br>启动arthas</p><p>java –jar arthas-boot.jar</p><p>启动之后，会出现服务列表选择，选择编号即可绑定目标进程，输入命令执行</p><p>除了在服务器上进行操作外，还可以进行远程连接Arthas，Arthas目前支持Web Console，我们可以通过浏览器访问Arthas。</p><p>通过Linux命令jps，找到对应的pid，然后绑定Arthas，之后就可以通过浏览器访问Arthas了。</p><p>默认情况下，arthas 只 listen 127.0.0.1，所以如果想从远程连接（比如在本地浏览器访问服务器上的arthas），则可以在启动服务器上的arthas时使用 –target-ip参数指定 listen 的 IP命令，命令启动之后，使用浏览器访问 <a href="http://10.253.41.66:8563即可" target="_blank" rel="noopener">http://10.253.41.66:8563即可</a></p><p>使用远程连接退出的时候需要注意，如果在服务器上，使用exist命令即可退出，但在远程连接上使用exist命令依旧可以退出，但如果再次访问，仍会访问成功，可以使用stop命令，进行关闭远程连接。</p><p>刷新后，依旧访问成功</p><p>使用stop命令</p><p>再次刷新后，无法访问成功</p><p>查看JVM信息<br>命令</p><p>jvm</p><p>内存使用情况<br>命令</p><p>memory</p><p>watch<br>查看指定函数的调用情况，包括，返回值，跑出异常，入参，通过编写OGNL表达式进行应对变量的查看</p><p>命令（查看某个方法的出参入参）</p><p>watch com.cloud.openplatform.user.service.impl.UserServiceImpl getErrorTimes {params, returnObj}</p><p>如果想要查看入参的某个参数的话可以使用</p><p>{params[0].username, retrunObj.data.errorTimes}</p><p>查看多个入参或者一个入参的多个属性可以使用</p><p>{params[0].useranme,params[0].password,returnObj.msg} // 多个属性</p><p>{params[0].username,params[1].password, returnObj.mag} // 多个入参</p><p>反编译<br>反编译语法</p><p>jad –source-only 类的全路径名 类中的方法名 –lineNumber true（或者false）[&gt; 路径地址]</p><p>参数</p><p>说明</p><p>是否必填</p><p>–source –only</p><p>代表只输出源码信息，不包括classloader信息</p><p>否</p><p>类的全路径名</p><p>代表类的全路径名</p><p>是</p><p>类的方法名</p><p>代表类的方法名</p><p>否</p><p>–lineNumber</p><p>行序号，默认为true</p><p>否</p><p>命令（查看类的反编译）</p><p>jad –source-only com.cloud.form.user.service.impl.UserServiceImpl</p><p>可以选择加上–source-only去掉classLoader信息</p><p>（IDEA快捷键 选中一个类或者方法 ctrl + alt + shift + c，复制全路径名称，例如：com.cloud.openplatform.user.service.impl.UserServiceImpl  或者（注意方法前面是个#号记得去掉） com.cloud.openplatform.user.service.impl.UserServiceImpl#getUserInfoByUserId）</p><p>命令（查看方法）</p><p>jad com.cloud.openplatform.user.service.impl.UserServiceImpl getUserInfoByUserId</p><p>仪表盘<br>dashboard展示三部分信息：</p><p>第一部分是JVM中运行的多有线程：所在线程组，优先级，线程的状态，CPU的占用率，是否是后台进程等</p><p>第二部分是显示JVM内存的使用情况</p><p>第三部分是操作系统的一些信息和Java版本号</p><p>默认一直刷新，刷新频率为5秒</p><p>命令</p><p>// 10秒刷新一次，3次后停止刷新</p><p>dashboard -i 10000 –n 3</p><p>thread<br>查看线程的状态，实际上就是显示dashboard的第一部分</p><p>命令</p><p>thread</p><p>命令（查看某个Id的线程详情）</p><p>thread  线程id</p><p>命令（查看最繁忙的3个线程）</p><p>thread –n 3</p><p>命令（查看阻塞其他线程的线程）</p><p>thread -b</p><p>trace<br>该命令用于监控方法内部调用路径，并输出方法路径上的每个节点上耗时，有点类似于debug打上断点，然后调用时触发。</p><p>命令格式</p><p>trace 类全路径名 方法名</p><p>重新再启动一个页面，输入命令trace 类全路径 方法名 –listen listenerId</p><p>使用此命令的目的是让查询结果显示在一个页面中</p><p>热部署<br>首先通过Arthas命令将反编译的文件导出到指定文件</p><p>其次，使用Linux命令 vi或者vim进行修改</p><p>使用Arthas命令拿到Hash值</p><p>sc –d 类名</p><p>编译java文件</p><p>mc –c classLoaderHash java文件路径 –d 编译文件导出路径</p><p>加载字节码到内存</p><p>retransform class文件绝对路径</p><h3 id="死锁实例分析"><a href="#死锁实例分析" class="headerlink" title="死锁实例分析"></a>死锁实例分析</h3><p>thread命令找到异常线程</p><p>查看线程详情</p><p>根据详情信息，反编译查看代码问题，解决后，进行热部署或者其他操作</p><p>CPU飙升问题排查<br>通过dashboard命令可以看到Cpu占用率，找到占用率较高的线程</p><p>查看线程详情</p><p>反编译后分析问题</p>]]></content>
      
      
      <categories>
          
          <category> Arthas </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Arthas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot+Dubbo+Seata</title>
      <link href="/2023/03/14/SpringBoot+Dubbo+Seata/"/>
      <url>/2023/03/14/SpringBoot+Dubbo+Seata/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。"><a href="#Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。" class="headerlink" title="Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。"></a>Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。</h2><h3 id="下载seata"><a href="#下载seata" class="headerlink" title="下载seata"></a>下载seata</h3><pre><code>打开https://github.com/seata/seata/releases，目前最新版本是v0.6.1。下载解压后，到seata-server-0.6.1\distribution\bin目录下可以看到seata-server.bat和seata-server.sh，选择一个双击执行</code></pre><h3 id="Maven依赖"><a href="#Maven依赖" class="headerlink" title="Maven依赖"></a>Maven依赖</h3><pre><code> Dubbo依赖    &lt;dependency&gt;        &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;        &lt;artifactId&gt;dubbo&lt;/artifactId&gt;        &lt;version&gt;2.7.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;        &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;2.7.1&lt;/version&gt;    &lt;/dependency&gt;Zookeeper依赖    &lt;dependency&gt;        &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;        &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;        &lt;version&gt;2.13.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;        &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;        &lt;version&gt;2.13.0&lt;/version&gt;    &lt;/dependency&gt;Seata依赖    &lt;dependency&gt;        &lt;groupId&gt;io.seata&lt;/groupId&gt;        &lt;artifactId&gt;seata-all&lt;/artifactId&gt;        &lt;version&gt;0.6.1&lt;/version&gt;    &lt;/dependency&gt;</code></pre><h3 id="项目配置"><a href="#项目配置" class="headerlink" title="项目配置"></a>项目配置</h3><pre><code>server.port=8011spring.datasource.url=jdbc:mysql://127.0.0.1:3306/seataspring.datasource.username=rootspring.datasource.password=rootdubbo.application.name=order-servicedubbo.registry.address=zookeeper://127.0.0.1:2181dubbo.protocol.name=dubbodubbo.protocol.port=20881dubbo.consumer.timeout=9999999dubbo.consumer.check=false</code></pre><h3 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h3><pre><code>Seata 是通过代理数据源实现事务分支，所以需要先配置一个数据源的代理，否则事务不会回滚。@Beanpublic DataSourceProxy dataSourceProxy(DataSource dataSource) {    return new DataSourceProxy(dataSource);}</code></pre><h3 id="Seata配置"><a href="#Seata配置" class="headerlink" title="Seata配置"></a>Seata配置</h3><pre><code>还需要配置全局事务扫描器。有两个参数，一个是应用名称，一个是事务分组。@Beanpublic GlobalTransactionScanner globalTransactionScanner() {    return new GlobalTransactionScanner(&quot;springboot-order&quot;, &quot;my_test_tx_group&quot;);}</code></pre><h3 id="配置注册中心"><a href="#配置注册中心" class="headerlink" title="配置注册中心"></a>配置注册中心</h3><pre><code> registry {    type = &quot;file&quot;    file {        name = &quot;file.conf&quot;    }    }    config {    # file、nacos 、apollo、zk、consul    type = &quot;file&quot;    file {        name = &quot;file.conf&quot;    }}service {    #vgroup-&gt;rgroup    vgroup_mapping.my_test_tx_group = &quot;default&quot;    #only support single node    default.grouplist = &quot;127.0.0.1:8091&quot;    #degrade current not support    enableDegrade = false    #disable    disable = false}</code></pre>]]></content>
      
      
      <categories>
          
          <category> Seata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Seata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Seata</title>
      <link href="/2023/03/08/Seata/"/>
      <url>/2023/03/08/Seata/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。"><a href="#Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。" class="headerlink" title="Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。"></a>Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。</h2><h3 id="Seata中四种分布式事务模式"><a href="#Seata中四种分布式事务模式" class="headerlink" title="Seata中四种分布式事务模式"></a>Seata中四种分布式事务模式</h3><pre><code>AT模式TCC模式Saga模式XA模式</code></pre><h4 id="AT模式"><a href="#AT模式" class="headerlink" title="AT模式"></a>AT模式</h4><pre><code>是一种基于本地事务+二阶段协议来实现的最终数据一致性方案，也是Seata默认的解决方案 。</code></pre><p><img src="/image/AT%E6%A8%A1%E5%BC%8F.png" alt="效果图预览"></p><h4 id="TCC模式"><a href="#TCC模式" class="headerlink" title="TCC模式"></a>TCC模式</h4><pre><code>TCC事务是Try、Confirm、Cancel三个词语的缩写，简单理解就是把一个完整的业务逻辑拆分成三个阶段，然后通过事务管理器在业务逻辑层面根据每个分支事务的执行情况分别调用该业务的Confirm或者Cacel方法。</code></pre><p><img src="/image/TCC%E6%A8%A1%E5%BC%8F.png" alt="效果图预览"></p><h4 id="Saga模式"><a href="#Saga模式" class="headerlink" title="Saga模式"></a>Saga模式</h4><pre><code>Saga模式是SEATA提供的长事务解决方案，在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者。</code></pre><p><img src="/image/Saga%E6%A8%A1%E5%BC%8F.png" alt="效果图预览"></p><h4 id="XA模式"><a href="#XA模式" class="headerlink" title="XA模式"></a>XA模式</h4><pre><code>XA可以认为是一种强一致性的事务解决方法，它利用事务资源（数据库、消息服务等）对 XA 协议的支持，以 XA 协议的机制来管理分支事务的一种 事务模式。</code></pre><p><img src="/image/XA%E6%A8%A1%E5%BC%8F.png" alt="效果图预览"></p><pre><code>分布式事务本质上要解决的就是跨网络节点的多个事务的数据一致性问题，业内常见的解决方法有两种：1、强一致性    就是所有的事务参与者要么全部成功，要么全部失败，全局事务协调者需要知道每个事务参与者的执行状态，再根据状态来决定数据的提交或者回滚！2、最终一致性，也叫弱一致性，    也就是多个网络节点的数据允许出现不一致的情况，但是在最终的某个时间点会达成数据一致。    基于 CAP 定理我们可以知道，强一致性方案对于应用的性能和可用性会有影响，所以对于数据一致性要求不高的场景，就会采用最终一致性算法。</code></pre><h3 id="Seata实现两阶段提交"><a href="#Seata实现两阶段提交" class="headerlink" title="Seata实现两阶段提交"></a>Seata实现两阶段提交</h3><pre><code>2PC，全称为两阶段提交（Two-Phase Commit），是一种在分布式系统中用来保证事务原子性和一致性的协议。它主要用于协调分布式数据库或分布式事务环境中的多个参与者，确保所有参与者要么一起成功提交事务，要么一起回滚事务，以保持数据的一致性。</code></pre><p><img src="/image/%E4%BA%8C%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.png" alt="效果图预览"></p><pre><code>在2PC协议中有两个主要阶段：准备阶段（Prepare Phase）：    事务协调器接收到发起事务的客户端请求后，向所有参与该事务的资源管理器（例如数据库、服务节点等）发送“准备提交”请求。    每个资源管理器执行事务操作，并将事务相关的更改锁定但不提交，然后回复事务协调器它们是否准备好提交事务（根据各自是否能够成功完成事务而定）。提交阶段（Commit Phase）：    如果事务协调器收到了所有资源管理器的肯定答复，即所有参与者都准备好提交事务，则向所有参与者发出“正式提交”指令。    若协调器收到任何一个参与者的否定响应，或者在等待超时后仍有参与者未响应，则向所有参与者发出“回滚事务”的指令。</code></pre><h3 id="Seata定义了3个组件来协议分布式事务的处理过程"><a href="#Seata定义了3个组件来协议分布式事务的处理过程" class="headerlink" title="Seata定义了3个组件来协议分布式事务的处理过程"></a>Seata定义了3个组件来协议分布式事务的处理过程</h3><p> <img src="/image/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1.png" alt="效果图预览"></p><pre><code>Transaction Coordinator (TC)：事务协调器，它是独立的中间件，需要独立部署运行，它维护全局事务的运行状态，接收TM指令发起全局事务的提交与回滚，负责与RM通信协调各各分支事务的提交或回滚。Transaction Manager (TM)：事务管理器，TM需要嵌入应用程序中工作，它负责开启一个全局事务，并最终向TC发起全局提交或全局回滚的指令。Resource Manager (RM)：控制分支事务，负责分支注册、状态汇报，并接收事务协调器TC的指令，驱动分支（本地）事务的提交和回滚。</code></pre>]]></content>
      
      
      <categories>
          
          <category> Seata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Seata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Seata安装</title>
      <link href="/2023/03/07/Seata%E5%AE%89%E8%A3%85/"/>
      <url>/2023/03/07/Seata%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。"><a href="#Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。" class="headerlink" title="Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。"></a>Seata就是其中一种，它是阿里开源的分布式事务解决方案，提供了高性能且简单易用的分布式事务服务。</h2><h3 id="下载seata"><a href="#下载seata" class="headerlink" title="下载seata"></a>下载seata</h3><pre><code>官方下载地址：https://github.com/seata/seata/releasesregistry.type=file:registry.type=file 其类型设置为 file 时，意味着 Seata 的服务注册中心不依赖于外部的如 Nacos、Eureka、Zookeeper 等第三方注册中心，而是使用本地文件的方式来存储和管理服务节点信息。这种模式主要用于快速测试或简单的单机部署场景，因为在这种模式下无法自动发现和管理集群环境中的其他 Seata Server 节点，不具备高可用性。config.type=file:config.type=file 表示 Seata 使用本地文件作为配置源。这意味着 Seata 会从指定的本地文件中读取全局事务协调器（TC）、事务管理器（TM）和资源管理器（RM）等组件所需的配置信息，而不是通过Nacos、Apollo或其他远程配置中心获取配置。这种方式同样适用于快速验证和简单部署情况，实际生产环境中可能需要结合分布式配置中心来动态更新和管理配置。seata启动：/bin/seata-server.bat -m file</code></pre><h3 id="依赖引入"><a href="#依赖引入" class="headerlink" title="依赖引入"></a>依赖引入</h3><pre><code>&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.seata&lt;/groupId&gt;        &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;1.4.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.baomidou&lt;/groupId&gt;        &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;        &lt;version&gt;3.4.1&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--mysql--&gt;    &lt;dependency&gt;        &lt;groupId&gt;mysql&lt;/groupId&gt;        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;        &lt;version&gt;5.1.47&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!--bank-2 不需要--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;        &lt;artifactId&gt;httpclient&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><h3 id="定义配置"><a href="#定义配置" class="headerlink" title="定义配置"></a>定义配置</h3><pre><code> server:    port: 8081    #port: 8082spring:    application:        name: bank-1        #name: bank-2    datasource:        url: jdbc:mysql://localhost:3306/bank1?characterEncoding=utf8&amp;useSSL=false        #url: jdbc:mysql://localhost:3306/bank2?characterEncoding=utf8&amp;useSSL=false        driver-class-name: com.mysql.jdbc.Driver        username: root        password: rootseata:    tx-service-group: order_tx_group #自定义事务组名称需要与seata-server中的对应    service:        vgroup-mapping:        order_tx_group: default # TC 集群（必须与seata-server保持一致）</code></pre><h3 id="服务调用"><a href="#服务调用" class="headerlink" title="服务调用"></a>服务调用</h3><pre><code>在调用方上加上  @GlobalTransactional 注解 ，在分支事务上加上 @Transactional 注解当业务方法开启全局异常处理器后，TM注册到TC获取到一个XID，此时在业务中，服务远程访问时，此XID会被下面分支业务方法RM接收到，当各个方法处理完成后RM会向TC直接交互把结果通过XID通知给TC，最后业务方法结束后，TM会通知TC业务已经完成，TC会根据RM通知的结果来通知各个RM提交或者回滚。但是在分布式事务中，入口TM传出时不会将XID放入请求头中向其他服务传递，这样就导致全局异常捕获失效，因此需要手动将XID设置到请求头中，携带给各分支业务来避免事务失效问题。</code></pre><h3 id="正常流程"><a href="#正常流程" class="headerlink" title="正常流程"></a>正常流程</h3><p><img src="/image/Seata%E6%AD%A3%E5%B8%B8%E6%B5%81%E7%A8%8B.png" alt="效果图预览">  </p><h3 id="回滚流程"><a href="#回滚流程" class="headerlink" title="回滚流程"></a>回滚流程</h3><p><img src="/image/Seata%E5%9B%9E%E6%BB%9A%E6%B5%81%E7%A8%8B.png" alt="效果图预览">  </p>]]></content>
      
      
      <categories>
          
          <category> Seata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Seata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dubbo</title>
      <link href="/2022/12/14/Dubbo/"/>
      <url>/2022/12/14/Dubbo/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="dubbo：是一个基于soa思想的rpc框架"><a href="#dubbo：是一个基于soa思想的rpc框架" class="headerlink" title="dubbo：是一个基于soa思想的rpc框架"></a>dubbo：是一个基于soa思想的rpc框架</h2><h3 id="soa思想"><a href="#soa思想" class="headerlink" title="soa思想"></a>soa思想</h3><pre><code>面向服务的架构给每一个模块暴露对应的ip和端口，当做一个服务进行运行重点在于服务的管理（负载均衡，容灾模式，服务的横向扩展）</code></pre><h3 id="Dubbo三大组件"><a href="#Dubbo三大组件" class="headerlink" title="Dubbo三大组件"></a>Dubbo三大组件</h3><pre><code>注册中心：    协调 Consumer 与 Provider 之间的地址注册与发现配置中心:   存储 Dubbo 启动阶段的全局配置，保证配置的跨环境共享与全局一致性   负责服务治理规则（路由规则、动态配置等）的存储与推送。元数据中心:   接收 Provider 上报的服务接口元数据，为 Admin 等控制台提供运维能力（如服务测试、接口文档等）   作为服务发现机制的补充，提供额外的接口/方法级别配置信息的同步能力，相当于注册中心的额外扩展</code></pre><p> <img src="/image/dubbo%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="效果图预览">  </p><h3 id="Spring中使用"><a href="#Spring中使用" class="headerlink" title="Spring中使用"></a>Spring中使用</h3><h4 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h4><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-core&lt;/artifactId&gt;    &lt;version&gt;4.3.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-beans&lt;/artifactId&gt;    &lt;version&gt;4.3.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-context&lt;/artifactId&gt;    &lt;version&gt;4.3.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;    &lt;artifactId&gt;dubbo&lt;/artifactId&gt;    &lt;version&gt;2.5.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;    &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;    &lt;version&gt;3.4.6&lt;/version&gt;&lt;/dependency&gt;</code></pre><h4 id="服务提供者"><a href="#服务提供者" class="headerlink" title="服务提供者"></a>服务提供者</h4><pre><code> // 服务提供者接口public interface UserService {String findName(String name);void addUser(String username);}public class UserServiceImpl implements UserService {    @Override    public String findName(String name) {        System.out.println(&quot;姓名：&quot; + name);        return &quot;hello&quot; + name;    }    @Override    public void addUser(String username) {        System.out.println(&quot;添加用户，用户名为：&quot; + username);    }}spring.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot;    xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt;    &lt;dubbo:application name=&quot;dubbo_product&quot;/&gt;    &lt;dubbo:registry address=&quot;multicast://224.5.6.7:1234&quot;/&gt;    &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt;    &lt;dubbo:service interface=&quot;service.UserService&quot; ref=&quot;userService&quot;/&gt;    &lt;bean id=&quot;userService&quot; class=&quot;service.UserServiceImpl&quot;/&gt;&lt;/beans&gt;开启服务public class TestDubbo {    public static void main(String[] args) throws IOException {        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring-dubbo.xml&quot;);        context.start();        System.out.println(&quot;服务提供者，开始提供服务。。。。&quot;);        System.in.read();    }}</code></pre><h4 id="服务消费者"><a href="#服务消费者" class="headerlink" title="服务消费者"></a>服务消费者</h4><pre><code>需要将服务提供接口拷贝到当前服务下public interface UserService {    String findName(String name);    void addUser(String username);}&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot;    xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt;    &lt;dubbo:application name=&quot;dubbo_consumer&quot;/&gt;    &lt;dubbo:registry address=&quot;multicast://224.5.6.7:1234&quot;/&gt;    &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt;&lt;!-- &lt;dubbo:registry address=&quot;zookeeper://224.5.6.7:1234&quot;/&gt;    &lt;dubbo:protocol name=&quot;zookeeper&quot; port=&quot;20880&quot;/&gt; --&gt;    &lt;dubbo:reference interface=&quot;service.UserService&quot; ref=&quot;userService&quot;/&gt;&lt;/beans&gt;测试public class TestDubbo {    public static void main(String[] args) throws IOException {        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring-dubbo.xml&quot;);        UserService userService = (UserService) context.getBean(&quot;userService&quot;);        userService.addUser(&quot;测试人员&quot;);        String name = userService.findName(&quot;xiaoming&quot;);        System.out.println(name);    }}</code></pre><h3 id="SpringCloud整合Dubbo"><a href="#SpringCloud整合Dubbo" class="headerlink" title="SpringCloud整合Dubbo"></a>SpringCloud整合Dubbo</h3><h4 id="引入依赖-1"><a href="#引入依赖-1" class="headerlink" title="引入依赖"></a>引入依赖</h4><pre><code> &lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><h4 id="服务提供方"><a href="#服务提供方" class="headerlink" title="服务提供方"></a>服务提供方</h4><pre><code> // 服务提供者接口public interface ProductService {String findName(String name);}public class ProductServiceImpl implements ProductService {    @Override    public String findName(String name) {        System.out.println(&quot;姓名：&quot; + name);        return &quot;hello&quot; + name;    }}application.yamldubbo:    application:        name: product     # 服务名    protocol:        name: dubbo       # 暴露的协议名称        port: 20880       # 暴露的协议端口    registry:        address: spring-cloud://XX:8848 # Dubbo 服务注册中心配置，其中子属性address 的值 &quot;spring-cloud://XX&quot;，说明挂载到 SpringCloud 的注册中心</code></pre><h4 id="服务消费方"><a href="#服务消费方" class="headerlink" title="服务消费方"></a>服务消费方</h4><p>   同样需要将服务方的接口copy到消费放的项目目录下</p><pre><code>public interface ProductService {    String findName(String name);}application.yamldubbo:    application:        name: users    protocol:        name: dubbo        port: 20880    registry:        address: spring-cloud://XX:8848    cloud:        subscribed-services: * # 表示要订阅服务的服务名，可以配置&#39;*&#39;，代表订阅所有服务，不推荐使用。若需订阅多应用，使用 &quot;,&quot; 分割。</code></pre><h4 id="调用服务"><a href="#调用服务" class="headerlink" title="调用服务"></a>调用服务</h4><pre><code>public class UsersServiceImpl implements UserService {    @Reference    private ProductService productService;    @GetMapping(&quot;/users&quot;)    public String getUsers() {        String result = productService.findName(&quot;xiaochen&quot;);        return &quot;users ok!!!  result:&quot; + result;    }}</code></pre><h3 id="配置优先级"><a href="#配置优先级" class="headerlink" title="配置优先级"></a>配置优先级</h3><pre><code>xml配置    不同粒度配置的覆盖关系    以 timeout 为例，其它 retries, loadbalance, actives 等类似：    方法级优先，接口级次之，全局配置再次之。    如果级别一样，则消费方优先，提供方次之。属性配置    从Dubbo支持的配置来源说起，默认有6种配置来源：        JVM System Properties，JVM -D 参数        System environment，JVM进程的环境变量        Externalized Configuration，外部化配置，从配置中心读取        Application Configuration，应用的属性配置，从Spring应用的Environment中提取&quot;dubbo&quot;打头的属性集        API / XML /注解等编程接口采集的配置可以被理解成配置来源的一种，是直接面向用户编程的配置采集方式        从classpath读取配置文件 dubbo.propertiesAPI配置：https://dubbo.apache.org/zh/docs/references/configuration/api/注解配置：https://dubbo.apache.org/zh/docs/references/configuration/annotation/</code></pre><h3 id="启动时检查"><a href="#启动时检查" class="headerlink" title="启动时检查"></a>启动时检查</h3><pre><code>https://dubbo.apache.org/zh/docs/advanced/preflight-check/Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 check=&quot;true&quot;。可以通过 check=&quot;false&quot; 关闭检查，比如，测试时，有些服务不关心，或者出现了循环依赖，必须有一方先启动。另外，如果你的 Spring 容器是懒加载的，或者通过 API 编程延迟引用服务，请关闭 check，否则服务临时不可用时，会抛出异常，拿到 null 引用，如果 check=&quot;false&quot;，总是会返回引用，当服务恢复时，能自动连上。通过 spring 配置文件    关闭某个服务的启动时检查 (没有提供者时报错)：    &lt;dubbo:reference interface=&quot;com.foo.BarService&quot; check=&quot;false&quot; /&gt;    关闭所有服务的启动时检查 (没有提供者时报错)：    &lt;dubbo:consumer check=&quot;false&quot; /&gt;    关闭注册中心启动时检查 (注册订阅失败时报错)：    &lt;dubbo:registry check=&quot;false&quot; /&gt;通过 dubbo.properties    dubbo.reference.com.foo.BarService.check=false    dubbo.consumer.check=false    dubbo.registry.check=false通过 -D 参数    java -Ddubbo.reference.com.foo.BarService.check=false    java -Ddubbo.consumer.check=false     java -Ddubbo.registry.check=false</code></pre><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><pre><code>在集群负载均衡时，Dubbo 提供了多种均衡策略，缺省为 random 随机调用。具体实现上，Dubbo 提供的是客户端负载均衡，即由 Consumer 通过负载均衡算法得出需要将请求提交到哪个 Provider 实例。目前 Dubbo 内置了如下负载均衡算法，可直接配置使用：    算法    特性    备注    Random LoadBalance    加权随机    默认算法，默认权重相同    RoundRobin LoadBalance    加权轮询    借鉴于 Nginx 的平滑加权轮询算法，默认权重相同，    LeastActive LoadBalance    最少活跃优先 + 加权随机    背后是能者多劳的思想    ShortestResponse LoadBalance    最短响应优先 + 加权随机    更加关注响应速度    ConsistentHash LoadBalance    一致性 Hash    确定的入参，确定的提供者，适用于有状态请求</code></pre><p>   常见有四种负载均衡：</p><pre><code>random    随机，按权重设置随机概率。    在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。roundRobin （默认）    轮询，按公约后的权重设置轮询比率。    存在慢的提供者类即请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。leastActive    最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。    使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。consistentHash    一致性Hash，相同参数的请求总是发到同一提供者。    当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其他提供者，不会引起剧烈变动</code></pre><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><pre><code>服务端服务级别    &lt;dubbo:service interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;客户端服务级别    &lt;dubbo:reference interface=&quot;...&quot; loadbalance=&quot;roundrobin&quot; /&gt;服务端方法级别    &lt;dubbo:service interface=&quot;...&quot;&gt;        &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt;    &lt;/dubbo:service&gt;客户端方法级别    &lt;dubbo:reference interface=&quot;...&quot;&gt;        &lt;dubbo:method name=&quot;...&quot; loadbalance=&quot;roundrobin&quot;/&gt;</code></pre><h3 id="集群容错"><a href="#集群容错" class="headerlink" title="集群容错"></a>集群容错</h3><pre><code>Dubbo 提供了多种容错方案，缺省为 failover 重试。Failover Cluster    失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。Failfast Cluster    快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。Failsafe Cluster    失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。Failback Cluster    失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。Forking Cluster    并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=&quot;2&quot; 来设置最大并行数。Broadcast Cluster    广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。配置服务提供方和消费方集群模式&lt;dubbo:service cluster=&quot;failsafe&quot; /&gt;或&lt;dubbo:reference cluster=&quot;failsafe&quot; /&gt;</code></pre><h3 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h3><pre><code>需要通过不同的派发策略和不同的线程池配置的组合来应对不同的场景Dispatcher    all 所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等。    direct 所有消息都不派发到线程池，全部在 IO 线程上直接执行。    message 只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在 IO 线程上执行。    execution 只有请求消息派发到线程池，不含响应，响应和其它连接断开事件，心跳等消息，直接在 IO 线程上执行。    connection 在 IO 线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池。ThreadPool    fixed 固定大小线程池，启动时建立线程，不关闭，一直持有。(缺省)    cached 缓存线程池，空闲一分钟自动删除，需要时重建。    limited 可伸缩线程池，但池中的线程数只会增长不会收缩。只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题。    eager 优先创建Worker线程池。在任务数量大于corePoolSize但是小于maximumPoolSize时，优先创建Worker来处理任务。当任务数量大于maximumPoolSize时，将任务放入阻塞队列中。阻塞队列充满时抛出RejectedExecutionException。(相比于cached:cached在任务数量超过maximumPoolSize时直接抛出异常而不是将任务放入阻塞队列)</code></pre><h3 id="服务分组"><a href="#服务分组" class="headerlink" title="服务分组"></a>服务分组</h3><pre><code>当一个接口有多种实现时，可以用 group 区分。</code></pre><h4 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h4><pre><code>&lt;dubbo:service group=&quot;feedback&quot; interface=&quot;com.xxx.IndexService&quot; /&gt;&lt;dubbo:service group=&quot;member&quot; interface=&quot;com.xxx.IndexService&quot; /&gt;</code></pre><h4 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h4><pre><code>&lt;dubbo:reference id=&quot;feedbackIndexService&quot; group=&quot;feedback&quot; interface=&quot;com.xxx.IndexService&quot; /&gt;&lt;dubbo:reference id=&quot;memberIndexService&quot; group=&quot;member&quot; interface=&quot;com.xxx.IndexService&quot; /&gt;</code></pre><h4 id="任意组"><a href="#任意组" class="headerlink" title="任意组"></a>任意组</h4><pre><code> &lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; group=&quot;*&quot; /&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> dubbo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> dubbo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>synchronized 和 ReentrantLock</title>
      <link href="/2022/11/09/synchronized%20%E5%92%8C%20ReentrantLock/"/>
      <url>/2022/11/09/synchronized%20%E5%92%8C%20ReentrantLock/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><h3 id="synchronized实现"><a href="#synchronized实现" class="headerlink" title="synchronized实现"></a>synchronized实现</h3><pre><code>每一个对象实际都拥有一个叫做监视器monitor的东西，线程只有获得了这个监视器才能才能进入同步块和同步方法，如果没有获取到监视器的线程将会被阻塞在同步块和同步方法的入口处。</code></pre><p><img src="/image/synchronized%E5%AE%9E%E7%8E%B0.png" alt="效果图预览"> </p><h3 id="synchronized和ReentrantLock不同"><a href="#synchronized和ReentrantLock不同" class="headerlink" title="synchronized和ReentrantLock不同"></a>synchronized和ReentrantLock不同</h3><pre><code>1、用法不同：synchronized 可以用来修饰普通方法、静态方法和代码块，而 ReentrantLock 只能用于代码块。2、获取锁和释放锁的机制不同：synchronized 是自动加锁和释放锁的，而 ReentrantLock 需要手动加锁和释放锁。3、锁类型不同：synchronized 是非公平锁，而 ReentrantLock 默认为非公平锁，也可以手动指定为公平锁，通过new ReentrantLock() 指定4、响应中断不同：ReentrantLock 可以响应中断，解决死锁的问题，而 synchronized 不能响应中断。5、底层实现不同：synchronized 是 JVM 层面通过监视器实现的，而 ReentrantLock 是基于 AQS 实现的。</code></pre><h3 id="synchronized-是可重入锁"><a href="#synchronized-是可重入锁" class="headerlink" title="synchronized 是可重入锁"></a>synchronized 是可重入锁</h3><pre><code>synchronized 是可重入锁，也就是说，允许一个线程二次请求自己持有对象锁的临界资源，这种情况称为可重入锁。synchronized 锁对象的时候有个计数器，他会记录下线程获取锁的次数，在执行完对应的代码块之后，计数器就会-1，直到计数器清零，就释放锁了。synchronized 之所以，是可重入的。是因为 synchronized 锁对象有个计数器，会随着线程获取锁后 +1 计数，当线程执行完毕后 -1，直到清零释放锁。Synchronized的可重入性是通过JVM内部机制实现的。具体来说，每个锁对象都有一个计数器来记录当前持有该锁的线程重入的次数。当一个线程首次获取该锁时，计数器会加1。如果同一个线程再次获取该锁，计数器会再次加1，这就是所谓的重入。相应的，每次线程释放锁时，计数器会减1。只有当计数器减为0时，锁才会真正释放，其他线程才有机会获取该锁。通过这种计数器机制，Synchronized实现了可重入性，允许同一个线程多次获取同一个锁而不会发生死锁。同时，这也保证了同步代码块或方法在被一个线程重入时，仍然能够保持正确的同步状态。需要注意的是，Synchronized的可重入性是自动的，无需程序员显式控制。但这也意味着在使用Synchronized时需要注意避免不必要的重入，以免增加不必要的开销和复杂性。</code></pre><h3 id="Synchronized锁的升级过程主要包括以下几个阶段"><a href="#Synchronized锁的升级过程主要包括以下几个阶段" class="headerlink" title="Synchronized锁的升级过程主要包括以下几个阶段"></a>Synchronized锁的升级过程主要包括以下几个阶段</h3><pre><code>1.无锁状态：初始状态下，对象没有被任何线程锁定，所有的线程都可以尝试获取锁。2.偏向锁状态：当线程第一次获取锁时，对象头中的标记位会变为偏向锁状态，同时记录获取锁的线程ID。此后，如果该线程再次进入同步块，JVM会检查对象头的Mark   Word是否指向当前线程的线程ID，如果是，则无需使用CAS操作加锁，直接进入同步块，这就是偏向锁的支持重入的特性。这个过程中并不会涉及到锁的升级。3.轻量级锁状态：当另一个线程尝试获取这个已经被偏向的锁时，偏向锁就会升级为轻量级锁。此时，JVM会通过自旋锁的方式尝试获取锁，自旋就是不会立即阻塞线程，而是让线程空转等待锁释放。如果自旋成功则获取锁，执行同步块；如果自旋失败，则锁升级为重量级锁。4.重量级锁状态：在这个状态下，未抢到锁的线程都会被阻塞，等待操作系统唤醒。此时的性能开销最大，因为线程的阻塞和唤醒都需要操作系统来协助完成。</code></pre><p>   Synchronized锁的升级过程是为了在保证线程安全的前提下，尽可能地提高程序的性能。通过锁的升级，可以实现在线程竞争不激烈的情况下使用效率更高的锁，而在线程竞争激烈的情况下使用更稳定的锁，从而在各种场景下都能保持较好的性能。</p>]]></content>
      
      
      <categories>
          
          <category> 锁 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k8s</title>
      <link href="/2022/10/10/k8s%E5%AE%89%E8%A3%85/"/>
      <url>/2022/10/10/k8s%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Kuboard-Spray Kuboard-Spray 是一款可以在图形界面引导下完成 Kubernetes 高可用集群离线安装的工具，开源仓库的地址为<a href="https://github.com/eip-work/kuboard-spray">https://github.com/eip-work/kuboard-spray</a></p><h3 id="一、安装-Kuboard-Spray"><a href="#一、安装-Kuboard-Spray" class="headerlink" title="一、安装 Kuboard-Spray"></a>一、安装 Kuboard-Spray</h3><pre><code>取一台服务器或虚拟机，执行一条命令，即可完成 Kuboard-Spray 的安装。    对这台服务器的最低要求为：        1核2G        不少于 10G 磁盘空余空间        已经安装好 docker        待执行的命令如下：            docker run -d \        --privileged \        --restart=unless-stopped \        --name=kuboard-spray \        -p 80:80/tcp \        -v /var/run/docker.sock:/var/run/docker.sock \        -v ~/kuboard-spray-data:/data \        eipwork/kuboard-spray:latest-amd64        # 如果抓不到这个镜像，可以尝试一下这个备用地址：        # swr.cn-east-2.myhuaweicloud.com/kuboard/kuboard-spray:latest-amd64持久化KuboardSpray 的信息保存在容器的 /data 路径，请将其映射到一个您认为安全的地方，上面的命令中，将其映射到了 ~/kuboard-spray-data 路径；只要此路径的内容不受损坏，重启、升级、重新安装 Kuboard-Spray，或者将数据及 Kuboard-Spray 迁移到另外一台机器上，您都可以找回到原来的信息。在浏览器打开地址 http://这台机器的IP，输入用户名 admin，默认密码 Kuboard123，即可登录 Kuboard-Spray 界面。</code></pre>]]></content>
      
      
      <categories>
          
          <category> k8s使用 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> k8s </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k8s</title>
      <link href="/2022/07/19/k8s%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
      <url>/2022/07/19/k8s%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Kubernetes (k8s)是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。</p><h3 id="一、k8s-简介"><a href="#一、k8s-简介" class="headerlink" title="一、k8s 简介"></a>一、k8s 简介</h3><p><img src="/image/k8s%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="效果图预览"></p><pre><code>一个K8S集群是由两大部分组成：     Master节点和Node节点,其中 Master 节点作为整个集群的控制中心，主要负责集群的管理和调度工作</code></pre><h4 id="1-1-Master节点"><a href="#1-1-Master节点" class="headerlink" title="1.1 Master节点"></a>1.1 Master节点</h4><pre><code>Master节点主要包括API Server、Scheduler、Controller manager、etcd几大组件</code></pre><h5 id="1-1-1-API-Server"><a href="#1-1-1-API-Server" class="headerlink" title="1.1.1 API Server"></a>1.1.1 API Server</h5><pre><code>API Server 是 Kubernetes 最核心的组件之一，它提供了 Kubernetes 集群中各个组件之间的通信和管理接口，所有操作都需要通过 API Server 发起和处理。当用户使用 kubectl 命令或者其他 Kubernetes 客户端工具时，实际上是通过 API Server 和集群进行交互的。</code></pre><h5 id="1-1-2-Etcd"><a href="#1-1-2-Etcd" class="headerlink" title="1.1.2 Etcd"></a>1.1.2 Etcd</h5><pre><code>Etcd 是 Kubernetes 集群中的分布式键值存储系统，用于保存集群中的所有状态信息和元数据。所有与 Kubernetes 集群相关的信息，包括 Pod、Service、Deployment 等对象的创建、更新和删除等操作，都将被记录在 Etcd 中。这样可以使得 Kubernetes 系统具有高可用性和复原能力，并且允许多个 Master 节点之间进行数据同步和共享。</code></pre><h5 id="1-1-3-Controller-Manager"><a href="#1-1-3-Controller-Manager" class="headerlink" title="1.1.3 Controller Manager"></a>1.1.3 Controller Manager</h5><pre><code>Controller Manager 是 Kubernetes 集群中的另一个核心组件，它负责监控和维护集群中所有资源对象的状态，以及进行自动化控制和管理操作。Controller Manager 中包含多个控制器，每个控制器负责监控和维护一种资源对象的状态，如 Deployment、ReplicaSet、DaemonSet 等，同时根据用户的需求，自动进行相应的容器调度、扩容、缩容等操作。</code></pre><h5 id="1-1-4-Scheduler"><a href="#1-1-4-Scheduler" class="headerlink" title="1.1.4 Scheduler"></a>1.1.4 Scheduler</h5><pre><code>Scheduler 是 Kubernetes 集群中的另一个重要组件，主要负责根据集群中各个节点的负载情况，以及用户的调度策略，将新创建的 Pod 分配到合适的节点上。Scheduler 会根据 Pod 的资源需求、节点的资源情况、节点之间的网络距离等因素进行智能调度，从而实现负载均衡和资源最大化利用的目标.</code></pre><h4 id="1-2-Node-节点"><a href="#1-2-Node-节点" class="headerlink" title="1.2 Node 节点"></a>1.2 Node 节点</h4><pre><code>是容器化应用程序真正运行的地方</code></pre><h5 id="1-2-1-kubelet"><a href="#1-2-1-kubelet" class="headerlink" title="1.2.1 kubelet"></a>1.2.1 kubelet</h5><pre><code>kubelet 是运行在每个 Node 节点上的代理程序，它负责与 Master 节点上的 API Server 进行通信，并根据 Master 节点下发的指令，调度和管理本地节点上的容器。kubelet 可以监控本地节点上的容器状态，如启动、停止、健康状况等，并定期向 Master 节点报告节点状态信息。</code></pre><h5 id="1-2-2-kube-proxy"><a href="#1-2-2-kube-proxy" class="headerlink" title="1.2.2 kube-proxy"></a>1.2.2 kube-proxy</h5><pre><code>kube-proxy 是 Kubernetes 集群中的网络代理组件，它主要负责实现集群内 Service 的负载均衡和访问控制等功能。每个 Node 节点上都会部署一个 kube-proxy 组件来负责处理该节点上所有 Service 的流量转发和路由等操作。</code></pre><h5 id="1-2-3-Pod"><a href="#1-2-3-Pod" class="headerlink" title="1.2.3 Pod"></a>1.2.3 Pod</h5><pre><code>Pod 是 Kubernetes 中最小的调度和管理单元，它代表着集群中运行的一个或多个容器实例。在一个 Pod 中，所有容器共享相同的网络命名空间、进程命名空间和存储卷，因此它们可以互相通信和共享数据。Pod 可以通过控制器进行创建、扩缩容和更新等操作。</code></pre><h3 id="二、K8S-核心概念"><a href="#二、K8S-核心概念" class="headerlink" title="二、K8S 核心概念"></a>二、K8S 核心概念</h3><pre><code>Kubernetes 是一个基于容器化技术的分布式应用程序编排平台，其核心概念主要包括 Pod、Service、Namespace、Deployment、StatefulSet、DaemonSet、Job 和 CronJob 等。</code></pre><h4 id="2-1-Pod"><a href="#2-1-Pod" class="headerlink" title="2.1 Pod"></a>2.1 Pod</h4><pre><code>Pod是Kubernetes中最小的可调度和可管理的单元，它可以包含一个或多个容器，并共享相同的网络和存储资源。Pod是部署和扩展应用程序的基本单位。</code></pre><h5 id="2-1-1-容器"><a href="#2-1-1-容器" class="headerlink" title="2.1.1 容器"></a>2.1.1 容器</h5><pre><code>Pod 中的容器是指实际运行业务逻辑的进程，可以使用 Docker、CRI-O、containerd 等各种容器运行时来运行。每个 Pod 中可以包含一个或多个容器，这些容器可以通过共享网络和存储资源，实现相互通信和协作。</code></pre><h5 id="2-1-2-生命周期"><a href="#2-1-2-生命周期" class="headerlink" title="2.1.2 生命周期"></a>2.1.2 生命周期</h5><pre><code>Pod 的生命周期包括 Pending、Running、Succeeded、Failed 和 Unknown 等几个阶段。在创建一个 Pod 后，它会首先进入 Pending 阶段，等待被调度到某个节点上。如果调度成功，Pod 就会进入 Running 阶段，开始正常运行。如果 Pod 运行失败或者所有容器都退出了，Pod 就会进入 Failed 或 Succeeded 阶段。如果调度和运行过程中出现了异常，Pod 就会进入 Unknown 阶段。</code></pre><h5 id="2-1-3-Pod-网络"><a href="#2-1-3-Pod-网络" class="headerlink" title="2.1.3 Pod 网络"></a>2.1.3 Pod 网络</h5><pre><code>Pod 网络是指 Kubernetes 中用于实现容器之间通信的网络环境。Pod 中的每个容器都有一个独立的 IP 地址，但它们共享相同的网络命名空间和端口空间，因此可以互相访问和通信。Kubernetes 支持多种网络插件和方案，如 Flannel、Calico、Cilium 等，用户可以根据实际情况进行选择和配置</code></pre><h4 id="2-2-Service"><a href="#2-2-Service" class="headerlink" title="2.2 Service"></a>2.2 Service</h4><pre><code>Service 是 Kubernetes 中用于提供内部负载均衡和服务发现的组件，它可以将同一个应用程序的不同副本暴露在集群内部，并为这些副本提供唯一的虚拟 IP 地址和 DNS 域名。Service 可以通过控制器进行创建、更新和删除操作。</code></pre><h5 id="2-2-1-ClusterIP"><a href="#2-2-1-ClusterIP" class="headerlink" title="2.2.1 ClusterIP"></a>2.2.1 ClusterIP</h5><pre><code>ClusterIP 是 Service 的默认类型，它会分配一个集群内部的虚拟 IP 地址，并将该地址绑定到 Service 上。当其他 Pod 或容器需要访问 Service 时，只需要使用该虚拟 IP 地址即可。</code></pre><h5 id="2-2-2-NodePort"><a href="#2-2-2-NodePort" class="headerlink" title="2.2.2 NodePort"></a>2.2.2 NodePort</h5><pre><code>NodePort 是一种扩展 ClusterIP 的功能，它会在每个节点上分配一个唯一的端口号，并将该端口号映射到 Service 上。当其他节点或外部网络需要访问 Service 时，只需要使用该节点 IP 地址和映射的端口号即可。</code></pre><h5 id="2-2-3-LoadBalancer"><a href="#2-2-3-LoadBalancer" class="headerlink" title="2.2.3 LoadBalancer"></a>2.2.3 LoadBalancer</h5><pre><code>LoadBalancer 是一种针对外部流量的负载均衡方案，它可以通过云服务商提供的负载均衡器或自定义的负载均衡器，将流量从外部网络转发到集群内部的 Service 上。</code></pre><h4 id="2-3-Namespace"><a href="#2-3-Namespace" class="headerlink" title="2.3 Namespace"></a>2.3 Namespace</h4><pre><code>Namespace 是 Kubernetes 中用于隔离和管理资源对象的逻辑分区，它可以帮助用户将不同的资源对象归类、管理和隔离。Kubernetes 中默认存在一些 Namespace，如 default、kube-system 等，用户也可以根据需要创建自定义的 Namespace。</code></pre><h4 id="2-4-DaemonSet"><a href="#2-4-DaemonSet" class="headerlink" title="2.4 DaemonSet"></a>2.4 DaemonSet</h4><pre><code>DaemonSet 是 Kubernetes 中用于在每个节点上运行一组 Pod 的控制器，它通常用于运行系统级别的服务或代理程序等，在每个节点上保证资源对象的一致性和状态。</code></pre><h4 id="2-5-Job"><a href="#2-5-Job" class="headerlink" title="2.5 Job"></a>2.5 Job</h4><pre><code>Job 是 Kubernetes 中用于管理一次性任务的控制器，它会创建一个或多个 Pod 来执行某个任务，并在任务完成后自动删除这些 Pod。Job 还支持任务成功和失败的检测和处理等功能。</code></pre><h4 id="2-6-CronJob"><a href="#2-6-CronJob" class="headerlink" title="2.6 CronJob"></a>2.6 CronJob</h4><pre><code>CronJob 是 Kubernetes 中用于周期性执行任务的控制器，它可以根据用户定义的时间表，自动创建和删除相应的 Job 对象。CronJob 还支持任务成功和失败的检测和处理等功能。</code></pre>]]></content>
      
      
      <categories>
          
          <category> k8s概念 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> k8s </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx</title>
      <link href="/2022/05/08/Nginx/"/>
      <url>/2022/05/08/Nginx/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Nginx-engine-x-是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP-POP3-SMTP服务。"><a href="#Nginx-engine-x-是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP-POP3-SMTP服务。" class="headerlink" title="Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。"></a>Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。</h2>]]></content>
      
      
      <categories>
          
          <category> Nginx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>堆,栈</title>
      <link href="/2022/02/08/java%E4%B8%AD%E5%A0%86%E6%A0%88%E4%BF%A1%E6%81%AF/"/>
      <url>/2022/02/08/java%E4%B8%AD%E5%A0%86%E6%A0%88%E4%BF%A1%E6%81%AF/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>堆栈分析</p><h3 id="1、堆栈"><a href="#1、堆栈" class="headerlink" title="1、堆栈"></a>1、堆栈</h3><pre><code>   (1)使用命令 top -p &lt;pid&gt;,显示java进程，比如14203。   (2)按H,获取每个线程的cpu情况。（shift+H）。  （3）找到内存和cpu占用最高的线程tid，，比如14204。  （4）转换为十六进制得到377c,此为线程id的十六进制表示。  （5）执行jstack &lt;pid&gt;|grep -A &lt;thread ox16 id&gt; ,得到线程信息中137这个线程所在行的后面10行。  （6）查看对应的堆栈信息找出可能存在问题的代码</code></pre>]]></content>
      
      
      <categories>
          
          <category> 堆栈分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 堆 </tag>
            
            <tag> 栈 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MongoDB</title>
      <link href="/2021/11/15/MongoDB/"/>
      <url>/2021/11/15/MongoDB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="MongoDB是一个开源、高性能、无模式的文档型数据库，当初的设计就是用于简化开发和方便扩展，是NoSQL数据库产品中的一种。是最像关系型数据库（MySQL）的非关系型数据库。"><a href="#MongoDB是一个开源、高性能、无模式的文档型数据库，当初的设计就是用于简化开发和方便扩展，是NoSQL数据库产品中的一种。是最像关系型数据库（MySQL）的非关系型数据库。" class="headerlink" title="MongoDB是一个开源、高性能、无模式的文档型数据库，当初的设计就是用于简化开发和方便扩展，是NoSQL数据库产品中的一种。是最像关系型数据库（MySQL）的非关系型数据库。"></a>MongoDB是一个开源、高性能、无模式的文档型数据库，当初的设计就是用于简化开发和方便扩展，是NoSQL数据库产品中的一种。是最像关系型数据库（MySQL）的非关系型数据库。</h2><h3 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h3><p><img src="/image/MongoDB.png" alt="效果图预览"></p><h3 id="MongoDB特点"><a href="#MongoDB特点" class="headerlink" title="MongoDB特点"></a>MongoDB特点</h3><p>高性能</p><p>MongoDB提供高性能的数据持久性。特别是,对嵌入式数据模型的支持减少了数据库系统上的I/O活动。</p><p>索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。（文本索引解决搜索的需求、TTL索引解决历史数据自动过期的需求、地理位置索引可用于构建各种 O2O 应用）</p><p>mmapv1、wiredtiger、mongorocks（rocksdb）、in-memory 等多引擎支持满足各种场景需求。</p><p>Gridfs解决文件存储的需求。</p><p>高可用性</p><p>MongoDB的复制工具称为副本集（replica set），它可提供自动故障转移和数据冗余。</p><p>高可扩展性</p><pre><code>MongoDB提供了水平可扩展性作为其核心功能的一部分。分片将数据分布在一组集群的机器上。（海量数据存储，服务能力水平扩展）从3.4开始，MongoDB支持基于片键创建数据区域。在一个平衡的集群中，MongoDB将一个区域所覆盖的读写只定向到该区域内的那些片。丰富的查询支持MongoDB支持丰富的查询语言，支持读和写操作(CRUD)，比如数据聚合、文本搜索和地理空间查询等。其他特点：如无模式（动态模式）、灵活的文档模型、</code></pre><h3 id="Linux系统中的安装启动和连接"><a href="#Linux系统中的安装启动和连接" class="headerlink" title="Linux系统中的安装启动和连接"></a>Linux系统中的安装启动和连接</h3><p>  到官网下载压缩包 mongod-linux-x86_64-4.0.10.tgz 。</p><p>  上传压缩包到Linux中，解压到当前目录：</p><pre><code>tar -xvf mongodb-linux-x86_64-4.0.10.tgz</code></pre><p>  移动解压后的文件夹到指定的目录中：</p><pre><code> mv mongodb-linux-x86_64-4.0.10 /usr/local/mongodb</code></pre><p>  新建几个目录，分别用来存储数据和日志：</p><p>   数据存储目录<br>     mkdir -p /mongodb/single/data/db<br>   日志存储目录<br>     mkdir -p /mongodb/single/log</p><p>   新建并修改配置文件<br>      vim /mongodb/single/mongod.conf</p><p>   配置文件的内容如下：<br>    systemLog:<br>        #MongoDB发送所有日志输出的目标指定为文件<br>        # #The path of the log file to which mongod or mongos should send all diagnostic   logging information<br>        destination: file<br>        #mongod或mongos应向其发送所有诊断日志记录信息的日志文件的路径<br>        path: “/mongodb/single/log/mongod.log”<br>        #当mongos或mongod实例重新启动时，mongos或mongod会将新条目附加到现有日志文件的末尾。<br>        logAppend: true<br>    storage:<br>        #mongod实例存储其数据的目录。storage.dbPath设置仅适用于mongod。<br>        ##The directory where the mongod instance stores its data.Default Value is “/data/db”.<br>        dbPath: “/mongodb/single/data/db”<br>        journal:<br>            #启用或禁用持久性日志以确保数据文件保持有效和可恢复。<br>            enabled: true<br>    processManagement:<br>        #启用在后台运行mongos或mongod进程的守护进程模式。<br>        fork: true<br>    net:<br>        #服务实例绑定的IP，默认是localhost，115.60.97.40服务器内网地址<br>        bindIp: localhost,115.60.97.40<br>        #bindIp<br>        #绑定的端口，默认是27017<br>        port: 27017<br>   启动MongoDB服务</p><pre><code>[root@master single]# /usr/local/mongodb/bin/mongod --config mongod.confabout to fork child process, waiting until server is ready for connections.forked process: 2923child process started successfully, parent exiting如果启动后不是 successfully ，则是启动失败了。原因基本上就是配置文件有问题。通过进程来查看服务是否启动了：[root@master single]# ps -ef | grep mongodroot       2923      1  0 17:32 ?        00:00:00 /usr/local/mongodb/bin/mongod --config mongod.confroot       2956   1650  0 17:33 pts/0    00:00:00 grep --color=auto mongod分别使用mongo命令和compass工具来连接测试。配置mongo命令到环境变量，修改 /etc/profile 文件，在文件末尾加上如下代码  vim  /etc/profile   export PATH=$PATH:/usr/local/mongodb/bin然后执行命令 source /etc/profile[root@master bin]# mongoMongoDB shell version v4.0.10connecting to: mongodb://127.0.0.1:27017/?gssapiServiceName=mongodbImplicit session: session { &quot;id&quot; : UUID(&quot;b69fa065-b5c2-4bc2-a282-5c34edd4740a&quot;) }MongoDB server version: 4.0.10Welcome to the MongoDB shell.For interactive help, type &quot;help&quot;.For more comprehensive documentation, see        http://docs.mongodb.org/Questions? Try the support group        http://groups.google.com/group/mongodb-userServer has startup warnings:</code></pre><p>   如果远程连接不上，需要配置防火墙放行，或直接关闭linux防火墙</p><p>   #查看防火墙状态<br>   systemctl status firewalld<br>   #临时关闭防火墙<br>   systemctl stop firewalld<br>   #开机禁止启动防火墙<br>   systemctl disable firewalld</p><p>   如果一旦是因为数据损坏，则需要进行如下操作（了解）：</p><pre><code>删除lock文件：rm -f /mongodb/single/data/db/*.lock修复数据：/usr/local/mongdb/bin/mongod --repair --dbpath=/mongodb/single/data/db通过mongo客户端中的shutdownServer命令来关闭服务#客户端登录服务，注意，这里通过localhost登录，如果需要远程登录，必须先登录认证才行。mongo --port 27017#切换到admin库use admin#关闭服务db.shutdownServer()</code></pre><h3 id="数据库操作"><a href="#数据库操作" class="headerlink" title="数据库操作"></a>数据库操作</h3><pre><code>选择和创建数据库的语法格式：use 数据库名称  例如：use articledb查看有权限查看的所有的数据库命令show dbs或show databases查看当前正在使用的数据库命令dbMongoDB 中默认的数据库为 test，如果你没有选择数据库，集合将存放在 test 数据库中。数据库名可以是满足以下条件的任意UTF-8字符串。不能是空字符串（&quot;&quot;)。不得含有&#39; &#39;（空格)、.、$、/、\和\0 (空字符)。应全部小写。最多64字节。有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。admin： 从权限的角度来看，这是&quot;root&quot;数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合config: 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。MongoDB 删除数据库的语法格式如下：db.dropDatabase()集合的显式创建（了解）  基本语法格式：  db.createCollection(name)参数说明:  name: 要创建的集合名称  集合的命名规范：    集合名不能是空字符串&quot;&quot;。    集合名不能含有\0字符（空字符)，这个字符表示集合名的结尾。    集合名不能以&quot;system.&quot;开头，这是为系统集合保留的前缀。    用户创建的集合名字不能含有保留字符。有些驱动程序的确支持在集合名里面包含，这是因为某些系统生成的集合中包含该字符。除非你要访问这种系统创建的集合，否则千万不要在名字里出现$。    集合的隐式创建    当向一个集合中插入一个文档的时候，如果集合不存在，则会自动创建集合。提示：通常我们使用隐式创建文档即可。集合的删除    集合删除语法格式如下：    db.collection.drop()    或    db.集合.drop()返回值  如果成功删除选定集合，则 drop() 方法返回 true，否则返回 false。例如：要删除mycollection集合db.mycollection.drop()文档基本CRUD</code></pre><p>文档（document）的数据结构和 JSON 基本一样。</p><p>所有存储在集合中的数据都是 BSON 格式。</p><p>文档的插入<br>    单个文档插入<br>    使用insert() 或 save()方法向集合中插入文档，语法如下：</p><pre><code>db.collection.insert(    &lt;document or array of documents&gt;,    {        writeConcern: &lt;document&gt;,        ordered: &lt;boolean&gt;    })提示：    comment集合如果不存在，则会隐式创建    mongo中的数字，默认情况下是double类型，如果要存整型，必须使用函数NumberInt(整型数字)，否则取出来就有问题了。    插入当前日期使用 new Date()    插入的数据没有指定 _id ，会自动生成主键值    如果某字段没值，可以赋值为null，或不写该字段。批量文档插入    语法:    db.collection.insertMany(        [ &lt;document 1&gt; , &lt;document 2&gt;, ... ],        {            writeConcern: &lt;document&gt;,            ordered: &lt;boolean&gt;        }文档键命名规范：    键不能含有\0 (空字符)。这个字符用来表示键的结尾。    .和$有特别的意义，只有在特定环境下才能使用。    以下划线&quot;_&quot;开头的键是保留的(不是严格要求的)。   插入时指定了 _id ，则主键就是该值。   如果某条数据插入失败，将会终止插入，但已经插入成功的数据不会回滚掉。   因为批量插入由于数据较多容易出现失败，因此，可以使用try catch进行异常捕捉处理，测试的时候可以不处理。如（了解）：</code></pre><p>   文档的基本查询<br>        查询数据的语法格式如下：</p><pre><code>    db.collection.find(&lt;query&gt;, [projection])    查询所有   如果我们要查询spit集合的所有文档，我们输入以下命令    db.comment.find()    或    db.comment.find({})    db.comment.findOne({userid:&#39;1003&#39;})投影查询    如果要查询结果返回部分字段，则需要使用投影查询（不显示所有字段，只显示指定的字段）。文档的更新更新文档的语法：db.collection.update(query, update, options)//或db.collection.update(    &lt;query&gt;,    &lt;update&gt;,    {        upsert: &lt;boolean&gt;,        multi: &lt;boolean&gt;,        writeConcern: &lt;document&gt;,        collation: &lt;document&gt;,        arrayFilters: [ &lt;filterdocument1&gt;, ... ],        hint: &lt;document|string&gt; // Available starting in MongoDB 4.2    }）覆盖的修改如果我们想修改_id为1的记录，点赞量为1001，输入以下语句：db.comment.update({_id:&quot;1&quot;},{likenum:NumberInt(1001)})执行后，我们会发现，这条文档除了likenum字段其它字段都不见了局部修改为了解决这个问题，我们需要使用修改器$set来实现，命令如下：我们想修改_id为2的记录，浏览量为889，输入以下语句：db.comment.update({_id:&quot;2&quot;},{$set:{likenum:NumberInt(889)}})批量的修改    更新所有用户为 1003 的用户的昵称为 凯撒大帝    //默认只修改第一条数据    db.comment.update({userid:&quot;1003&quot;},{$set:{nickname:&quot;凯撒大帝&quot;}})    //修改所有符合条件的数据    db.comment.update({userid:&quot;1003&quot;},{$set:{nickname:&quot;凯撒大帝&quot;}},{multi:true})删除文档    删除文档的语法结构：    db.集合名称.remove(条件)以下语句可以将数据全部删除，请慎用db.comment.remove({})如果删除_id=1的记录，输入以下语句db.comment.remove({_id:&quot;1&quot;})文档的分页查询统计查询统计查询使用count()方法，语法如下：db.collection.count(query, options)分页列表查询可以使用limit()方法来读取指定数量的数据，使用skip()方法来跳过指定数量的数据。基本语法如下所示：db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER)如果你想返回指定条数的记录，可以在find方法后调用limit来返回结果(TopN)，默认值20，例如：db.comment.find().limit(3)分页查询：需求：每页2个，第二页开始：跳过前两条数据，接着值显示3和4条数据排序查询    sort() 方法对数据进行排序，sort() 方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而 -1 是用于降序排列。    语法如下所示：    db.COLLECTION_NAME.find().sort({KEY:1})    或    db.集合名称.find().sort(排序方式)    例如：    对userid降序排列，并对访问量进行升序排列    db.comment.find().sort({userid:-1,likenum:1})    提示：    skip(), limilt(), sort()三个放在一起执行的时候，执行的顺序是先 sort(), 然后是 skip()，最后是显示的 limit()，和命令编写顺序无关。</code></pre>]]></content>
      
      
      <categories>
          
          <category> MongoDB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go语言基础</title>
      <link href="/2021/08/12/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"/>
      <url>/2021/08/12/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Go-是一个开源的编程语言，它能让构造简单、可靠且高效的软件变得容易。"><a href="#Go-是一个开源的编程语言，它能让构造简单、可靠且高效的软件变得容易。" class="headerlink" title=" Go 是一个开源的编程语言，它能让构造简单、可靠且高效的软件变得容易。"></a> Go 是一个开源的编程语言，它能让构造简单、可靠且高效的软件变得容易。</h2><h3 id="一、Go-语言的基础组成"><a href="#一、Go-语言的基础组成" class="headerlink" title="一、Go 语言的基础组成"></a>一、Go 语言的基础组成</h3><pre><code>Go 语言的基础组成有以下几个部分：    包声明    引入包    函数    变量    语句 &amp; 表达式    注释</code></pre><h3 id="二、Go-关键字"><a href="#二、Go-关键字" class="headerlink" title="二、Go 关键字"></a>二、Go 关键字</h3><pre><code>25 个关键字或保留字：</code></pre><p> <img src="/image/Go%E5%85%B3%E9%94%AE%E5%AD%97.png" alt="效果图预览"><br>    36 个预定义标识符：<br> <img src="/image/Go%E9%A2%84%E5%AE%9A%E4%B9%89%E6%A0%87%E8%AF%86%E7%AC%A6.png" alt="效果图预览"> </p><h3 id="三、Go-语言数据类型"><a href="#三、Go-语言数据类型" class="headerlink" title="三、Go 语言数据类型"></a>三、Go 语言数据类型</h3><pre><code>在 Go 编程语言中，数据类型用于声明函数和变量。布尔型    布尔型的值只可以是常量 true 或者 false。一个简单的例子：var b bool = true。数字类型    整型 int 和浮点型 float，Go 语言支持整型和浮点型数字，并且原生支持复数，其中位的运算采用补码。字符串类型:    字符串就是一串固定长度的字符连接起来的字符序列。Go的字符串是由单个字节连接起来的。Go语言的字符串的字节使用UTF-8编码标识Unicode文本。派生类型:    包括：        (a) 指针类型（Pointer）        (b) 数组类型        (c) 结构体类型(struct)        (d) 联合体类型 (union)        (e) 函数类型        (f) 切片类型        (g) 接口类型（interface）        (h) Map 类型        (i) Channel 类型数字类型    Go 也有基于架构的类型，例如：int、uint 和 uintptr。     uint8        无符号 8 位整型 (0 到 255)     uint16        无符号 16 位整型 (0 到 65535)     uint32        无符号 32 位整型 (0 到 4294967295)     uint64        无符号 64 位整型 (0 到 18446744073709551615)     int8        有符号 8 位整型 (-128 到 127)    int16        有符号 16 位整型 (-32768 到 32767)    int32        有符号 32 位整型 (-2147483648 到 2147483647)    int64        有符号 64 位整型 (-9223372036854775808 到 9223372036854775807)浮点型：    float32        IEEE-754 32位浮点型数    float64        IEEE-754 64位浮点型数    complex64        32 位实数和虚数    complex128        64 位实数和虚数其他数字类型：    byte        类似 uint8    rune        类似 int32    uint        32 或 64 位    int        与 uint 一样大小    uintptr        无符号整型，用于存放一个指针</code></pre><h3 id="三、Go-语言变量"><a href="#三、Go-语言变量" class="headerlink" title="三、Go 语言变量"></a>三、Go 语言变量</h3><pre><code>Go 语言变量名由字母、数字、下划线组成，其中首个字母不能为数字。</code></pre><h3 id="四、Go-算术运算符"><a href="#四、Go-算术运算符" class="headerlink" title="四、Go 算术运算符"></a>四、Go 算术运算符</h3><pre><code>假定 A 值为 10，B 值为 20</code></pre><p> <img src="/image/Go%E7%AE%97%E6%95%B0%E8%BF%90%E7%AE%97%E7%AC%A6.png" alt="效果图预览"> </p><h3 id="五、Go-关系运算符"><a href="#五、Go-关系运算符" class="headerlink" title="五、Go 关系运算符"></a>五、Go 关系运算符</h3><pre><code>假定 A 值为 10，B 值为 20</code></pre><p> <img src="/image/Go%E5%85%B3%E7%B3%BB%E8%BF%90%E7%AE%97%E7%AC%A6.png" alt="效果图预览"> </p><h3 id="六、Go-逻辑运算符"><a href="#六、Go-逻辑运算符" class="headerlink" title="六、Go 逻辑运算符"></a>六、Go 逻辑运算符</h3><pre><code>假定 A 值为 True，B 值为 False</code></pre><p> <img src="/image/Go%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6.png" alt="效果图预览"> </p><h3 id="七、Go-位运算符"><a href="#七、Go-位运算符" class="headerlink" title="七、Go 位运算符"></a>七、Go 位运算符</h3><pre><code> &amp;：与运算，全真为真；  |：或运算，全假才假；  ^:异或运算，相同为假，不同为真 假定 A 为60，B 为13</code></pre><p>  <img src="/image/Go%E4%BD%8D%E8%BF%90%E7%AE%97%E7%AC%A6.png" alt="效果图预览"> </p><h3 id="八、Go-赋值运算符"><a href="#八、Go-赋值运算符" class="headerlink" title="八、Go 赋值运算符"></a>八、Go 赋值运算符</h3><p><img src="/image/Go%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97%E7%AC%A6.png" alt="效果图预览"> </p><h3 id="九、Go-其他运算符"><a href="#九、Go-其他运算符" class="headerlink" title="九、Go 其他运算符"></a>九、Go 其他运算符</h3><p><img src="/image/Go%E5%85%B6%E4%BB%96%E8%BF%90%E7%AE%97%E7%AC%A6.png" alt="效果图预览"> </p><h3 id="十、Go-运算符优先级"><a href="#十、Go-运算符优先级" class="headerlink" title="十、Go 运算符优先级"></a>十、Go 运算符优先级</h3><pre><code>有些运算符拥有较高的优先级，二元运算符的运算方向均是从左至右。下表列出了所有运算符以及它们的优先级，由上至下代表优先级由高到低</code></pre><p><img src="/image/Go%E8%BF%90%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E7%BA%A7.png" alt="效果图预览"> </p><h3 id="十一、Go-判断语句"><a href="#十一、Go-判断语句" class="headerlink" title="十一、Go 判断语句"></a>十一、Go 判断语句</h3><p><img src="/image/Go%E5%88%A4%E6%96%AD%E8%AF%AD%E5%8F%A5.png" alt="效果图预览"> </p><h3 id="十二、Go-语言函数"><a href="#十二、Go-语言函数" class="headerlink" title="十二、Go 语言函数"></a>十二、Go 语言函数</h3><pre><code>函数是基本的代码块，用于执行一个任务。Go 语言最少有1个 main() 函数。你可以通过函数来划分不同功能，逻辑上每个函数执行的是指定的任务。函数声明告诉了编译器函数的名称，返回类型和参数。Go 语言函数定义格式如下：    func function_name( [parameter list] ) [return_types]{    函数体    }函数定义解析：    func：函数由 func 开始声明    function_name：函数名称，函数名和参数列表一起构成了函数签名。    parameter list：参数列表，参数就像一个占位符，当函数被调用时，你可以将值传递给参数，这个值被称为实际参数。参数列表指定的是参数类型、顺序及参数个数。参数是可选的，也就是说函数也可以不包含参数。    return_types：返回类型，函数返回一列值。return_types 是该列值的数据类型。有些功能不需要返回值，这种情况下 return_types 不是必须的。    函数体：函数定义的代码集合。Go 函数可以返回多个值</code></pre><h3 id="十三、函数参数"><a href="#十三、函数参数" class="headerlink" title="十三、函数参数"></a>十三、函数参数</h3><pre><code>函数如果使用参数，该变量可称为函数的形参。形参就像定义在函数体内的局部变量。调用函数，可以通过两种方式来传递参数：    值传递：值传递是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。    引用传递：引用传递是指在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。默认情况下，Go 语言使用的是值传递，即在调用过程中不会影响到实际参数。</code></pre><h3 id="十四、defer语句"><a href="#十四、defer语句" class="headerlink" title="十四、defer语句"></a>十四、defer语句</h3><pre><code>Go语言中的defer语句会将其后面跟随的语句进行延迟处理在defer所属的函数即将返回时，将延迟处理的语句按照defer定义的顺序逆序执行，即先进后出。package mainimport &quot;fmt&quot;func main() {    fmt.Println(&quot;开始&quot;)    defer fmt.Println(1)    defer fmt.Println(2)    defer fmt.Println(3)    fmt.Println(&quot;结束&quot;)}代码执行结果如下：开始结束321</code></pre><h3 id="十五、Go-语言变量作用域"><a href="#十五、Go-语言变量作用域" class="headerlink" title="十五、Go 语言变量作用域"></a>十五、Go 语言变量作用域</h3><pre><code>作用域为已声明标识符所表示的常量、类型、变量、函数或包在源代码中的作用范围。Go 语言中变量可以在三个地方声明：    函数内定义的变量称为局部变量    函数外定义的变量称为全局变量    函数定义中的变量称为形式参数</code></pre><h4 id="15-1、局部变量"><a href="#15-1、局部变量" class="headerlink" title="15.1、局部变量"></a>15.1、局部变量</h4><pre><code>在函数体内声明的变量称之为局部变量，它们的作用域只在函数体内，参数和返回值变量也是局部变量。</code></pre><h4 id="15-2、全局变量"><a href="#15-2、全局变量" class="headerlink" title="15.2、全局变量"></a>15.2、全局变量</h4><pre><code>在函数体外声明的变量称之为全局变量，全局变量可以在整个包甚至外部包（被导出后）使用。</code></pre><h4 id="15-3、形式参数"><a href="#15-3、形式参数" class="headerlink" title="15.3、形式参数"></a>15.3、形式参数</h4><pre><code>形式参数会作为函数的局部变量来使用。</code></pre><h3 id="十六、初始化局部和全局变量"><a href="#十六、初始化局部和全局变量" class="headerlink" title="十六、初始化局部和全局变量"></a>十六、初始化局部和全局变量</h3><pre><code>不同类型的局部和全局变量默认值为：</code></pre><p><img src="/image/Go%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%98%E9%87%8F.png" alt="效果图预览"> </p><h3 id="十七、Go-语言数组"><a href="#十七、Go-语言数组" class="headerlink" title="十七、Go 语言数组"></a>十七、Go 语言数组</h3><pre><code>数组是具有相同唯一类型的一组已编号且长度固定的数据项序列，这种类型可以是任意的原始类型例如整型、字符串或者自定义类型。</code></pre><h3 id="十八、Go-语言指针"><a href="#十八、Go-语言指针" class="headerlink" title="十八、Go 语言指针"></a>十八、Go 语言指针</h3><pre><code>Go 语言的取地址符是 &amp;，放到一个变量前使用就会返回相应变量的内存地址。地址&amp; 取值*</code></pre><h3 id="十九、Go-语言结构体"><a href="#十九、Go-语言结构体" class="headerlink" title="十九、Go 语言结构体"></a>十九、Go 语言结构体</h3><pre><code>Go 语言中数组可以存储同一类型的数据，但在结构体中我们可以为不同项定义不同的数据类型。结构体是由一系列具有相同类型或不同类型的数据构成的数据集合。</code></pre><h4 id="19-1、定义结构体"><a href="#19-1、定义结构体" class="headerlink" title="19.1、定义结构体"></a>19.1、定义结构体</h4><pre><code>结构体定义需要使用 type 和 struct 语句。struct 语句定义一个新的数据类型，结构体中有一个或多个成员。type 语句设定了结构体的名称。结构体的格式如下：type struct_variable_type struct {    member definition    member definition    ...    member definition}</code></pre><h3 id="二十、Go-语言切片"><a href="#二十、Go-语言切片" class="headerlink" title="二十、Go 语言切片"></a>二十、Go 语言切片</h3><pre><code>Go 语言切片是对数组的抽象。Go 数组的长度不可改变，在特定场景中这样的集合就不太适用，Go中提供了一种灵活，功能强悍的内置类型切片(&quot;动态数组&quot;),与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大。</code></pre><h4 id="20-1、定义切片"><a href="#20-1、定义切片" class="headerlink" title="20.1、定义切片"></a>20.1、定义切片</h4><pre><code>var identifier []type或使用make()函数来创建切片:    var slice1 []type = make([]type, len)</code></pre><h3 id="二十一、Go-语言范围"><a href="#二十一、Go-语言范围" class="headerlink" title="二十一、Go 语言范围"></a>二十一、Go 语言范围</h3><pre><code>Go 语言中 range 关键字用于for循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素。在数组和切片中它返回元素的索引值，在集合中返回 key-value 对的 key 值。</code></pre><h3 id="二十二、Go-语言Map"><a href="#二十二、Go-语言Map" class="headerlink" title="二十二、Go 语言Map"></a>二十二、Go 语言Map</h3><pre><code>Map 是一种无序的键值对的集合。Map 最重要的一点是通过 key 来快速检索数据，key 类似于索引，指向数据的值。Map 是一种集合，所以我们可以像迭代数组和切片那样迭代它。不过，Map 是无序的，我们无法决定它的返回顺序，这是因为 Map 是使用 hash 表来实现的。</code></pre><h4 id="22-1、定义切片定义-Map"><a href="#22-1、定义切片定义-Map" class="headerlink" title="22.1、定义切片定义 Map"></a>22.1、定义切片定义 Map</h4><pre><code>可以使用内建函数 make 也可以使用 map 关键字来定义 Map:/* 声明变量，默认 map 是 nil */var map_variable map[key_data_type]value_data_type/* 使用 make 函数 */map_variable = make(map[key_data_type]value_data_type)</code></pre><h3 id="二十三、Go-语言接口"><a href="#二十三、Go-语言接口" class="headerlink" title="二十三、Go 语言接口"></a>二十三、Go 语言接口</h3><pre><code>Go 语言提供了另外一种数据类型即接口，它把所有的具有共性的方法定义在一起，任何其他类型只要实现了这些方法就是实现了这个接口。/* 定义接口 */type interface_name interface {method_name1 [return_type]method_name2 [return_type]method_name3 [return_type]...method_namen [return_type]}/* 定义结构体 */type struct_name struct {/* variables */}/* 实现接口方法 */func (struct_name_variable struct_name) method_name1() [return_type] {/* 方法实现 */}...func (struct_name_variable struct_name) method_namen() [return_type] {/* 方法实现*/}实现：package mainimport (    &quot;fmt&quot;)type Phone interface {    call()}type NokiaPhone struct {}func (nokiaPhone NokiaPhone) call() {    fmt.Println(&quot;I am Nokia, I can call you!&quot;)}type IPhone struct {}func (iPhone IPhone) call() {    fmt.Println(&quot;I am iPhone, I can call you!&quot;)}func main() {    var phone Phone    phone = new(NokiaPhone)    phone.call()    phone = new(IPhone)    phone.call()}</code></pre><h3 id="二十四、Go-错误处理"><a href="#二十四、Go-错误处理" class="headerlink" title="二十四、Go 错误处理"></a>二十四、Go 错误处理</h3><pre><code>Go 语言通过内置的错误接口提供了非常简单的错误处理机制。error类型是一个接口类型，这是它的定义：    type error interface {        Error() string    }</code></pre><h3 id="二十五、Go-语言反射"><a href="#二十五、Go-语言反射" class="headerlink" title="二十五、Go 语言反射"></a>二十五、Go 语言反射</h3><pre><code>Go语言提供了一种机制，在不知道具体类型的情况下，可以用反射来更新变量值，查看变量类型。Typeof    Typeof返回接口中保存的值得类型，Typeof(nil)会返回nilValueOf    ValueOf返回一个初始化为interface接口保管的具体值得Value，ValueOf(nil)返回Value零值</code></pre><h3 id="二十六、Go-语言并发"><a href="#二十六、Go-语言并发" class="headerlink" title="二十六、Go 语言并发"></a>二十六、Go 语言并发</h3><pre><code>并发与并行    并发：同一时间段内执行多个任务    并行：同一时刻执行多个任务Go语言中的并发程序主要是通过基于CSP（communicating sequential processes）的goroutine和channel来实现，当然也支持使用传统的多线程共享内存的并发方式</code></pre>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch</title>
      <link href="/2021/07/02/ElasticSearch/"/>
      <url>/2021/07/02/ElasticSearch/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能"><a href="#一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能" class="headerlink" title="一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能"></a>一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能</h2><h3 id="初识elasticsearch"><a href="#初识elasticsearch" class="headerlink" title="初识elasticsearch"></a>初识elasticsearch</h3><pre><code>elasticsearch底层是基于lucene来实现的。Lucene是一个Java语言的搜索引擎类库，是Apache公司的顶级项目，由DougCutting于1999年研发。官网地址：https://lucene.apache.org/ 。</code></pre><h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><p>   倒排索引中有两个非常重要的概念：</p><pre><code>文档（Document）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息词条（Term）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条创建倒排索引是对正向索引的一种特殊处理，流程如下：将每一个文档的数据利用算法分词，得到一个个词条创建表，每行数据包括词条、词条所在文档id、位置等信息因为词条唯一性，可以给词条创建索引，例如hash表结构索引</code></pre><h3 id="正向和倒排对比"><a href="#正向和倒排对比" class="headerlink" title="正向和倒排对比"></a>正向和倒排对比</h3><pre><code>概念区别：    正向索引是最传统的，根据id索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条，是根据文档找词条的过程。    而倒排索引则相反，是先找到用户要搜索的词条，根据词条得到保护词条的文档的id，然后根据id获取文档。是根据词条找文档的过程。    优缺点：    正向索引：        优点：        可以给多个字段创建索引        根据索引字段搜索、排序速度非常快        缺点：        根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描。    倒排索引：        优点：        根据词条搜索、模糊搜索时，速度非常快        缺点：        只能给词条创建索引，而不是字段        无法根据字段做排序</code></pre><h3 id="文档和字段"><a href="#文档和字段" class="headerlink" title="文档和字段"></a>文档和字段</h3><pre><code>一个文档就像数据库里的一条数据，字段就像数据库里的列elasticsearch是面向文档（Document）存储的，可以是数据库中的一条商品数据，一个订单信息。</code></pre><h3 id="索引和映射"><a href="#索引和映射" class="headerlink" title="索引和映射"></a>索引和映射</h3><pre><code>索引就像数据库里的表，映射就像数据库中定义的表结构索引（Index），就是相同类型的文档的集合【类似mysql中的表】</code></pre><h3 id="mysql与elasticsearch"><a href="#mysql与elasticsearch" class="headerlink" title="mysql与elasticsearch"></a>mysql与elasticsearch</h3><pre><code>Mysql：擅长事务类型操作，可以确保数据的安全和一致性Elasticsearch：擅长海量数据的搜索、分析、计算</code></pre><h3 id="安装es、kibana、分词器"><a href="#安装es、kibana、分词器" class="headerlink" title="安装es、kibana、分词器"></a>安装es、kibana、分词器</h3><pre><code>分词器的作用是    创建倒排索引时对文档分词    用户搜索时，对输入的内容分词IK分词器有几种模式    ik_smart：智能切分，粗粒度    ik_max_word：最细切分，细粒度IK分词器如何拓展词条？如何停用词条？    利用config目录的IkAnalyzer.cfg.xml文件添加拓展词典和停用词典    在词典中添加拓展词条或者停用词条</code></pre><h3 id="部署单点es"><a href="#部署单点es" class="headerlink" title="部署单点es"></a>部署单点es</h3><h4 id="创建网络"><a href="#创建网络" class="headerlink" title="创建网络"></a>创建网络</h4><pre><code>因为我们还需要部署kibana容器，因此需要让es和kibana容器互联。这里先创建一个网络：docker network create es-net</code></pre><h4 id="加载镜像"><a href="#加载镜像" class="headerlink" title="加载镜像"></a>加载镜像</h4><pre><code>我们采用elasticsearch的7.12.1版本的镜像，这个镜像体积非常大，接近1G。</code></pre><h4 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h4><pre><code>运行docker命令，部署单点es：     docker run -d \--name es \-e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; \-e &quot;discovery.type=single-node&quot; \-v es-data:/usr/share/elasticsearch/data \-v es-plugins:/usr/share/elasticsearch/plugins \--privileged \--network es-net \-p 9200:9200 \-p 9300:9300 \elasticsearch:7.12.1</code></pre><p>   命令解释：</p><pre><code>-e &quot;cluster.name=es-docker-cluster&quot;：设置集群名称-e &quot;http.host=0.0.0.0&quot;：监听的地址，可以外网访问-e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;：内存大小-e &quot;discovery.type=single-node&quot;：非集群模式-v es-data:/usr/share/elasticsearch/data：挂载逻辑卷，绑定es的数据目录-v es-logs:/usr/share/elasticsearch/logs：挂载逻辑卷，绑定es的日志目录-v es-plugins:/usr/share/elasticsearch/plugins：挂载逻辑卷，绑定es的插件目录--privileged：授予逻辑卷访问权--network es-net ：加入一个名为es-net的网络中-p 9200:9200：端口映射配置</code></pre><h4 id="部署kibana"><a href="#部署kibana" class="headerlink" title="部署kibana"></a>部署kibana</h4><p>  kibana可以给我们提供一个elasticsearch的可视化界面</p><p>  再运行docker命令，部署kibana</p><pre><code>docker run -d \--name kibana \-e ELASTICSEARCH_HOSTS=http://es:9200 \--network=es-net \-p 5601:5601  \kibana:7.12.1--network es-net ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中-e ELASTICSEARCH_HOSTS=http://es:9200&quot;：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直 接   访问elasticsearch-p 5601:5601：端口映射配置kibana启动一般比较慢，需要多等待一会，可以通过命令：</code></pre><p>   docker logs -f kibana</p><h4 id="安装IK分词器"><a href="#安装IK分词器" class="headerlink" title="安装IK分词器"></a>安装IK分词器</h4><h1 id="进入容器内部"><a href="#进入容器内部" class="headerlink" title="进入容器内部"></a>进入容器内部</h1><p>docker exec -it elasticsearch /bin/bash</p><h1 id="在线下载并安装"><a href="#在线下载并安装" class="headerlink" title="在线下载并安装"></a>在线下载并安装</h1><pre><code>./bin/elasticsearch-plugin  install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip#退出exit#重启容器docker restart elasticsearch</code></pre><h3 id="文档操作"><a href="#文档操作" class="headerlink" title="文档操作"></a>文档操作</h3><pre><code>创建文档：POST /{索引库名}/_doc/文档id查询文档：GET /{索引库名}/_doc/文档id删除文档：DELETE /{索引库名}/_doc/文档id修改文档：全量修改：PUT /{索引库名}/_doc/文档id增量修改：POST /{索引库名}/_update/文档id { &quot;doc&quot;: {字段}}</code></pre><h4 id="新增文档"><a href="#新增文档" class="headerlink" title="新增文档"></a>新增文档</h4><pre><code>POST /索引库名/_doc/文档id{    &quot;字段1&quot;: &quot;值1&quot;,    &quot;字段2&quot;: &quot;值2&quot;,    &quot;字段3&quot;: {        &quot;子属性1&quot;: &quot;值3&quot;,        &quot;子属性2&quot;: &quot;值4&quot;    },    // ...}</code></pre><h4 id="查询文档"><a href="#查询文档" class="headerlink" title="查询文档"></a>查询文档</h4><pre><code>GET /{索引库名称}/_doc/{id}//批量查询：查询该索引库下的全部文档GET /{索引库名称}/_search</code></pre><h4 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h4><pre><code>DELETE /{索引库名}/_doc/id值</code></pre><h4 id="修改文档"><a href="#修改文档" class="headerlink" title="修改文档"></a>修改文档</h4><pre><code>修改有两种方式：全量修改：直接覆盖原来的文档增量修改：修改文档中的部分字段</code></pre><h5 id="全量修改"><a href="#全量修改" class="headerlink" title="全量修改"></a>全量修改</h5><pre><code>全量修改是覆盖原来的文档，其本质是：根据指定的id删除文档新增一个相同id的文档注意：如果根据id删除时，id不存在，第二步的新增也会执行，也就从修改变成了新增操作了。语法：PUT /{索引库名}/_doc/文档id{    &quot;字段1&quot;: &quot;值1&quot;,    &quot;字段2&quot;: &quot;值2&quot;,    // ... 略}</code></pre><h5 id="增量修改"><a href="#增量修改" class="headerlink" title="增量修改"></a>增量修改</h5><pre><code>增量修改是只修改指定id匹配的文档中的部分字段。语法：POST /{索引库名}/_update/文档id{    &quot;doc&quot;: {        &quot;字段名&quot;: &quot;新的值&quot;,    }}</code></pre><h4 id="分片和副本"><a href="#分片和副本" class="headerlink" title="分片和副本"></a>分片和副本</h4><pre><code>为了支持大规模数据存储和高并发查询，Elasticsearch 将索引划分为多个分片，每个分片可以存储一部分数据。数据分片是 Elasticsearch 实现分布式扩展性和高可用性的核心机制之一。分片使 Elasticsearch 可以在多个节点上平均分布数据，从而提高了查询性能和可用性。</code></pre><h3 id="主分片和副本分片"><a href="#主分片和副本分片" class="headerlink" title="主分片和副本分片"></a>主分片和副本分片</h3><p>   每个索引都可以被划分为多个主分片和多个副本分片。主分片是包含文档的原始分片，每个分片都是一个 Lucene 索引，其中包含了处理索引文档所需的所有信息。副本分片是主分片的备份，并且可以在 Elasticsearch 集群中的其他节点上复制。副本分片通常用于提高查询性能和冗余备份，如果某个节点离线或部分故障，我们可以使用其他节点上的副本分片来替代。</p><h3 id="Elasticsearch的索引"><a href="#Elasticsearch的索引" class="headerlink" title="Elasticsearch的索引"></a>Elasticsearch的索引</h3><p>   Elasticsearch的索引是一个具有相似特性的文档的集合。索引由多个分片组成，每个分片可以是一个主分片或副本分片。当文档被索引时，它会被分配到一个主分片上，然后副本分片会从主分片上复制数据，以提供数据的高可用性和故障恢复能力。</p><h3 id="Elasticsearch的倒排索引"><a href="#Elasticsearch的倒排索引" class="headerlink" title="Elasticsearch的倒排索引"></a>Elasticsearch的倒排索引</h3><p>   倒排索引是一种将文档中的单词与包含这些单词的文档建立映射的数据结构。在Elasticsearch中，倒排索引由单词词典和倒排列表组成。单词词典包含文档中出现的所有单词及其出现的频率和位置信息，倒排列表则包含包含某个单词的所有文档的列表。</p><h3 id="Elasticsearch中的映射"><a href="#Elasticsearch中的映射" class="headerlink" title="Elasticsearch中的映射"></a>Elasticsearch中的映射</h3><p>   映射是定义索引中字段的结构和属性的过程。映射定义了字段的名称、数据类型、分析器和其他属性，以确保索引和搜索的正确性和效率。映射可以通过REST API或配置文件进行定义。</p><h3 id="Elasticsearch的优化策略"><a href="#Elasticsearch的优化策略" class="headerlink" title="Elasticsearch的优化策略"></a>Elasticsearch的优化策略</h3><pre><code>调整索引设置：可以通过调整索引的shard数量、副本数量等设置，以提高索引的性能和可靠性。优化数据模型：合理设计数据模型，避免深度嵌套和大量使用text类型字段，可以降低索引的复杂度和提高查询效率。使用合适的分析器：根据具体需求选择合适的分析器，可以避免全文本检索时的歧义和错误。优化查询语句：通过优化查询语句，使用合适的查询方式和过滤条件，可以减少查询的复杂度和提高查询效率。使用缓存：通过合理使用Elasticsearch的缓存机制，可以避免不必要的磁盘IO和网络传输，提高查询效率。调整系统配置：通过调整系统的JVM参数、操作系统参数等配置，可以优化系统的性能和稳定性，提高Elasticsearch的运行效率。设计阶段调优（1）根据业务增量需求，采取基于日期模板创建索引，通过 roll over API 滚动索引；（2）使用别名进行索引管理；（3）每天凌晨定时对索引做 force_merge 操作，以释放空间；（4）采取冷热分离机制，热数据存储到 SSD，提高效率；冷数据定期进行shrink操作,缩减存储;（5）采取 curator 进行索引的生命周期管理（6）仅针对需要分词的字段，合理的设置分词器；（7）Mapping 阶段充分结合各个字段的属性，是否需要检索、是否需要存储查询调优阶段（1）禁用 wildcard；（2）禁用批量 terms（成百上千的场景）；（3）充分利用倒排索引机制，能 keyword 类型尽量 keyword；（4）数据量大时候，可以先基于时间敲定索引再检索；（5）设置合理的路由机制。    1、写入前副本数设置为 0；    2、写入前关闭 refresh_interval 设置为-1，禁用刷新机制；    3、写入过程中：采取 bulk 批量写入；    4、写入后恢复副本数和刷新间隔；    5、尽量使用自动生成的 id。部署调优，业务调优等。部署时，对 Linux 的设置有哪些优化方法:    1、关闭缓存 swap;    2、堆内存设置为：Min（节点内存/2, 32GB）;    3、设置最大文件句柄数；    4、线程池+队列大小根据业务需要做调整；    5、磁盘存储 raid 方式——存储有条件使用 RAID10，增加单节点性能以及避免单    节点存储故障。</code></pre><h3 id="ES-分片策略"><a href="#ES-分片策略" class="headerlink" title="ES 分片策略"></a>ES 分片策略</h3><pre><code>ES（Elasticsearch）的分区策略主要涉及如何将索引数据分配给多个分片，以实现分布式的数据存储和查询。ES的分区策略是基于哈希算法的，通过将文档的ID或其他字段值进行哈希计算，然后将结果映射到特定的分片上，以实现数据的均匀分布。</code></pre><h3 id="Elasticsearch索引文档的过程"><a href="#Elasticsearch索引文档的过程" class="headerlink" title="Elasticsearch索引文档的过程"></a>Elasticsearch索引文档的过程</h3><pre><code>第一步：客户写集群某节点写入数据，发送请求。（如果没有指定路由/协调节点，请求的节点扮演路由节点的角色。）第二步：节点1接受到请求后，使用文档_id来确定文档属于分片0。请求会被转到另外的节点，假定节点3。因此分片0的主分片分配到节点3上。第三步：节点3在主分片上执行写操作，如果成功，则将请求并行转发到节点1和节点2的副本分片上，等待结果返回。所有的副本分片都报告成功，节点3将向协调节点（节点1）报告成功，节点1向请求客户端报告写入成功。</code></pre><h3 id="elasticsearch-是如何实现-master-选举"><a href="#elasticsearch-是如何实现-master-选举" class="headerlink" title="elasticsearch 是如何实现 master 选举"></a>elasticsearch 是如何实现 master 选举</h3><pre><code>Elasticsearch 实现 Master 选举的方式是使用 Zen Discovery 机制。在 Zen Discovery 中，每个节点都知道集群中的所有节点，并通过心跳检测来检查其他节点是否可用。当节点发现当前的 Master 节点不可用时，它会与其他候选节点进行协调，并通过多数决定的方式选出新的 Master 节点。选出 Master 节点后，其他节点会将请求发送到该节点进行处理。前置前提：1、 只有候选主节点（master：true）的节点才能成为主节点。2、 最小主节点数（min_master_nodes）的目的是防止脑裂。</code></pre><p>   选举流程大致描述如下：</p><pre><code>第一步：确认候选主节点数达标，elasticsearch.yml 设置的值discovery.zen.minimum_master_nodes；第二步：比较：先判定是否具备 master 资格，具备候选主节点资格的优先返回；</code></pre><h3 id="Lucene"><a href="#Lucene" class="headerlink" title="Lucene"></a>Lucene</h3><pre><code>Lucene是apache下的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。官网地址：https://lucene.apache.org/</code></pre><h3 id="Solr"><a href="#Solr" class="headerlink" title="Solr"></a>Solr</h3><pre><code>Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。官网地址：http://lucene.apache.org/solrElasticsearch的优缺点：优点：1.Elasticsearch是分布式的。不需要其他组件，分发是实时的，被叫做&quot;Push replication&quot;。2.Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。3.处理多租户（multitenancy）不需要特殊配置，而Solr则需要更多的高级设置。4.Elasticsearch 采用 Gateway 的概念，使得完备份更加简单。5.各节点组成对等的网络结构，某些节点出现故障时会自动分配其他节点代替其进行工作。缺点：1.只有一名开发者（当前Elasticsearch GitHub组织已经不只如此，已经有了相当活跃的维护者）2.还不够自动（不适合当前新的Index Warmup API）Solr的优缺点：优点1.Solr有一个更大、更成熟的用户、开发和贡献者社区。2.支持添加多种格式的索引，如：HTML、PDF、微软 Office 系列软件格式以及 JSON、XML、CSV 等纯文本格式。3.Solr比较成熟、稳定。4.不考虑建索引的同时进行搜索，速度更快。缺点1.建立索引时，搜索效率下降，实时索引搜索效率不高。二者安装都很简单；2.Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能;3.Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式；4.Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供；5.Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。6.Solr 是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用。1.维基百科使用Elasticsearch来进行全文搜做并高亮显示关键词，以及提供search-as-you-type、did-you-mean等搜索建议功能。2.英国卫报使用Elasticsearch来处理访客日志，以便能将公众对不同文章的反应实时地反馈给各位编辑。3.StackOverflow将全文搜索与地理位置和相关信息进行结合，以提供more-like-this相关问题的展现。4.GitHub使用Elasticsearch来检索超过1300亿行代码。5.每天，Goldman Sachs使用它来处理5TB数据的索引，还有很多投行使用它来分析股票市场的变动。</code></pre><h3 id="ES并发量很大怎么办"><a href="#ES并发量很大怎么办" class="headerlink" title="ES并发量很大怎么办"></a>ES并发量很大怎么办</h3><pre><code>水平扩展集群：将ES集群分成多个节点，每个节点负责一部分数据。这样可以将查询请求和索引请求分散到多个节点上，从而提高集群的吞吐量和并发能力。提高硬件性能：可以增加节点的硬件配置，如CPU、内存和存储等资源，以提升节点的处理能力和响应速度。优化查询和索引操作：通过优化查询语句、使用索引、限制返回字段等方式，来减少查询请求和索引请求的响应时间和资源消耗。调整ES配置参数：根据集群的实际情况，调整ES的配置参数，如线程池大小、缓存设置等，以充分利用硬件资源并提高性能。使用负载均衡：在集群前端引入负载均衡器，将请求分发到不同的节点上，从而平衡负载并提高集群的并发处理能力。监控和调优：定期对ES集群进行监控和分析，找出性能瓶颈并进行调优。可以使用ES自带的监控工具或第三方监控工具来进行监控和分析。数据冷热分离：根据数据的访问频率和时效性，将热数据和冷数据进行分离存储。对于热数据，可以存储在高性能的存储设备上，以提高访问速度；对于冷数据，可以存储在低成本、大容量的存储设备上，以降低成本。使用缓存：在ES集群中引入缓存机制，如Redis等，将热门查询结果缓存起来，减少对ES的直接查询压力。限流和降级：在并发量过高的情况下，可以考虑使用限流和降级策略，保证核心业务的正常运行。分布式部署：将ES集群部署在多个地区或多个可用区，提高数据的可用性和容灾能力。</code></pre><h3 id="ES分片不均"><a href="#ES分片不均" class="headerlink" title="ES分片不均"></a>ES分片不均</h3><pre><code>es分片不均匀如何处理Elasticsearch集群中的分片不均匀分布时，可能会导致集群性能下降、资源利用率不高以及数据分布不均等问题。为了处理分片不均匀的情况，可以采取以下几种策略：手动重新分配分片：可以使用Elasticsearch的API手动将分片从某些节点移动到其他节点。POST /_cluster/reroute{&quot;commands&quot; : [    {    &quot;move&quot; : {        &quot;index&quot; : &quot;index_name&quot;,        &quot;shard&quot; : 0,        &quot;from_node&quot; : &quot;node_1&quot;,        &quot;to_node&quot; : &quot;node_2&quot;    }    }]}自动分配分片：通过Elasticsearch的自动分配机制，可以通过以下API触发一次分片分配：POST /_cluster/reroute?retry_failed=true调整分片数：在创建索引时，可以根据节点数量和预期的数据量来合理设置分片数量，以便更好地分配负载。索引模板：使用索引模板可以预设特定索引的分片和副本配置。监控和诊断：定期监控集群的分片分配情况，使用Elasticsearch的监控和诊断工具，如Kibana或Elasticsearch的API。当发现不均匀时，采取上述策略手动或自动调整。集群扩展：如果是资源不足导致分片不均匀，可以增加更多的节点到集群中，以自动分配更多的分片。</code></pre>]]></content>
      
      
      <categories>
          
          <category> ElasticSearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ThreadLocal原理</title>
      <link href="/2021/05/28/ThreadLocal%E5%8E%9F%E7%90%86/"/>
      <url>/2021/05/28/ThreadLocal%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="ThreadLocal英文翻译过来就是：线程本地量，它其实是一种线程的隔离机制，保障了多线程环境下对于共享变量访问的安全性。"><a href="#ThreadLocal英文翻译过来就是：线程本地量，它其实是一种线程的隔离机制，保障了多线程环境下对于共享变量访问的安全性。" class="headerlink" title="ThreadLocal英文翻译过来就是：线程本地量，它其实是一种线程的隔离机制，保障了多线程环境下对于共享变量访问的安全性。"></a>ThreadLocal英文翻译过来就是：线程本地量，它其实是一种线程的隔离机制，保障了多线程环境下对于共享变量访问的安全性。</h2><h3 id="什么是ThreadLocal"><a href="#什么是ThreadLocal" class="headerlink" title="什么是ThreadLocal"></a>什么是ThreadLocal</h3><pre><code> ThreadLocal提供了线程的局部变量，每个线程都可以通过set()和get()来对这个局部变量进行操作，但不会和其他线程的局部变量进行冲突，实现了线程的数据隔离。  简而言之：ThreadLocal中填充的变量属于当前线程，该变量对其他线程而言是不可见的。</code></pre><h3 id="ThreadLocal原理"><a href="#ThreadLocal原理" class="headerlink" title="ThreadLocal原理"></a>ThreadLocal原理</h3><p> <img src="/image/ThreadLocal%E5%86%85%E5%AD%98%E5%9B%BE.png" alt="效果图预览"> </p><pre><code>Thread线程类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，即每个线程都有一个属于自己的ThreadLocalMap。ThreadLocalMap内部维护着Entry数组，每个Entry代表一个完整的对象，key是ThreadLocal本身，value是ThreadLocal的泛型值。并发多线程场景下，每个线程Thread，在往ThreadLocal里设置值的时候，都是往自己的ThreadLocalMap里存，读也是以某个ThreadLocal作为引用，在自己的map里找对应的key，从而可以实现了线程隔离。</code></pre><h3 id="TheadLocal使用场景"><a href="#TheadLocal使用场景" class="headerlink" title="TheadLocal使用场景"></a>TheadLocal使用场景</h3><pre><code>  1.用来替代参数链传递：在编写API接口时，可以将需要传递的参数放入ThreadLocal中，从而不需要在每个调用的方法上都显式地传递这些参数。这种方法虽然不如将参数封装为对象传递来得常见，但在某些情况下可以简化代码结构。  2.数据库连接和会话管理：在某些应用中，如Web应用程序，ThreadLocal可以用来保持对数据库连接或会话的管理，以简化并发控制并提高性能。例如，可以使用ThreadLocal来维护一个连接池，使得每个请求都能共享相同的连接，而不是每次都需要重新建立连接。  3.全局存储信息：例如在前后端分离的应用中，ThreadLocal可以用来在服务端维护用户的上下文信息或者一些配置信息，而不需要通过HTTP请求携带大量的用户信息。这样做可以在不改变原有架构的情况下，提供更好的用户体验。</code></pre><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><pre><code>  强引用：其实就是咱们一般用“=”的赋值行为，如 Student s = new Student(),只要强引用还在，对象就不会被回收。  软引用：不是必须存活的对象，jvm在内存不够的情况下即将内存溢出前会对其进行回收。例如缓存。  弱引用：非必须存活的对象，引用关系比软引用还弱，无论内存够还是不够，下次的GC一定会被回收。  虚引用：别名幽灵引用或者幻影引用。等同于没有引用，唯一的目的是对象被回收的时候会受到系统通知。</code></pre>]]></content>
      
      
      <categories>
          
          <category> ThreadLocal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ThreadLocal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java中多线程</title>
      <link href="/2021/04/17/java%E4%B8%AD%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
      <url>/2021/04/17/java%E4%B8%AD%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="线程-英语-thread-是操作系统能够进行运算调度的最小单位。它被包含在进程之中-是进程中的实际运作单位。"><a href="#线程-英语-thread-是操作系统能够进行运算调度的最小单位。它被包含在进程之中-是进程中的实际运作单位。" class="headerlink" title="线程(英语:thread)是操作系统能够进行运算调度的最小单位。它被包含在进程之中,是进程中的实际运作单位。"></a>线程(英语:thread)是操作系统能够进行运算调度的最小单位。它被包含在进程之中,是进程中的实际运作单位。</h2><h3 id="创建线程方式"><a href="#创建线程方式" class="headerlink" title="创建线程方式"></a>创建线程方式</h3><pre><code>通过继承Thread类来创建线程。通过实现Runnable接口来创建线程。通过实现Callable接口来创建线程。使用Executor框架来创建线程池</code></pre><h3 id="线程和进程的区别"><a href="#线程和进程的区别" class="headerlink" title="线程和进程的区别"></a>线程和进程的区别</h3><pre><code>线程和进程是操作系统中重要的概念，都是操作系统资源分配的基本单位，但它们有一些关键的区别。地址空间和资源拥有：进程是执行中的一个程序，具有自己的地址空间和文件描述符等资源。线程是在进程中执行的一个单独的执行路径，共享进程的地址空间和资源。开销：创建和销毁一个进程需要保存寄存器、栈信息以及进行资源分配和回收等操作，开销较大。而线程的创建和销毁只需保存寄存器和栈信息，开销较小。通信切换：进程之间必须通过IPC（进程间通信）进行通信，切换开销相对较大。线程之间可以直接共享进程的地址空间和资源，切换开销相对较小。并发性：进程是独立的执行单元，具有自己的调度算法，在并发条件下更加稳定可靠。而线程共享进程的资源，线程之间的调度和同步比较复杂，对并发条件的处理需要更多的注意。一对多的关系：一个线程只能属于一个进程，而一个进程可以拥有多个线程。</code></pre><h3 id="Runnable和-Callable有什么区别"><a href="#Runnable和-Callable有什么区别" class="headerlink" title="Runnable和 Callable有什么区别"></a>Runnable和 Callable有什么区别</h3><pre><code>Runnable接口只有一个需要实现的方法，即run()。当你启动一个线程时，这个run()方法就会被执行。Runnable的主要问题是它不支持返回结果Callable可以返回结果，也可以抛出异常。它有一个call()方法，当调用这个方法时，这个方法就会被执行。</code></pre><h3 id="线程状态"><a href="#线程状态" class="headerlink" title="线程状态"></a>线程状态</h3><p> <img src="/image/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.png" alt="效果图预览">  </p><pre><code>    New：线程对象创建之后、但还没有调用start()方法，就是这个状态。    Runnable：它包括就绪（ready）和运行中（running）两种状态。如果调用start方法，线程就会进入Runnable状态。它表示我这个线程可以被执行啦（此时相当于ready状态），如果这个线程被调度器分配了CPU时间，那么就可以被执行（此时处于running状态）。    Blocked：阻塞的（被同步锁或者IO锁阻塞）。表示线程阻塞于锁，线程阻塞在进入synchronized关键字修饰的方法或代码块(等待获取锁)时的状态。比如前面有一个临界区的代码需要执行，那么线程就需要等待，它就会进入这个状态。它一般是从RUNNABLE状态转化过来的。如果线程获取到锁，它将变成RUNNABLE状态。    WAITING : 永久等待状态，进入该状态的线程需要等待其他线程做出一些特定动作（比如通知）。处于该状态的线程不会被分配CPU执行时间，它们要等待被显式地唤醒，否则会处于无限期等待的状态。一般Object.wait。    TIMED_WATING: 等待指定的时间重新被唤醒的状态。有一个计时器在里面计算的，最常见就是使用Thread.sleep方法触发，触发后，线程就进入了Timed_waiting状态，随后会由计时器触发，再进入Runnable状态。    终止(TERMINATED)：表示该线程已经执行完成。</code></pre><h3 id="线程池类型"><a href="#线程池类型" class="headerlink" title="线程池类型"></a>线程池类型</h3><pre><code>FixedThreadPool：这是一个固定大小的线程池，它创建一个核心线程数固定大小的线程池，即使线程是空闲的，也不会被销毁。这个线程池适用于任务量固定，且每个任务都需要执行的情况。CachedThreadPool：这是一个可缓存的线程池，它的核心线程数是0，最大线程数是Integer.MAX_VALUE，非核心线程闲置60秒后会被销毁。这个线程池适用于执行大量短生命周期的异步任务。SingleThreadExecutor：这是一个单线程的线程池，它只创建一个线程来执行任务，如果这个线程异常结束，会有新的线程来替代它。此执行器保证所有任务的执行顺序按照任务的提交顺序执行。ScheduledThreadPool：这是一个定时线程池，它支持定时以及周期性执行任务的需求。各种线程池的使用场景：    FixedThreadPool：适用于为了满足资源管理需求，需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。    CachedThreadPool：适用于执行很多短期异步任务的小程序，或者是负载较轻的服务器。    SingleThreadExecutor：适用于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。    ScheduledThreadPool：适用于需要多个后台线程执行周期任务，同时为了满足资源管理需求而需要限制后台线程的数量的应用场景。</code></pre><h3 id="ThreadPoolExecutor的重要参数"><a href="#ThreadPoolExecutor的重要参数" class="headerlink" title="ThreadPoolExecutor的重要参数"></a>ThreadPoolExecutor的重要参数</h3><pre><code>corePoolSize：核心线程数    1  * 核心线程会一直存活，及时没有任务需要执行    2  * 当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理    3  * 设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭maxPoolSize：最大线程数    1  * 当线程数&gt;=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务    2  * 当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常keepAliveTime：线程空闲时间    1  * 当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize    2  * 如果allowCoreThreadTimeout=true，则会直到线程数量=0allowCoreThreadTimeout：允许核心线程超时queueCapacity：任务队列容量（阻塞队列）    1  * 当核心线程数达到最大时，新任务会放在队列中排队等待执行rejectedExecutionHandler: 任务拒绝处理器    1     * 两种情况会拒绝处理任务：    2         - 当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务    3         - 当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务    4     * 线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常    5     * ThreadPoolExecutor类有几个内部实现类来处理这类情况：    6         - AbortPolicy 丢弃任务，抛运行时异常    7         - CallerRunsPolicy 执行任务    8         - DiscardPolicy 忽视，什么都不会发生    9         - DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务    10     * 实现RejectedExecutionHandler接口，可自定义处理器 </code></pre><h3 id="Future和Callable"><a href="#Future和Callable" class="headerlink" title="Future和Callable"></a>Future和Callable</h3><pre><code>Callable：这是一个接口，它代表一段可以调用并返回结果的代码。Callable接口的主要优点是它可以返回运行结果，并能抛出异常。这在处理并行计算时非常有用，因为它可以让我们更容易地获取并行任务的结果。Future：这也是一个接口，它表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。Future接口的主要作用是用于获取Callable任务的结果。当你提交一个Callable任务给一个线程池后，线程池会返回一个Future对象，通过这个Future对象，你可以知道Callable任务的状态，可以取消任务的执行，也可以获取任务执行的结果。</code></pre><h3 id="阻塞队列的有界和无界"><a href="#阻塞队列的有界和无界" class="headerlink" title="阻塞队列的有界和无界"></a>阻塞队列的有界和无界</h3><pre><code>阻塞队列：是一种特殊的队列，它在普通队列的基础上提供了两个附加功能    当队列为空的时候，获取队列中元素的消费者线程会被阻塞，同时唤醒生产者线程。    当队列满了的时候，向队列中添加元素的生产者线程被阻塞，同时唤醒消费者线程。界队列： 就是没有设置固定大小的队列，不过它并不是像我们理解的那种元素没有任何限制，而是它的元素存储量很大，像LinkedBlockingQueue，它的默认队列长度 无是Integer.Max_Value，所以我们感知不到它的长度限制。 无界队列存在比较大的潜在风险，如果在并发量较大的情况下，线程池中可以几乎无限制的添加任务，容易导致内存溢出的问题！</code></pre><h3 id="常用的队列"><a href="#常用的队列" class="headerlink" title="常用的队列"></a>常用的队列</h3><pre><code>1.ArrayDeque, （数组双端队列） 2.PriorityQueue, （优先级队列） 3.ConcurrentLinkedQueue, （基于链表的并发队列） 4.DelayQueue, （延期阻塞队列）（阻塞队列实现了BlockingQueue接口） 5.ArrayBlockingQueue, （基于数组的并发阻塞队列） 6.LinkedBlockingQueue, （基于链表的FIFO阻塞队列） 7.LinkedBlockingDeque, （基于链表的FIFO双端阻塞队列） 8.PriorityBlockingQueue, （带优先级的无界阻塞队列） 9.SynchronousQueue （并发同步阻塞队列）阻塞队列和非阻塞队列的主要区别在于它们的行为，当队列满或空时。阻塞队列：    当队列满时，试图添加元素的线程会被阻塞，直到队列中有可用空间。    当队列空时，试图移除元素的线程也会被阻塞，直到队列中有新的元素。    这种机制允许阻塞队列在多线程环境中作为缓冲区使用，生产者线程可以在消费者线程准备好处理数据之前阻塞，反之亦然。非阻塞队列：    当队列满时，试图添加元素的线程会立即得到一个反馈，通常是一个异常或者一个特殊的返回值。    当队列空时，试图移除元素的线程也会立即得到一个反馈。    非阻塞队列不会在操作无法完成时阻塞线程，这使得它们在某些场景下更为适用，比如需要避免线程阻塞的情况。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 多线程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot集成RocketMQ</title>
      <link href="/2021/03/07/SpringBoot%E9%9B%86%E6%88%90RocketMQ/"/>
      <url>/2021/03/07/SpringBoot%E9%9B%86%E6%88%90RocketMQ/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt;    &lt;artifactId&gt;rocketmq-spring-boot&lt;/artifactId&gt;    &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt;</code></pre><h3 id="配置文件修改"><a href="#配置文件修改" class="headerlink" title="配置文件修改"></a>配置文件修改</h3><pre><code>在springboot-rocketmq-producer项目的application.yml文件中添加如下配置：rocketmq:    name-server: 172.31.184.89:9876    producer:        group: feige-producer-group    consumer:        topic: my-spring-boot-topic在springboot-rocketmq-consumer项目的application.yml文件中添加如下配置：server:port: 8080rocketmq:name-server: 172.31.184.89:9876consumer:    group: feige-consumer-group    topic: my-spring-boot-topic</code></pre><h3 id="实现生产者"><a href="#实现生产者" class="headerlink" title="实现生产者"></a>实现生产者</h3><p>   定义一个生产者类MyProducer，在该类中引入RocketMQTemplate 操作类，然后定义发送消息的方法sendMessage，在此方法中调用 rocketMQTemplate.convertAndSend 方法进行消息发送。</p><pre><code>@Componentpublic class MyProducer {    @Autowired    private RocketMQTemplate rocketMQTemplate;    /**    * 发送普通消息    *    * @param topic   主题    * @param message 消息    */    public void sendMessage(String topic, String message) {        rocketMQTemplate.convertAndSend(topic, message);    }</code></pre><h3 id="编写生产者单元测试"><a href="#编写生产者单元测试" class="headerlink" title="编写生产者单元测试"></a>编写生产者单元测试</h3><pre><code>    @Autowired    private MyProducer myProducer;    @Value(&quot;${rocketmq.consumer.topic:}&quot;)    private String consumerTopic;    @Test    void sendMessage() {        myProducer.sendMessage(consumerTopic,&quot;SpringBoot集成RocketMQ消息测试&quot;);    }</code></pre><h3 id="实现消费者"><a href="#实现消费者" class="headerlink" title="实现消费者"></a>实现消费者</h3><pre><code>   定义消费者类MyConsumer。此类实现了RocketMQListener接口并重写了onMessage方法用于接收broker推送过来的消息。    @Component    @RocketMQMessageListener(topic = &quot;${rocketmq.consumer.topic:}&quot;, consumerGroup = &quot;generalConsumerGroup&quot;)    public class MyConsumer implements RocketMQListener&lt;String&gt; {        @Override        public void onMessage(String s) {            System.out.println(&quot;收到的消息是=&quot; + s);        }    }</code></pre><h3 id="实现事务消息"><a href="#实现事务消息" class="headerlink" title="实现事务消息"></a>实现事务消息</h3><h4 id="实现事务消息的生产者"><a href="#实现事务消息的生产者" class="headerlink" title="实现事务消息的生产者"></a>实现事务消息的生产者</h4><pre><code>在前面创建的MyProducer类中添加实现事务消息的方法 sendTransactionMessage。/** * 发送事务消息 * * @param topic 话题 * @param msg   消息 */public void sendTransactionMessage(String topic, String msg) throws InterruptedException {    String[] tags = {&quot;tagA&quot;, &quot;tagB&quot;, &quot;tagC&quot;, &quot;tagD&quot;, &quot;tagE&quot;};    for (int i = 0; i &lt; 10; i++) {        // 2. 将topic和tag整合在一起，以:分割，        String destination = topic + &quot;:&quot; + tags[i % tags.length];            // 1.注意该message是org.springframework.messaging.Message        Message&lt;String&gt; message = MessageBuilder.withPayload(msg + &quot;_&quot; + tags[i % tags.length] + &quot;_&quot; + i)                .setHeader(&quot;destination&quot;, destination).build();        // 第一个参数是发布的目的地，第二个参数是消息，第三个参数是额外的参数        rocketMQTemplate.sendMessageInTransaction(destination, message, destination);    }}这里需要注意的是传入的Message类是org.springframework.messaging.Message ，不是RocketMQ的Message。</code></pre><h4 id="实现本地事务消息"><a href="#实现本地事务消息" class="headerlink" title="实现本地事务消息"></a>实现本地事务消息</h4><p>   接着在定义生产者本地事务实现类 MyTransactionListener，该类实现了RocketMQLocalTransactionListener接口，并重写了executeLocalTransaction方法和checkLocalTransaction方法。这里多了一步就是将 org.springframework.messaging.Message 转成 org.apache.rocketmq.common.message.Message 。</p><pre><code>@RocketMQTransactionListener(rocketMQTemplateBeanName = &quot;rocketMQTemplate&quot;)public class MyTransactionListener implements RocketMQLocalTransactionListener {    @Override    public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) {        // 将消息转成rocketmq下的message        org.apache.rocketmq.common.message.Message message = RocketMQUtil.convertToRocketMessage(new StringMessageConverter(), &quot;utf-8&quot;, (String) arg, msg);        String tags = message.getTags();        if (tags.equals(&quot;tagA&quot;)) {            return RocketMQLocalTransactionState.COMMIT;        } else if (tags.equals(&quot;tagB&quot;)) {            return RocketMQLocalTransactionState.ROLLBACK;        }        return RocketMQLocalTransactionState.UNKNOWN;    }    @Override    public RocketMQLocalTransactionState checkLocalTransaction(Message msg) {        // 将消息转成rocketmq下的message        String destination = (String) msg.getHeaders().get(&quot;destination&quot;);        org.apache.rocketmq.common.message.Message message = RocketMQUtil.convertToRocketMessage(new StringMessageConverter(),                &quot;utf-8&quot;,destination, msg);        String tags = message.getTags();        if (tags.equals(&quot;tagC&quot;)) {            return RocketMQLocalTransactionState.COMMIT;        } else if (tags.equals(&quot;tagD&quot;)) {            return RocketMQLocalTransactionState.ROLLBACK;        }        return RocketMQLocalTransactionState.UNKNOWN;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringBoot </category>
          
          <category> RocketMQ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RocketMQ </tag>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocketMQ</title>
      <link href="/2021/03/06/RocketMQ/"/>
      <url>/2021/03/06/RocketMQ/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><pre><code>RocketMQ 是阿里巴巴开源的分布式消息中间件。支持事务消息、顺序消息、批量消息、定时消息、消息回溯等。它里面有几个区别于标准消息中件间的概念，如Group、Topic、Queue等。系统组成则由Producer、Consumer、Broker、NameServer等。</code></pre><hr><h3 id="RockerMQ架构上主要分为四部分"><a href="#RockerMQ架构上主要分为四部分" class="headerlink" title="RockerMQ架构上主要分为四部分"></a>RockerMQ架构上主要分为四部分</h3><pre><code>Producer: 消息生产者角色，支持分布式集群部署，主要用于发送消息，通常集成于业务系统。它相当于是发信者。Consumer: 消息消费者角色，支持分布式集群部署，支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，通常集成于业务系统。它相当于收信者。Broker: 主要负责消息的存储、投递和查询以及服务高可用保证。它相当于是邮局 其内部包含以下几个重要子模块。    4.1. Remoting Module: 整个Broker的实体，负责处理来自Clients端的请求。    4.2. Client Manager: 负责管理客户端（Producer/Consumer）和维护Topic订阅信息。    4.3. Store Service: 提供方便简单的API接口处理消息存储到物理磁盘和查询功能。NameServer: 它是Broker的注册中心，支持Broker的动态注册与发现。它主要包括两个功能：Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的提供者。然后提供心跳检测机制，检查Broker是否存活；路由信息管理，每个NameServer通常也是集群方式部署，各实例互不进行通信，Broker向每一台NameServer注册自己的路由信息， 所以，每一个NameServer实例上面都保存一份完整的路由信息，当某个NameServer因某种原因下线了，Broker仍然可以向其他NameServer同步其路由信息。NameServer是无状态的。</code></pre><h3 id="消息生产"><a href="#消息生产" class="headerlink" title="消息生产"></a>消息生产</h3><pre><code>生产者（Producer）：用于产生消息的运行实体，一般集成于业务调用链路的上游。生产者是轻量级匿名无身份的。</code></pre><h3 id="消息存储"><a href="#消息存储" class="headerlink" title="消息存储"></a>消息存储</h3><pre><code>主题（Topic）:    RocketMQ 消息传输和存储的分组容器，主题内部由多个队列组成，消息的存储和水平扩展实际是通过主题内的队列实现的。队列（MessageQueue）:    RocketMQ 消息传输和存储的实际单元容器，类比于其他消息队列中的分区。RocketMQ 通过流式特性的无限队列结构来存储消息，消息在队列内具有顺序存储特性。消息（Message）:    RocketMQ 的最小传输单元，消息具备不可变性，在初始化发送和完成存储后即不可变。</code></pre><h3 id="消息消费"><a href="#消息消费" class="headerlink" title="消息消费"></a>消息消费</h3><pre><code>消费者分组（ConsumerGroup）:    RocketMQ发布订阅模型中定义的独立的消费身份分组。用于统一管理底层运行的多个消费者（Consumer）。同一个消费者组的多个消费者必须保持消费逻辑和配置一致，共同分担该消费者组订阅的消息，实现消费能力的水平扩展。消费者（Consumer）:    RocketMQ 消费消息的运行实体，一般集成在业务调用链路的下游。消费者必须指定到某一个消费者组中。订阅关系（Subscription）:    RocketMQ 发布订阅模型中消息过滤、重试、消费进度的规则配置。订阅关系以消费组粒度进行管理，消费组通过定义订阅关系控制指定消费组下的消费者如何实现消息过滤、消费重试及消费进度恢复等。RocketMQ 的订阅关系除过滤表达式之外都是持久化的，即服务端重启或请求断开，订阅关系依然保留。</code></pre><h3 id="顺序消息-amp-延迟消息-amp-广播消息的实现"><a href="#顺序消息-amp-延迟消息-amp-广播消息的实现" class="headerlink" title="顺序消息&amp;延迟消息&amp;广播消息的实现"></a>顺序消息&amp;延迟消息&amp;广播消息的实现</h3><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><pre><code> 顺序消息指的是消费者在消费消息时，按照生产者发送消息的顺序进行消费。即先发送的先消费【FIFO】。 顺序消息分为 全局顺序消息和局部顺序消息。 全局顺序消息就是全局使用一个queue。 局部顺序消息就是 有顺序依赖的消息放在同一个queue中，多个queue并行消费。</code></pre><h4 id="局部顺序消息"><a href="#局部顺序消息" class="headerlink" title="局部顺序消息"></a>局部顺序消息</h4><pre><code>默认情况下RocketMQ会根据轮询的方式将消息发送到某个broker中的某个队列中，这样的话就不能保证消息是有序的。</code></pre><h3 id="广播消息"><a href="#广播消息" class="headerlink" title="广播消息"></a>广播消息</h3><pre><code>广播消息是向主题（topic）的所有订阅者发送消息，订阅同一个topic的多个消费者，都能全量收到生产者发送的所有消息。// 设置消费者的模式是广播模式defaultMQPushConsumer.setMessageModel(MessageModel.BROADCASTING);</code></pre><h3 id="延迟消息"><a href="#延迟消息" class="headerlink" title="延迟消息"></a>延迟消息</h3><pre><code>延迟消息与普通消息的不同之处在于，它们要在指定的时间之后才会被传递。生产者并不会延迟发送消息，而是发送到topic里面，消费者延迟指定的时间进行消费。//设置延迟级别，默认有18个延迟级别,这个消息将延迟10秒消费message.setDelayTimeLevel(3);延迟消息的消费者与普通消息的消费者相同的。RocketMQ内部通过名为SCHEDULE_TOPIC_XXXX 的topic来存放延迟消息。</code></pre><h3 id="批量消息"><a href="#批量消息" class="headerlink" title="批量消息"></a>批量消息</h3><pre><code>批量发送消息提高了传递消息的性能。官方建议批量消息的总大小不应超过1M，实际不应超过4M。如果超过4M的批量消息需要进行分批处理。同时设置broker的配置参数为4M。</code></pre><h3 id="过滤消息"><a href="#过滤消息" class="headerlink" title="过滤消息"></a>过滤消息</h3><pre><code>使用tag过滤在大多数情况下，标签是一种简单而有用的设计，可以用来选择你想要的消息。首先是根据tag来过滤消息，生产者在发送消息的时候指定该消息的tag标签，消费者则可以根据tag来过滤消息。</code></pre><h4 id="过滤消息生产者"><a href="#过滤消息生产者" class="headerlink" title="过滤消息生产者"></a>过滤消息生产者</h4><pre><code>定义了三个tag，分别是tagA，tagB以及tagC，生产者在生产消息的时候给每个消息指定不同的tag。</code></pre><h4 id="过滤消息的消费者"><a href="#过滤消息的消费者" class="headerlink" title="过滤消息的消费者"></a>过滤消息的消费者</h4><pre><code>消费者过滤出了标签带有tagA以及tagC的消息进行消费。这里其实是broker将consumer需要的消息推给消费者。</code></pre><h4 id="使用SQL过滤"><a href="#使用SQL过滤" class="headerlink" title="使用SQL过滤"></a>使用SQL过滤</h4><pre><code>RocketMQ只定义了一些基本的语法类支持这个特性。1. 数值比较：如 `&gt;`,`&gt;=`,`&lt;=`,`BETWEEN`,`=`;2. 字符比较：如 `=`,&#39;&lt;&gt;&#39;,`IN`;3. `IS NULL` 或 `IS NOT NULL` ;4. 逻辑`AND`,`OR`,`NOT`;则需要修改 broker.conf 文件，增加如下配置：// 开启对 propertyfilter的支持enablePropertyFilter = true filterSupportRetry = tru</code></pre><h3 id="RocketMQ事务消息"><a href="#RocketMQ事务消息" class="headerlink" title="RocketMQ事务消息"></a>RocketMQ事务消息</h3><h4 id="事务消息的定义"><a href="#事务消息的定义" class="headerlink" title="事务消息的定义"></a>事务消息的定义</h4><pre><code>事务消息可以认为是一个两阶段的提交消息实现，以确保分布式事务的最终一致性。事务性消息确保本地事务的执行和消息的发送可以原子执行。两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做，所谓的两个阶段是指：第一阶段：准备阶段；第二阶段：提交阶段。事务消息有三种状态：    TransactionStatus.CommitTransaction: 提交事务，表示允许消费者消费该消息。    TransactionStatus.RollbackTransaction: 回滚事务，表示该消息将被删除，不允许消费。    TransactionStatus.Unknow: 中间状态，表示需要MQ回查才能确定状态。</code></pre><h4 id="事务消息的实现流程"><a href="#事务消息的实现流程" class="headerlink" title="事务消息的实现流程"></a>事务消息的实现流程</h4><p><img src="/image/RocketMq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF.jpeg" alt="效果图预览"><br>     生产者发送half消息，broker接收到half消息并回复half消息。<br>     生产者调用 TransactionListener.executeTransaction() 方法执行本地事务。<br>     生产者获得本地事务执行状态，提交给broker。如果状态是COMMIT_MESSAGE状态的话则broker会将消息推送给消费者。如果状态是ROLLBACK_MESSAGE状态的话则broker会丢弃此消息。如果状态是中间状态UNKNOW状态则broker会回查本地事务状态。<br>     生产者调用 TransactionListener.checkLocalTransaction() 方法回查本地事务执行状态，并再次执行5,6,7三步骤，若回查次数超过15次则丢弃。</p><pre><code> 使用限制：    事务性消息没有调度和批处理支持。    为避免单条消息被检查次数过多，导致半队列消息堆积，我们默认单条消息的检查次数限制为15次，但用户可以通过更改 transactionCheckMax 来更改此限制，如果一条消息的检查次数超过 transactionCheckMax 次，broker默认会丢弃这条消息，同时打印错误日志。用户可以重写 AbstractTransactionCheckListener 类来改变这种行为。    事务消息将一定时间后检查，该时间由代理配置中的参数 transactionTimeout 确定。并且用户也可以在发送事务消息时通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制，这个参数优先于 transactionMsgTimeout 参数。    一个事务性消息会被检查或消费不止一次。    事务性消息的生产者ID不能与其他类型消息的生产者ID共享，与其他类型的消息不同，事务性消息允许向后查询。MQ服务器通过其生产者ID查询客户端。    提交给用户目标主题的消息reput可能会失败，目前它取决于日志记录，高可用是由RocketMQ本身的高可用机制来保证的。如果要保证事务消息不丢失，保证事务完整性，推荐使用同步双写机制。</code></pre><h4 id="本地事务的实现"><a href="#本地事务的实现" class="headerlink" title="本地事务的实现"></a>本地事务的实现</h4><pre><code>    事务消息最关键的地方是生产者本地事务的实现，生产者本地事务实现 TransactionListener 接口，并实现该接口中的executeLocalTransaction方法和checkLocalTransaction方法。    其中，executeLocalTransaction 方法的作用是执行本地事务。它在生产者每次发送half消息的时候被调用，    如果调用此方法返回LocalTransactionState.COMMIT_MESSAGE状态，则此消息会被消费者消费到。    如果返回 LocalTransactionState.ROLLBACK_MESSAGE 状态，则此消息会被broker丢弃    如果返回 LocalTransactionState.UNKNOW 状态，即中间状态，则broker会调用checkLocalTransaction方法进行回查，最多回查15次。    checkLocalTransaction方法的作用是检查本地事务， 它是生产者发送完所有消息的时候调用，主要是针对的是中间状态的消息进行调用。    同样的如果调用此方法返回前面提到的三种状态，broker也会做出相同的处理。</code></pre><h4 id="事务消息的生产者"><a href="#事务消息的生产者" class="headerlink" title="事务消息的生产者"></a>事务消息的生产者</h4><pre><code>    事务消息的生产者与普通消息的生产者最核心的区别是事务消息的生产者需要事务监听器，并且是调用sendMessageInTransaction 方法发送 half 消息。</code></pre><h3 id="消费者的消费模式"><a href="#消费者的消费模式" class="headerlink" title="消费者的消费模式"></a>消费者的消费模式</h3><h4 id="推模式"><a href="#推模式" class="headerlink" title="推模式"></a>推模式</h4><pre><code> 消费者推模式的例子就是 org.apache.rocketmq.example.simple.PushConsumer 。推模式的消费者的实现类是 DefaultMQPushConsumer 。</code></pre><h4 id="拉模式"><a href="#拉模式" class="headerlink" title="拉模式"></a>拉模式</h4><pre><code> 消费者拉模式的例子是：org.apache.rocketmq.example.simple.LitePullConsumerAssign 。拉模式主要适用于回溯消费消息。比如：某个消息你消费失败了，你现在想重新消费该消息的情况。我们知道RocketMQ中消息消费完之后不会里面会被删除，默认会在队列中保留48小时。通过broker配置文件中的fileReservedTime参数进行设置。</code></pre>]]></content>
      
      
      <categories>
          
          <category> RocketMQ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RocketMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CAS 机制</title>
      <link href="/2020/12/15/CAS%20%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/12/15/CAS%20%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="CAS的全称是-Compare-And-Swap（比较再交换，确切一点称之为：比较并且相同再做交换）"><a href="#CAS的全称是-Compare-And-Swap（比较再交换，确切一点称之为：比较并且相同再做交换）" class="headerlink" title="CAS的全称是 Compare And Swap（比较再交换，确切一点称之为：比较并且相同再做交换）"></a>CAS的全称是 Compare And Swap（比较再交换，确切一点称之为：比较并且相同再做交换）</h2><h3 id="CAS的作用"><a href="#CAS的作用" class="headerlink" title="CAS的作用"></a>CAS的作用</h3><pre><code>  CAS可以将比较和交换转换为原子操作，这个原子操作直接由处理器CPU保证。  CAS指令需要有三个操作数，分别是：        内存位置（在Java中可以简单地理解为变量的内存地址，用V表示）        旧的预取值（用A表示）        准备设置的新值（用B表示）</code></pre><p>   <img src="/image/CAS.png" alt="效果图预览"> </p><pre><code> CAS指令执行时，当且仅当 V 符合 A 时，处理器才会用 B 更新 V 的值，否则它就不执行更新 或 重来（当他重来重试的这种行为称为——自旋）。但是不管是否更新了 V 的值，都会返回 V 的旧值。该过程是一个原子操作，执行期间不会被其他线程中断。 </code></pre><h3 id="CAS-的原子类"><a href="#CAS-的原子类" class="headerlink" title="CAS 的原子类"></a>CAS 的原子类</h3><pre><code>  AtomicBoolean  AtomicInteger  AtomicLong  AtomicReference</code></pre><h3 id="CAS的缺点"><a href="#CAS的缺点" class="headerlink" title="CAS的缺点"></a>CAS的缺点</h3><pre><code>  循环时间长开销很大。  引起ABA问题。</code></pre><h3 id="cas和Synchronized"><a href="#cas和Synchronized" class="headerlink" title="cas和Synchronized"></a>cas和Synchronized</h3><pre><code>  一、CAS（乐观锁）        1、CAS的全称是：Compare And Swap（比较再交换），是现代CPU广泛支持的一种对内存中的共享数据进行操作的一种特殊指令。CAS可以将read-modify-check-write转化为原子操作，这个原子操作直接由处理器保证，也正是因为这个，才保证了原子类的线程安全。        2、总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是更新的时候会判断一下在此期间别人有没有更新这个数据，也就是这个数据和我拿的时候的值是否一致。  二、Synchronized（悲观锁）        1、总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想要拿到数据就会阻塞，知道它拿到锁。        2、共享资源每次只给一个线程使用，其他线程阻塞，用完后再把资源转让给其他线程使用。因此Synchronized我们称之为悲观锁。jdk的ReentrantLock也是一种悲观锁。性能较差。</code></pre>]]></content>
      
      
      <categories>
          
          <category> CAS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CAS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DevOps</title>
      <link href="/2020/11/20/DevOps/"/>
      <url>/2020/11/20/DevOps/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="DevOps与敏捷开发最大的不同点就在于，对软件进行多次、频繁的部署来避免软件部署难的问题。DevOps的提出，最开始也确实是为了打破开发和运维之间的对立和隔阂。"><a href="#DevOps与敏捷开发最大的不同点就在于，对软件进行多次、频繁的部署来避免软件部署难的问题。DevOps的提出，最开始也确实是为了打破开发和运维之间的对立和隔阂。" class="headerlink" title="DevOps与敏捷开发最大的不同点就在于，对软件进行多次、频繁的部署来避免软件部署难的问题。DevOps的提出，最开始也确实是为了打破开发和运维之间的对立和隔阂。"></a>DevOps与敏捷开发最大的不同点就在于，对软件进行多次、频繁的部署来避免软件部署难的问题。DevOps的提出，最开始也确实是为了打破开发和运维之间的对立和隔阂。</h2><h3 id="瀑布式开发"><a href="#瀑布式开发" class="headerlink" title="瀑布式开发"></a>瀑布式开发</h3><pre><code>瀑布式开发，又称“瀑布（Waterfall）模型”，是软件开发中最早出现的模型之一。整个软件开发流程严格遵循需求、设计、开发、测试、部署、维护几个阶段。在这个流程中，需要等上 一个阶段工作完成后，才会进行下个阶段的工作。例如：开发工程师会把需求的代码全部开发好，才给到测试人员进行验证，最后交给运维工程师部署上线。在这种模式下，项目开发的进程由是从一个阶段“流动”到下一个阶段，如同瀑布流水一般，因此被称为瀑布模型（Waterfall Model）。</code></pre><h3 id="敏捷开发"><a href="#敏捷开发" class="headerlink" title="敏捷开发"></a>敏捷开发</h3><pre><code>敏捷意味着效率的提升，相比于传统的瀑布开发，敏捷开发实行的是一种更加快捷的做法。敏捷的核心理念是：将一个大的目标不断拆解，把它变成一个个可交付的小目标，然后通过不断迭代，以小步快跑的方式持续开发。敏捷之所以更快，根本原因在于持续迭代和验证节省了大量不必要的浪费和返工。</code></pre><h3 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h3><p><img src="/image/%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F%E5%AF%B9%E6%AF%94.png" alt="效果图预览"><br>    DevOps与敏捷开发最大的不同点就在于，对软件进行多次、频繁的部署来避免软件部署难的问题。DevOps的提出，最开始也确实是为了打破开发和运维之间的对立和隔阂。</p><pre><code>DevOps完善了敏捷开发存在的短板，实现了真正的软件交付全流程闭环。在 DevOps 的模式下，开发和运维都不再是“孤立”的团队，两者会在软件的整个生命周期内相互协作，并在工作中得到紧密地配合。而由此带来的效益，则是更加高效的服务交付和质量</code></pre><p> <img src="/image/devops.png" alt="效果图预览"></p><h3 id="黄金圈法则"><a href="#黄金圈法则" class="headerlink" title="黄金圈法则"></a>黄金圈法则</h3><p> <img src="/image/%E9%BB%84%E9%87%91%E5%9C%88%E6%B3%95%E5%88%99.png" alt="效果图预览"></p><h3 id="DevOps实践体系"><a href="#DevOps实践体系" class="headerlink" title="DevOps实践体系"></a>DevOps实践体系</h3><pre><code>1、需求方面，包括影响地图等业务探索方法、精益、敏捷协作、可视化等方面的实践；2、开发方面，包括松耦合架构、分支策略、代码版本控制、持续集成、代码评审、质量内建、安全左移和技术债务管理等；3、测试方面，包括环境管理、自动化测试等重要实践；4、交付方面，包括配置管理、数据库变更管理、简化变更审批、持续部署、低风险发布等；5、线上运维方面，包括完善的监控告警机制、混沌工程等。DevOps用四个核心指标来衡量软件交付效能，包括变更前置时间、部署频率、变更失败率、故障恢复时长，这四个指标是 Dora 年度 DevOps 状态报告[4]使用的指标，也是业界认可度最高的四个指标。</code></pre><h3 id="DevOps展望"><a href="#DevOps展望" class="headerlink" title="DevOps展望"></a>DevOps展望</h3><pre><code> 1、与业务更深度结合：DevOps与企业目标，尤其是业务目标相结合，能够探索出来一条更有效的路径，融合业务目标和DevOps的实践。 2、极简DevOps：当前DevOps涵盖的范围太广，有包罗软件交付万象之势，但是成熟的理论方法必然要找到自己最适配的场景，给出自己最优秀的实践框架 和落地方法。 3、DevOps与AI深度结合：AI的浪潮汹涌而来，DevOps也要与AI更多融合，推出更多的先进实践和工具，持续改进，持续发展完善</code></pre><h3 id="DevOps的核心原则"><a href="#DevOps的核心原则" class="headerlink" title="DevOps的核心原则"></a>DevOps的核心原则</h3><pre><code> 自动化（Automation）：通过自动化工具和流程来减少人为操作，提高效率和可靠性。 持续交付（Continuous Delivery）：实现持续集成和持续部署，使软件能够快速、频繁地交付给用户。 团队协作（Collaboration）：打破开发与运维之间的壁垒，促进团队合作与共同责任。</code></pre><h3 id="持续集成CI"><a href="#持续集成CI" class="headerlink" title="持续集成CI"></a>持续集成CI</h3><pre><code> 持续集成（CI）是在源代码变更后自动检测、拉取、构建和（在大多数情况下）进行单元测试的过 程。持续集成是启动管道的环节（经过某些预验证 —— 通常称为 上线前检查 (pre-flight checks) —— 有时会被归在持续集成之前）。持续集成的目标是快速确保开发人员新提交的变更是好的，并且适 合在代码库中进一步使用。     它的好处主要有以下几点：        1）较早的发现错误：每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，哪个 环节出现问题都可以较早的发现。        2）快速的发现错误：每完成一部分代码的更新，就会把代码集成到主干中，这样就可以快速的发现 错误，比较容易的定位错误。        3）提升团队绩效：持续集成中代码更新速度快，能及时发现小问题并进行修改，使团队能创造出更 好的产品。        4）防止分支过多的偏离主干：经常持续集成，会使分支代码经常向主干更新，当单元测试失败或者 出现 bug，如果开发者需要在没有调试的情况下恢复仓库的代码到没有 bug 的状态，只有很小部分的代 码会丢失。 持续集成的目的是提高代码质量，让产品快速的更新迭代。它的核心措施是，代码集成到主干之前， 必须通过自动化测试。只要有一个测试用例失败，就不能集成。</code></pre><h3 id="持续交付"><a href="#持续交付" class="headerlink" title="持续交付"></a>持续交付</h3><pre><code> 持续交付在持续集成的基础上，将集成后的代码部署到更贴近真实运行环境的「类生产环境」（production-like environments）中。交付给质量团队或者用户，以供评审。如果评审通过，代码就进入生产阶段。如果所有的代码完成之后一起交付，会导致很多问题爆发出来，解决起来很麻烦，所以持续集成，也就是每更新一次代码，都向下交付一次，这样可以及时发现问题，及时解决，防止问题大量堆积。</code></pre><h3 id="持续部署-CD"><a href="#持续部署-CD" class="headerlink" title="持续部署(CD)"></a>持续部署(CD)</h3><pre><code>持续部署是指当交付的代码通过评审之后，自动部署到生产环境中。持续部署是持续交付的最高阶段。Puppet，SaltStack 和 Ansible 是这个阶段使用的流行工具。容器化工具在部署阶段也发挥着重要作用。Docker 和 k8s 是流行的工具，有助于在开发，测试和生产环境中实现一致性。 除此之外，k8s还可以实现自动扩容缩容等功能。</code></pre><h3 id="DevOps-容器云平台工作流程"><a href="#DevOps-容器云平台工作流程" class="headerlink" title="DevOps 容器云平台工作流程"></a>DevOps 容器云平台工作流程</h3><p> <img src="/image/DevOps%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="效果图预览"><br>    jenkins 主节点：<br>    负责维护 pipeline<br>    jenkins 从节点：<br>    负责把主节点 pipeline 里的步骤运行起来<br>    jenkins 主节点立即构建 pipeline，会调用 k8s apiserver 在 k8s 集群里创建一个 pod（jenkins 从节点）。所有 pipeline 里的步骤会在 jenkins 从节点运行。<br>    Jenkins—&gt;k8s，帮助你创建一个 pod，pod 里面封装的是 jenkins 服务<br>    主 Jenkins pipeline 流水线：<br>    第一步：从 gitlab 拉代码<br>    第二步：如果 java 开发，对代码编译打包并且把代码传到代码扫描仓库 sonarqube：maven 生成jar、war、go build 生成一个可执行的文件、python 代码，直接运行.py 结尾的文件<br>    第三步：把 jar 或者 war 包基于 dockerfile 构建镜像<br>    第四步: 把镜像传到镜像仓库 harbor<br>    第五步：写 yaml 文件，把开发、测试、生产环境的资源对应的 yaml 都写出来<br>    主 jenkins 构建 pipeline，调用 k8s api，在 k8s 里创建一个 pod，这个 pod 里面运行的是jenkins 服务，只不过这个 pod 里运行的 jenkins 服务是 jenkins 从节点，刚才这五个步骤，都是在jenkins 从节点这个 pod 里做的。完成之后，jenkins 从节点这个 pod 就会被删除。主 jenkins 是包工</p>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Boot</title>
      <link href="/2020/11/16/Spring%20Boot/"/>
      <url>/2020/11/16/Spring%20Boot/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>核心思想是减少软件开发人员对于配置项的维护，从而让开发人员更加聚焦在业务逻辑上。</p><h3 id="Spring-Boot-中自装配机制"><a href="#Spring-Boot-中自装配机制" class="headerlink" title="Spring Boot 中自装配机制"></a>Spring Boot 中自装配机制</h3><pre><code>SpringBoot自动装配:就是指：通过注解和一些简单的配置就能将某些组件载入Spring容器环境中，便于使用。SpringBoot自动装配实现机制:     注解@SpringBootApplication的定义来看，本质上它是@Configuration，EnableAutoConfiguration和@ComponentScan这三个注解的组合，它们的含义分别是：    @Configuration：用于在上下文中注册额外的Bean或导入其他配置类    @EnableAutoConfiguration：启用Spring Boot的自动装配机制    @ComponentScan：扫描被@Component，@Service，@Controller等注解的Bean，默认会扫描启动类所在包及其子包下的所有类，可以自定义不扫描某些类 注解@EnableAutoConfiguration中通过@Import导入了AutoConfigurationImportSelector类，在这个类中真正实现了从外部jar包的META-INF/spring.factories文件中读取配置的类信息。是在getCandidateConfigurations()方法中实现读取配置类。</code></pre><h3 id="Spring-Boot-中自定义实现Starter组件"><a href="#Spring-Boot-中自定义实现Starter组件" class="headerlink" title="Spring Boot 中自定义实现Starter组件"></a>Spring Boot 中自定义实现Starter组件</h3><pre><code>新建项目，在pom文件中添加依赖&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;org.chench.extra.spring.boot&lt;/groupId&gt;    &lt;artifactId&gt;redisson-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.0.0&lt;/version&gt;    &lt;dependencies&gt;        &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;        &lt;version&gt;2.3.1.RELEASE&lt;/version&gt;        &lt;!-- 禁止传递依赖 --&gt;        &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;dependency&gt;        &lt;groupId&gt;org.redisson&lt;/groupId&gt;        &lt;artifactId&gt;redisson&lt;/artifactId&gt;        &lt;version&gt;3.13.1&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- 配置参数提示，需加此依赖 --&gt;        &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;        &lt;version&gt;2.3.1.RELEASE&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;新一个保存配置参数信息的类RedissonProperties@ConfigurationProperties(prefix = &quot;auto.redisson&quot;)public class RedissonProperties {    private String host = &quot;localhost&quot;;    private int port = 6379;    private int timeout = 1000;    private boolean ssl = false;    public String getHost() {        return host;    }    public void setHost(String host) {        this.host = host;    }    public int getPort() {        return port;    }    public void setPort(int port) {        this.port = port;    }    public int getTimeout() {        return timeout;    }    public void setTimeout(int timeout) {        this.timeout = timeout;    }    public boolean isSsl() {        return ssl;    }    public void setSsl(boolean ssl) {        this.ssl = ssl;    }}创建RedissonClient对象的配置类@ConditionalOnClass(Redisson.class) // 使用条件注解，只有当依赖了Redisson时才加载到容器@EnableConfigurationProperties(RedissonProperties.class) // 加载配置参数类@Configuration // 这是一个配置类public class RedissionAutoConfiguration {    @Bean // 实例化RedissonClient对象    public RedissonClient redissonClient(RedissonProperties redissonProperties) {        Config config = new Config();        String prefix = redissonProperties.isSsl() ? &quot;rediss://&quot; : &quot;redis://&quot;;        String host = redissonProperties.getHost();        int port = redissonProperties.getPort();        int timeout = redissonProperties.getTimeout();        config.useSingleServer()                .setAddress(prefix + host + &quot;:&quot; + port)                .setTimeout(timeout);        return Redisson.create(config);    }}根据SpringBoot自动装配的规范要求，需要在文件META-INF/spring.factories文件添加需要自动装配的类。 所以新建文件src\main\resources\META-INF\spring.factories，在文件中添加自动装配的类信息：自动装配的类可以是多个，用英文逗号分隔，使用\进行换行 org.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.test.spring.boot.redisson.RedissionAutoConfiguration在src\main\resources\META-INF\路径下添加一个配置文件additional-spring-configuration-metadata.json,内容如下：{    &quot;properties&quot;: [        {        &quot;name&quot;: &quot;auto.redisson.host&quot;,        &quot;type&quot;: &quot;java.lang.String&quot;,        &quot;description&quot;: &quot;redis服务器地址.&quot;,        &quot;defaultValue&quot;: &quot;localhost&quot;        },{        &quot;name&quot;: &quot;auto.redisson.port&quot;,        &quot;type&quot;: &quot;java.lang.Integer&quot;,        &quot;description&quot;: &quot;redis服务器端口.&quot;,        &quot;defaultValue&quot;: 6379        },{        &quot;name&quot;: &quot;auto.redisson.ssl&quot;,        &quot;type&quot;: &quot;java.lang.Boolean&quot;,        &quot;description&quot;: &quot;是否使用ssl协议.&quot;,        &quot;defaultValue&quot;: false        }, {        &quot;name&quot;: &quot;auto.redission.timeout&quot;,        &quot;type&quot;: &quot;java.lang.Integer&quot;,        &quot;description&quot;: &quot;超时时间.&quot;,        &quot;defaultValue&quot;: 1000        }    ]}执行mvn clean install将项目打包安装到本地Maven仓库另一个项目中直接引入这个自定义的starter组件使用其中定义的RedissonClient组件即可 &lt;!-- 引入自定义的starter组件 --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.test.spring.boot&lt;/groupId&gt;    &lt;artifactId&gt;redisson-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt;SpringBoot配置文件application.properties中添加配置参数</code></pre><h3 id="SpringBoot-跨域解决"><a href="#SpringBoot-跨域解决" class="headerlink" title="SpringBoot 跨域解决"></a>SpringBoot 跨域解决</h3><pre><code>1.SpringBoot 配置 CORS 解决跨域   添加@Configuration注解实现WebMvcConfigurer接口   重写addCorsMappings方法并设置允许跨域的代码2.SpringBoot 通过 CorsFilter 解决跨域3.SpringBoot 通过注解@CrossOrigin解决跨域4.通过 nginx 配置 CORS 解决跨域</code></pre>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka</title>
      <link href="/2020/07/25/Kafka/"/>
      <url>/2020/07/25/Kafka/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Kafka是一种分布式的消息系统，用于实现高可靠性、高吞吐量、低延迟的数据传输。可以把Kafka想象成一个邮局，生产者（相当于寄信人）把消息（信件）发给Kafka，消费者（相当于收信人）从Kafka中获取消息（信件）。这个过程可以实现多生产者、多消费者、多主题的消息传递。"><a href="#Kafka是一种分布式的消息系统，用于实现高可靠性、高吞吐量、低延迟的数据传输。可以把Kafka想象成一个邮局，生产者（相当于寄信人）把消息（信件）发给Kafka，消费者（相当于收信人）从Kafka中获取消息（信件）。这个过程可以实现多生产者、多消费者、多主题的消息传递。" class="headerlink" title="Kafka是一种分布式的消息系统，用于实现高可靠性、高吞吐量、低延迟的数据传输。可以把Kafka想象成一个邮局，生产者（相当于寄信人）把消息（信件）发给Kafka，消费者（相当于收信人）从Kafka中获取消息（信件）。这个过程可以实现多生产者、多消费者、多主题的消息传递。"></a>Kafka是一种分布式的消息系统，用于实现高可靠性、高吞吐量、低延迟的数据传输。可以把Kafka想象成一个邮局，生产者（相当于寄信人）把消息（信件）发给Kafka，消费者（相当于收信人）从Kafka中获取消息（信件）。这个过程可以实现多生产者、多消费者、多主题的消息传递。</h2><h3 id="Kafka的特点"><a href="#Kafka的特点" class="headerlink" title="Kafka的特点"></a>Kafka的特点</h3><pre><code>Kafka具有以下特点：    高性能：Kafka能够提供每秒数百万级别的消息传输，可适应高吞吐量的数据处理场景。    可扩展性：Kafka支持水平扩展，用户可以通过增加broker节点来提高Kafka的吞吐量和容错性能。    可靠性：Kafka提供多副本备份机制，当某些节点故障时，可以自动进行副本切换，确保消息不会丢失。    持久化：Kafka采用磁盘存储，可以长期保存消息，也可根据需要设置消息的保留时间或删除策略。    灵活性和可定制性：Kafka提供各种配置选项，可以根据需要进行灵活定制。    大数据生态系统集成：Kafka可以很好地集成到Hadoop、Spark、Storm等大数据处理系统中，提供数据源或目标的功能。</code></pre>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安全框架</title>
      <link href="/2020/03/25/%E6%9D%83%E9%99%90%E6%A1%86%E6%9E%B6/"/>
      <url>/2020/03/25/%E6%9D%83%E9%99%90%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>Spring Security是非常流行的安全（权限）框架,Web应用框架。</p><h3 id="SpringSecurity的作用"><a href="#SpringSecurity的作用" class="headerlink" title="SpringSecurity的作用"></a>SpringSecurity的作用</h3><p>   主要有两大作用：一个是认证，一个是授权<br>   本质上，它就是Filter过滤器。而且是过滤器链。<br>   认证：<br>      在Spring Security中认证是由AuthenticationManager接⼝来负责的， 它只有一个核心方法Authentication authenticate(Authentication authentication)<br>      一个 AuthenticationManager 认证管理者可能会在 authenticate()方法中做下面三件事中的任意一个:<br>          如果认证成功，返回 Authentication (通常它的authenticated属性为true authenticated=true) .<br>          如果认证失败，抛出 AuthenticationException 异常.<br>          如果无法判断，返回 null</p><pre><code>  AuthenticationManager 最常用的实现是 ProviderManager，在ProviderManager中管理了众多 AuthenticationProvider 实例。在⼀次完整的认证流程中，Spring Security 允许存在多个 AuthenticationProvider ，⽤来实现多种认证⽅式，这些  AuthenticationProvider 都是由ProviderManager进⾏统⼀管理的。授权：   在 Spring Security 的授权体系中，有两个关键接⼝AccessDecisionManager、AccessDecisionVoter        AccessDecisionManager (访问决策管理器)，⽤来决定此次访问是否被允许。        AccessDecisionVoter (访问决定投票器)，投票器会检查⽤户是否具备应有的⻆⾊，进⽽投出赞成、反对或者弃权票。    ConfigAttribute，⽤来保存授权时的⻆⾊信息</code></pre><h3 id="SpringSecurity与Shiro的区别"><a href="#SpringSecurity与Shiro的区别" class="headerlink" title="SpringSecurity与Shiro的区别"></a>SpringSecurity与Shiro的区别</h3><pre><code>Spring Security的特点：    Spring家族的，能很好的整合Spring。    专门为Web应用开发设计的。    提供专业全面的权限。    重量级的。依赖于很多其他组件。在SSM中整合比Shiro麻烦。但在springboot中提供了自动配置方案。Shiro的特点：    它是Apache下的轻量级的权限框架。    轻量级的，依赖少，本身的大小也相对小。    不局限于Web环境，JavaSE下也可以运行。    缺点是针对Web环境下特定需求需要手动编写代码定制。功能没有Spring Security强大。  一般来说，常见的安全管理技术栈：      SSM+shiro      Spring Boot + Spring Security</code></pre><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><pre><code>  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;  &lt;/dependency&gt;</code></pre><h3 id="自定义用户认证"><a href="#自定义用户认证" class="headerlink" title="自定义用户认证"></a>自定义用户认证</h3><pre><code>  实现通过查找数据库来获取用户名密码，完成登录功能。具体的密码校验由spring security内部完成。</code></pre><h3 id="编写配置类"><a href="#编写配置类" class="headerlink" title="编写配置类"></a>编写配置类</h3><pre><code>设置使用哪个UserDetailsService 实现类import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.crypto.password.PasswordEncoder;@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter {    @Autowired    private UserDetailsService userDetailsService;    @Override    protected void configure(AuthenticationManagerBuilder auth) throws Exception {        auth.userDetailsService(userDetailsService)                .passwordEncoder(password());    }    @Bean    public PasswordEncoder password(){        return new BCryptPasswordEncoder();    }}</code></pre><h3 id="编写UserDetailsService实现类"><a href="#编写UserDetailsService实现类" class="headerlink" title="编写UserDetailsService实现类"></a>编写UserDetailsService实现类</h3><pre><code> UserDetailsService接口是springsecurity内部提供的，我们只需要编写对应的实现类即可完成用户认证授权  import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;  import com.hssy.authoritydemo.entity.User;  import com.hssy.authoritydemo.mapper.UserMapper;  import org.springframework.beans.factory.annotation.Autowired;  import org.springframework.security.core.GrantedAuthority;  import org.springframework.security.core.authority.AuthorityUtils;  import org.springframework.security.core.userdetails.UserDetails;  import org.springframework.security.core.userdetails.UserDetailsService;  import org.springframework.security.core.userdetails.UsernameNotFoundException;  import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;  import org.springframework.stereotype.Service;  import java.util.List;  @Service  public class MyUserDetailsService implements UserDetailsService {      @Autowired      private UserMapper userMapper;      @Override      public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {          List&lt;GrantedAuthority&gt; authorities =                  AuthorityUtils.commaSeparatedStringToAuthorityList(&quot;manager&quot;);          LambdaQueryWrapper&lt;User&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;();          queryWrapper.eq(User::getUsername,username);          User user = userMapper.selectOne(queryWrapper);          if (user == null){              throw  new UsernameNotFoundException(&quot;用户不存在&quot;);          }          return new org.springframework.security.core.userdetails.User(                  user.getUsername(),                  new BCryptPasswordEncoder().encode(user.getPassword()),                  authorities          );      }  }</code></pre><h3 id="自定义用户登录页面及访问权限基本设置"><a href="#自定义用户登录页面及访问权限基本设置" class="headerlink" title="自定义用户登录页面及访问权限基本设置"></a>自定义用户登录页面及访问权限基本设置</h3><pre><code> 主要是通过配置类中，重写configure（HttpSecurity http）的这个方法      @Override      protected void configure(HttpSecurity http) throws Exception {          http.formLogin()//表示进行表单登录                  .loginPage(&quot;/login.html&quot;)//自定义的登录页面                  .loginProcessingUrl(&quot;/login&quot;)//传一个登录处理的接口，不管你传的接口地址是什么，都由Security内部完成。当然也可以自己写这个接口，这样就不会用系统来完成登录处理校验用户名密码了。还有就是如果自定义了登录页面，那么登录处理的接口loginProcessingUrl项一定要写，不管是写系统自带的，还是你自己写的处理接口都行，否则报错。                  .usernameParameter(&quot;username&quot;) //定义登录时的用户名的key，即表单中name的值，默认为username                  .passwordParameter(&quot;password&quot;) //定义登录时的密码key,即表单中name的值，默认是password                  //设置的这两个用户名、密码的key，如果不自己写登录页面的话，可以不用写，因为系统默认提供的页面就是这个默认值。写了的话，一定要与表单页面中定义的name值一致才行。                  .defaultSuccessUrl(&quot;/pages/main&quot;)//登录成功跳转到的页面或者路径。当然，如果你不是从登录页面登录的，那么拦截之后会进入到你的请求路径（或页面）中                  .failureUrl(&quot;/login.html&quot;)//登录失败跳转到的页面                  .permitAll() //指和登录表单相关的接口 都通过，不拦截                  .and()                  .authorizeRequests()//开启授权请求                  .antMatchers(&quot;/&quot;,&quot;/pages/main&quot;,&quot;/login&quot;).permitAll()//设置哪些路径放行，不需要认证    不需要登录可以访问的                  .anyRequest().authenticated()//除开上面的，其他所有请求全部都需要权限验证。因为还没有用户授权，所以目前所有的接口登录后都能访问。                  .and()                  .csrf().disable();//关闭csrf防护      }</code></pre><h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><pre><code> 只需要再增加哪些路径需要什么权限才能访问即可完成授权。其他不用变 .antMatchers(&quot;/security/test1&quot;).hasAuthority(&quot;admin&quot;)//表示当前登录用户，只有具有权限名称为admin时，才能访问此地址.     @Override    protected void configure(HttpSecurity http) throws Exception {        http.formLogin()//表示进行表单登录                .loginPage(&quot;/login.html&quot;)//自定义的登录页面                .loginProcessingUrl(&quot;/login&quot;)//传一个登录处理的接口，不管你传的接口地址是什么，都由Security内部完成。当然也可以自己写这个接口，这样就不会用系统来完成登录处理校验用户名密码了。还有就是如果自定义了登录页面，那么登录处理的接口loginProcessingUrl项一定要写，不管是写系统自带的，还是你自己写的处理接口都行，否则报错。                .usernameParameter(&quot;username&quot;) //定义登录时的用户名的key，即表单中name的值，默认为username                .passwordParameter(&quot;password&quot;) //定义登录时的密码key,即表单中name的值，默认是password                //设置的这两个用户名、密码的key，如果不自己写登录页面的话，可以不用写，因为系统默认提供的页面就是这个默认值。写了的话，一定要与表单页面中定义的name值一致才行。                .defaultSuccessUrl(&quot;/pages/main&quot;)//登录成功跳转到的页面或者路径。当然，如果你不是从登录页面登录的，那么拦截之后会进入到你的请求路径（或页面）中                .failureUrl(&quot;/login.html&quot;)//登录失败跳转到的页面                .permitAll() //指和登录表单相关的接口 都通过，不拦截                .and()                .authorizeRequests()//开启授权请求                .antMatchers(&quot;/&quot;,&quot;/pages/main&quot;,&quot;/login&quot;).permitAll()//设置哪些路径放行，不需要认证    不需要登录可以访问的                .antMatchers(&quot;/security/test1&quot;).hasAuthority(&quot;admin&quot;)//表示当前登录用户，只有具有权限名称为admin时，才能访问此地址                .anyRequest().authenticated()//除开上面的，其他所有请求全部都需要认证。                .and()                .csrf().disable();//关闭csrf防护    } 用户增加权限呢，在UserDetailsService实现类中，重写方法增加这个权限即可。</code></pre><p> <img src="/image/%E6%9D%83%E9%99%90%E4%BB%A3%E7%A0%81.png" alt="效果图预览"> </p><h3 id="常见的授权方法"><a href="#常见的授权方法" class="headerlink" title="常见的授权方法"></a>常见的授权方法</h3><pre><code> 1. hasAuthority(String authority) 2. hasAnyAuthority(String... authorities) 3. hasRole(String role) 4. hasAnyRole(String... roles)</code></pre><h3 id="自定义403页面"><a href="#自定义403页面" class="headerlink" title="自定义403页面"></a>自定义403页面</h3><pre><code> 修改访问配置类    http.exceptionHandling().accessDeniedPage(&quot;/unauth&quot;);  添加对应控制器方法    import org.springframework.web.bind.annotation.GetMapping;    import org.springframework.web.bind.annotation.RestController;    @RestController    public class SystemController {        @GetMapping(&quot;/unauth&quot;)        public String unauth(){            return &quot;当前用户无权限访问&quot;;        }    }  其他写法    import org.springframework.stereotype.Controller;    import org.springframework.web.bind.annotation.GetMapping;    @Controller    public class SystemController {        @GetMapping(&quot;/unauth&quot;)        public String unauth(){        //    return &quot;当前用户无权限访问&quot;;            return &quot;forward:403.html&quot;;        }    }</code></pre><h3 id="授权（注解方式）"><a href="#授权（注解方式）" class="headerlink" title="授权（注解方式）"></a>授权（注解方式）</h3><pre><code>主启动类上添加注解   @EnableGlobalMethodSecurity(securedEnabled=true)控制器方法添加相关授权注解   @Secured   @PreAuthorize（重点）</code></pre><h3 id="用户注销"><a href="#用户注销" class="headerlink" title="用户注销"></a>用户注销</h3><pre><code>配置类中增加注销相关配置    //退出配置    http.logout().logoutUrl(&quot;/logout&quot;)//退出登录的处理接口随便写，系统帮你实现。和.loginProcessingUrl类似            .logoutSuccessUrl(&quot;/login.html&quot;)//退出成功跳转的页面或接口            .permitAll();</code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringSecurity </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringSecurity </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Netty</title>
      <link href="/2020/03/20/Netty/"/>
      <url>/2020/03/20/Netty/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>   Netty是当前非常流行的网络通讯框架，当程序对网络数据处理时，需要保证高并发和高可靠，底层就可以用Netty支撑。</p><h3 id="BIO、NIO-和-AIO-的区别"><a href="#BIO、NIO-和-AIO-的区别" class="headerlink" title="BIO、NIO 和 AIO 的区别"></a>BIO、NIO 和 AIO 的区别</h3><p>   BIO：一个连接一个线程，客户端有连接请求时服务器端就需要启动一个线程进行处理。线程开销大。<br>   伪异步 IO：将请求连接放入线程池，一对多，但线程还是很宝贵的资源。<br>   NIO：一个请求一个线程，但客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有 I/O 请求时才启动一个线程进行处理。<br>   AIO：一个有效请求一个线程，客户端的 I/O 请求都是由 OS 先完成了再通知服务器应用去启动线程进行处理，BIO 是面向流的，NIO 是面向缓冲区的；BIO 的各种流是阻塞的。而 NIO 是非阻塞的；BIO的 Stream 是单向的，而 NIO 的 channel 是双向的。</p><p>   NIO 的特点：<br>   事件驱动模型、单线程处理多任务、非阻塞 I/O，I/O 读写不再阻塞，而是返回 0、基于 block 的传输比基于流的传输更高效、更高级的 IO 函数 zero-copy、IO 多路复用大大提高了 Java 网络应用的可伸缩性和实用性。基于 Reactor 线程模型。在 Reactor 模式中，事件分发器等待某个事件或者可应用或个操作的状态发生，事件分发器就把这个事件传给事先注册的事件处理函数或者回调函数，由后者来做实际的读写操作。如在 Reactor 中实现读：注册读就绪事件和相应的事件处理器、事件分发器等待事件、事件到来，激活分发器，分发器调用事件对应的处理器、事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。</p><h3 id="Netty三大核心部分"><a href="#Netty三大核心部分" class="headerlink" title="Netty三大核心部分"></a>Netty三大核心部分</h3><p>   Channel（通道） Buffer(缓冲区) Selector(选择器)</p><p>   1、Buffer</p><p>   一个可以读写数据的内存块，可以理解成是一个容器对象（含数组），该对象提供了一组方法，可以更轻松地使用内存块，缓冲区对象内置了一些机制，能够跟踪和记录缓冲区的状态变化情况。与 Channel 进行交互，数据是从Channel 读入缓冲区，从缓冲区写入 Channel 中的。</p><p>   2、Channel</p><p>   NIO的通道类似于流，但有些区别</p><p>   通道可以同时进行读写，而流只能读或者只能写<br>   通道可以实现异步读写数据<br>   通道可以从缓存读数据，也可以写数据到缓存</p><p>   3、Selector</p><p>   能够检测多个注册的通道上是否有事件发生(注意:多个Channel以事件的方式可以注册到同一个Selector)，如果有事件发生，便获取事件然后针对每个事件进行相应的处理。这样就可以只用一个单线程去管理多个通道，也就是管理多个连接和请求。</p><h3 id="Netty的零拷贝"><a href="#Netty的零拷贝" class="headerlink" title="Netty的零拷贝"></a>Netty的零拷贝</h3><p>   1.零拷贝</p><p>   从操作系统的角度来看，文件的传输不存在CPU的拷贝，只存在DMA拷贝（直接内存拷贝，不使用CPU完成）。零拷贝是网络编程的关键，很多性能优化都离不开它。</p><p>   2.Netty对于零拷贝方式</p><p>   Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS，使用堆外直接内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入Socket中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。<br>   Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样方便的对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffer。<br>   Netty 的文件传输采用了 transferTo 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。</p><h3 id="Netty线程模型"><a href="#Netty线程模型" class="headerlink" title="Netty线程模型"></a>Netty线程模型</h3><p>   Netty线程模型主要基于主从 Reactor 多线程模型做了一定的改进，其中主从Reactor多线程模型有多个 Reactor。</p><p>   内部实现了两个线程池，boss 线程池和 work 线程池，其中 boss 线程池的线程负责处理请求的连接事件，当接收到连接事件的请求时，把对应的socket封装到一个NioSocketChannel 中，并交给 work 线程池，其中 work 线程池负责请求的 read 和 write 事件，由对应的 Handler 处理。</p><p>   其本质将线程连接和具体的业务处理区分开来。</p><h3 id="Netty中有哪些重要组件"><a href="#Netty中有哪些重要组件" class="headerlink" title="Netty中有哪些重要组件"></a>Netty中有哪些重要组件</h3><p>   1、Bootstrap、ServerBootstrap：一个 Netty 应用通常由一个 Bootstrap 开始，主要作用是配置整个 Netty 程序，串联各个组件，Netty 中 Bootstrap 类是客户端程序的启动引导类，ServerBootstrap 是服务端启动引导类。</p><p>   2、Future、ChannelFuture：Netty 中所有的 IO 操作都是异步的，不能立刻得知消息是否被正确处理。但是可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过 Future 和 ChannelFutures，他们可以注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件。</p><p>   3、Channel：Netty 网络操作抽象类，它除了包括基本的 I/O 操作，如 bind、connect、read、write 等</p><p>   4、Selector：基于 Selector 对象实现I/O多路复用，通过 Selector 一个线程可以监听多个连接的 Channel 事件，Selector 内部的机制就可以自动不断地查询(Select) 这些注册的 Channel是否有已就绪的I/O 事件（例如可读，可写，网络连接完成等）</p><p>   5、ChannelHandler：充当了所有处理入站和出站数据的逻辑容器。ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。</p><p>   6、EventLoop：主要是配合 Channel 处理 I/O 操作，用来处理连接的生命周期中所发生的事情</p><p>   7、ChannelPipeline：为 ChannelHandler 链提供了容器，当 channel 创建时，就会被自动分配到它专属的 ChannelPipeline，这个关联是永久性的。</p><p>   8、ChannelHandlerContext：包 含 一 个 具 体 的 事 件 处 理 器 ChannelHandler ， 同 时ChannelHandlerContext 中也绑定了对应的 pipeline 和 Channel 的信息，方便对 ChannelHandler进行调用。</p><h3 id="Netty如何解决拆包和粘包问题"><a href="#Netty如何解决拆包和粘包问题" class="headerlink" title="Netty如何解决拆包和粘包问题"></a>Netty如何解决拆包和粘包问题</h3><p>   主要思路：在数据包的前面加上一个固定字节数的数据长度，如加上一个 int（固定四个字节）类型的数据内容长度。</p><p>   就算客户端同时发送两个数据包到服务端，当服务端接受时，也可以先读取四个字节的长度，然后根据长度获取消息的内容，这样就不会出现多读取或者少读取的情况了。</p><h3 id="Netty主要采用了哪种设计模式"><a href="#Netty主要采用了哪种设计模式" class="headerlink" title="Netty主要采用了哪种设计模式"></a>Netty主要采用了哪种设计模式</h3><p>   netty的 pipeline 设计,就采用了责任链设计模式，底层采用双向链表的数据结构，将链上的各个处理器（Handler）串联起来。</p><p>   客户端每一个请求的到来，netty 认为，pipeline 中的所有的处理器都有机会处理它，因此，对于入栈的请求，全部从头节点开始往后传播，一直传播到尾节点。</p><p>   开发者可以自主的删除或者添加责任链中的某个节点。</p><h3 id="Netty-是如何保持长连接的"><a href="#Netty-是如何保持长连接的" class="headerlink" title="Netty 是如何保持长连接的"></a>Netty 是如何保持长连接的</h3><p>   什么是长连接？</p><pre><code>  客户端和服务器之间定期发送的一种特殊的数据包，通知对方自己还在线, 以确保 TCP 连接的有效性。但是由于网络不稳定性，有可能在 TCP 保持长连接的过程中，由于某些突发情况， 例如网线被拔出， 突然掉电等。 会造成服务器和客户端的连接中断。在这些突发情况下, 如果恰好服务器和客户端之间没有交互的话，那么它们是不能在短时间内发现对方已经掉线的。</code></pre><p>   如何保持长连接？</p><pre><code>  利用心跳维护长连接信息。  在服务器和客户端之间一定时间内没有数据交互时，即处于 idle 状态时，客户端或服务器会发送一个特殊的数据包给对方，当接收方收到这个数据报文后， 也立即发送一个特殊的数据报文， 回应发送方， 此即一个 PING-PONG 交互。</code></pre><p>   当某一端收到心跳消息后， 就知道了对方仍然在线， 这就确保 TCP 连接的有效性。</p><p>   Netty有三种类型保持心跳类型</p><p>   readerIdleTime：为读超时时间（即测试端一定时间内未接受到被测试端消息）。<br>   writerIdleTime：为写超时时间（即测试端一定时间内向被测试端发送消息）。<br>   allIdleTime：所有类型的超时时间。</p>]]></content>
      
      
      <categories>
          
          <category> Netty </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Netty </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ShardingJDBC</title>
      <link href="/2020/03/15/shardingJDBC/"/>
      <url>/2020/03/15/shardingJDBC/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>ShardingJDBC</p><h3 id="1、分库分表的方式"><a href="#1、分库分表的方式" class="headerlink" title="1、分库分表的方式"></a>1、分库分表的方式</h3><pre><code>分库分表包括分库和分表两个部分，在生产中通常包括：垂直分库、水平分库、垂直分表、水平分表四种方式。 </code></pre><p>   hexokinase</p><h3 id="2、Sharding-JDBC"><a href="#2、Sharding-JDBC" class="headerlink" title="2、Sharding-JDBC"></a>2、Sharding-JDBC</h3><pre><code>Sharding-JDBC的核心功能为数据分片和读写分离，通过Sharding-JDBC，应用可以透明的使用jdbc访问已经分库 分表、读写分离的多个数据源，而不用关心数据源的数量以及数据如何分布。 Sharding-JDBC执行流程： SQL解析 =&gt; 查询优化 =&gt; SQL路由 =&gt; SQL改写 =&gt; SQL执行 =&gt; 结果归并引入 sharding-jdbc和SpringBoot整合的Jar包：   &lt;dependency&gt;        &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;        &lt;artifactId&gt;sharding‐jdbc‐spring‐boot‐starter&lt;/artifactId&gt;        &lt;version&gt;4.0.0‐RC1&lt;/version&gt;     &lt;/dependency&gt;</code></pre><h3 id="3、分片规则配置"><a href="#3、分片规则配置" class="headerlink" title="3、分片规则配置"></a>3、分片规则配置</h3><pre><code>分片规则配置是sharding-jdbc进行对分库分表操作的重要依据，配置内容包括：数据源、主键生成策略、分片策 略等。</code></pre><h3 id="4、配置"><a href="#4、配置" class="headerlink" title="4、配置"></a>4、配置</h3><pre><code>   # 真实数据源定义 m为主库 s为从库    spring.shardingsphere.datasource.names = m0,m1,m2,s0,s1,s2     spring.shardingsphere.datasource.m0.type = com.alibaba.druid.pool.DruidDataSource     spring.shardingsphere.datasource.m0.driver‐class‐name = com.mysql.jdbc.Driver     spring.shardingsphere.datasource.m0.url = jdbc:mysql://localhost:3306/store_db?useUnicode=true     spring.shardingsphere.datasource.m0.username = root spring.shardingsphere.datasource.m0.password = root     spring.shardingsphere.datasource.m1.type = com.alibaba.druid.pool.DruidDataSource     spring.shardingsphere.datasource.m1.driver‐class‐name = com.mysql.jdbc.Driver     spring.shardingsphere.datasource.m1.url = jdbc:mysql://localhost:3306/product_db_1? useUnicode=true     spring.shardingsphere.datasource.m1.username = root spring.shardingsphere.datasource.m1.password = root     spring.shardingsphere.datasource.m2.type = com.alibaba.druid.pool.DruidDataSource     spring.shardingsphere.datasource.m2.driver‐class‐name = com.mysql.jdbc.Driver     spring.shardingsphere.datasource.m2.url = jdbc:mysql://localhost:3306/product_db_2? useUnicode=true     spring.shardingsphere.datasource.m2.username = root     spring.shardingsphere.datasource.m2.password = root     spring.shardingsphere.datasource.s0.type = com.alibaba.druid.pool.DruidDataSource     spring.shardingsphere.datasource.s0.driver‐class‐name = com.mysql.jdbc.Driver     spring.shardingsphere.datasource.s0.url = jdbc:mysql://localhost:3307/store_db?useUnicode=true     spring.shardingsphere.datasource.s0.username = root     spring.shardingsphere.datasource.s0.password = root     spring.shardingsphere.datasource.s1.type = com.alibaba.druid.pool.DruidDataSource     spring.shardingsphere.datasource.s1.driver‐class‐name = com.mysql.jdbc.Driver     spring.shardingsphere.datasource.s1.url = jdbc:mysql://localhost:3307/product_db_1? useUnicode=true     spring.shardingsphere.datasource.s1.username = root     spring.shardingsphere.datasource.s1.password = root     spring.shardingsphere.datasource.s2.type = com.alibaba.druid.pool.DruidDataSource     spring.shardingsphere.datasource.s2.driver‐class‐name = com.mysql.jdbc.Driver     spring.shardingsphere.datasource.s2.url = jdbc:mysql://localhost:3307/product_db_2? useUnicode=true     spring.shardingsphere.datasource.s2.username = root spring.shardingsphere.datasource.s2.password = root     # 主库从库逻辑数据源定义 ds0为store_db ds1为product_db_1 ds2为product_db_2     spring.shardingsphere.sharding.master‐slave‐rules.ds0.master‐data‐source‐name=m0     spring.shardingsphere.sharding.master‐slave‐rules.ds0.slave‐data‐source‐names=s0    spring.shardingsphere.sharding.master‐slave‐rules.ds1.master‐data‐source‐name=m1     spring.shardingsphere.sharding.master‐slave‐rules.ds1.slave‐data‐source‐names=s1     spring.shardingsphere.sharding.master‐slave‐rules.ds2.master‐data‐source‐name=m2     spring.shardingsphere.sharding.master‐slave‐rules.ds2.slave‐data‐source‐names=s2     # 默认分库策略，以store_info_id为分片键，分片策略为store_info_id % 2 + 1，也就是store_info_id为双数的 数据进入ds1，为单数的进入ds2     spring.shardingsphere.sharding.default‐database‐strategy.inline.sharding‐column = store_info_id     spring.shardingsphere.sharding.default‐database‐strategy.inline.algorithm‐expression = ds$‐&gt; {store_info_id % 2 + 1}     # store_info分表策略，固定分配至ds0的store_info真实表，     spring.shardingsphere.sharding.tables.store_info.actual‐data‐nodes = ds$‐&gt;{0}.store_info     spring.shardingsphere.sharding.tables.store_info.table‐strategy.inline.sharding‐column = id     spring.shardingsphere.sharding.tables.store_info.table‐strategy.inline.algorithm‐expression = store_info     # product_info分表策略，分布在ds1,ds2的product_info_1 product_info_2表 ，分片策略为product_info_id % 2 + 1，product_info_id生成为雪花算法，为双数的数据进入product_info_1表，为单数的进入product_info_2 表    spring.shardingsphere.sharding.tables.product_info.actual‐data‐nodes = ds$‐&gt; {1..2}.product_info_$‐&gt;{1..2}     spring.shardingsphere.sharding.tables.product_info.table‐strategy.inline.sharding‐column = product_info_id     spring.shardingsphere.sharding.tables.product_info.table‐strategy.inline.algorithm‐expression = product_info_$‐&gt;{product_info_id % 2 + 1}     spring.shardingsphere.sharding.tables.product_info.key‐generator.column=product_info_id     spring.shardingsphere.sharding.tables.product_info.key‐generator.type=SNOWFLAKE     # product_descript分表策略，分布在ds1,ds2的product_descript_1 product_descript_2表 ，分片策略为 product_info_id % 2 + 1，id生成为雪花算法，product_info_id为双数的数据进入product_descript_1表，为单 数的进入product_descript_2表     spring.shardingsphere.sharding.tables.product_descript.actual‐data‐nodes = ds$‐&gt; {1..2}.product_descript_$‐&gt;{1..2}     spring.shardingsphere.sharding.tables.product_descript.table‐strategy.inline.sharding‐column = product_info_id     spring.shardingsphere.sharding.tables.product_descript.table‐strategy.inline.algorithm‐ expression = product_descript_$‐&gt;{product_info_id %2+1}     spring.shardingsphere.sharding.tables.product_descript.key‐generator.column=id    spring.shardingsphere.sharding.tables.product_descript.key‐generator.type=SNOWFLAKE     # 设置product_info,product_descript为绑定表     spring.shardingsphere.sharding.binding‐tables[0] = product_info,product_descript     # 设置region为广播表(公共表)，每次更新操作会发送至所有数据源     spring.shardingsphere.sharding.broadcast‐tables=region     # 打开sql输出日志     spring.shardingsphere.props.sql.show = true</code></pre>]]></content>
      
      
      <categories>
          
          <category> ShardingJDBC，分库分表，脱敏 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ShardingJDBC，分库分表，脱敏 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java中事务</title>
      <link href="/2020/03/08/java%E4%B8%AD%E4%BA%8B%E5%8A%A1/"/>
      <url>/2020/03/08/java%E4%B8%AD%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><p> 事务分为编程式事务和声明式事务两种，编程式事务指在代码中手动的管理事务的提交、回滚等操作，代码侵入性比较强。声明式事务是基于 AOP 面向切面的，它将具体业务与事务处理部分解耦，代码侵入性很低，声明式事务也有两种实现方式，一种是基于 TX 和 AOP 的 xml 配置文件方式，二种就是基于 @Transactional 注解了</p><a id="more"></a><h3 id="Transactional"><a href="#Transactional" class="headerlink" title="@Transactional"></a>@Transactional</h3><pre><code> @Transactional 可以作用在类上，当作用在类上的时候，表示所有该类的 public 方法都配置相同的事务属性信息。@Transactional 也可以作用在方法上，当方法上也配置了 @Transactional，方法的事务会覆盖类的事务配置信息。</code></pre><p><img src="/image/Transactiona%E6%B3%A8%E8%A7%A3.png" alt="效果图预览">   </p><pre><code> 回滚是只判断异常类型是RuntimeException 和 Error 的才会进行回滚，别的异常类型是不会回滚的。</code></pre><h3 id="propagation属性"><a href="#propagation属性" class="headerlink" title="propagation属性"></a>propagation属性</h3><p>  事务七种传播行为<br><img src="/image/%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E5%B1%9E%E6%80%A7.png" alt="效果图预览">   </p><h3 id="Transactional-的失效场景"><a href="#Transactional-的失效场景" class="headerlink" title="@Transactional 的失效场景"></a>@Transactional 的失效场景</h3><pre><code>1、@Transactional 应用在非 public 修饰的方法上，@Transactional 将会失效。protected、private 修饰的方法上使用 @Transactional 注解，虽然事务无效，但不会有任何报错，这是我们很容犯错的一点。2、@Transactional 注解属性 propagation 设置错误。PROPAGATION_SUPPORTS、PROPAGATION_NOT_SUPPORTED、PROPAGATION_NEVER上面这三种都没有讲到，因为用了它们事务是不会发生回滚，加了等于没加。3、@Transactional 注解属性 rollbackFor 设置错误，默认的只会对 RuntimeException 类型和 Error 类型的才进行回滚。如果在事务中抛出其他类型的异常，却希望 Spring 能够回滚事务，就需要指定 rollbackFor 属性。4、同一个类中方法调用，导致 @Transactional 失效。总方法调子方法的时候，要放在不同的 service 里面，如果放在一个类里面，事务调用是不会生效的。5、异常被吃了，吃掉以后虽然不影响其他事务，但是其他数据的 commit 会造成数据不一致，所以有些时候 try catch 反倒会画蛇添足。6、数据库引擎不支持事务，这一点很简单，myisam 引擎是不支持事务的，innodb 引擎支持事务。7、数据源没有配置事务管理器，这个也很简单，要使用事务肯定要配事务管理器。Hibernate 用的是HibernateTransactionManager，JDBC 和 Mybatis 用的是 DataSourceTransactionManager。8 、最后就是一个方法内多数据库（多数据源）的情况下会失效，这个也是我同事做实验得出来的。</code></pre><h3 id="声明式事务"><a href="#声明式事务" class="headerlink" title="声明式事务"></a>声明式事务</h3><pre><code> 声明式事务主要是通过AOP      启动时扫描@Transactional           注解：在启动时，Spring Boot会扫描所有使用了@Transactional注解的方法，并将其封装成TransactionAnnotationParser对象。           AOP 来实现事务管理的核心类依然是 TransactionInterceptor。TransactionInterceptor 是一个拦截器，用于拦截使用了 @Transactional 注解的方法           将TransactionInterceptor织入到目标方法中：在AOP编程中，使用AspectJ           编写切面类，通过@Around注解将TransactionInterceptor织入到目标方法中。           在目标方法执行前创建事务：在目标方法执行前，TransactionInterceptor会调用PlatformTransactionManager创建一个新的事务，并将其纳入到当前线程的事务上下文中。           执行目标方法：在目标方法执行时，如果发生异常，则将事务状态标记为ROLLBACK_ONLY           ；否则，将事务状态标记为COMMIT。           提交或回滚事务：在目标方法执行完成后，TransactionInterceptor会根据事务状态（COMMIT或ROLLBACK_ONLY）来决定是否提交或回滚事务。</code></pre><h3 id="声明式事务和编程式事务"><a href="#声明式事务和编程式事务" class="headerlink" title="声明式事务和编程式事务"></a>声明式事务和编程式事务</h3><pre><code> 技术实现方式：声明式事务是通过AOP技术来实现的，而编程式事务是通过编写具体的代码来实现的。 代码耦合度：声明式事务可以将事务处理逻辑从业务代码中分离出来，从而降低代码的耦合度。而编程式事务需要在业务代码中显式地调用事务管理代码，因此会增加代码的耦合度。 难易程度：声明式事务相对来说比较容易上手，开发人员只需要学习注解或XML配置即可。而编程式事务需要开发人员理解事务管理的底层机制，并编写具体的代码。 性能影响：由于声明式事务是由容器来处理的，所以在一些场景下可能会对性能产生影响，大事务会有很多问题（下面在说一下大事务出现的问题）。而编程式事务由于直接调用事务管理API，相对来说会有更好的性能表现。</code></pre><h3 id="声明式事务-1"><a href="#声明式事务-1" class="headerlink" title="声明式事务"></a>声明式事务</h3><pre><code> 声明式事务通常通过AOP技术实现，在方法或类级别上声明事务属性。 声明式事务的优点包括：      简化代码：开发人员只需要关注业务逻辑，而无需手动管理事务，可以减少代码复杂度和工作量。      可配置性强：事务属性可以通过XML文件、注解等方式进行配置，灵活方便。      易于扩展：可以通过AOP技术轻松地扩展使其支持新的事务策略。 声明式事务存在以下缺点：      限制较大：事务属性需要在方法或类级别进行声明，这可能会导致某些情况下难以满足特定的业务需求。      难以调试：由于事务是在AOP层面进行管理的，因此在调试时可能难以追踪事务管理的具体细节。</code></pre><h3 id="编程式事务"><a href="#编程式事务" class="headerlink" title="编程式事务"></a>编程式事务</h3><pre><code> 编程式事务通常通过API接口实现，开发人员可以在代码中显式地管理事务。 编程式事务的优点包括：      灵活性强：开发人员可以在代码中根据具体业务需要来控制事务的具体范围和属性。      易于调试：由于事务管理在代码层面上实现，因此开发人员可以很容易地追踪事务管理的细节。 编程式事务存在以下缺点：      代码复杂度高：需要在代码中手动处理事务，并处理各种异常情况，可能会增加代码的复杂度和工作量。      可配置性差：事务的范围和属性需要在代码中显式声明，这可能会导致一些特定的业务需求难以满足。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 事务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins</title>
      <link href="/2020/01/08/Jenkins/"/>
      <url>/2020/01/08/Jenkins/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><h3 id="Jenkins是什么"><a href="#Jenkins是什么" class="headerlink" title="Jenkins是什么"></a>Jenkins是什么</h3><pre><code>Jenkins 是一款流行的开源持续集成（Continuous Integration）工具，广泛用于项目开发，具有自动化构建、测试和部署等功能。官网： http://jenkins-ci.org/。Jenkins的特征：    开源的Java语言开发持续集成工具，支持持续集成，持续部署。    易于安装部署配置：可通过yum安装,或下载war包以及通过docker容器等快速实现安装部署，可方便web界面配置管理。    消息通知及测试报告：集成RSS/E-mail通过RSS发布构建结果或当构建完成时通过e-mail通知，生成JUnit/TestNG测试报告。    分布式构建：支持Jenkins能够让多台计算机一起构建/测试。    文件识别：Jenkins能够跟踪哪次构建生成哪些jar，哪次构建使用哪个版本的jar等。    丰富的插件支持：支持扩展插件，你可以开发适合自己团队使用的工具，如git，svn，maven，docker等。</code></pre><h3 id="Gitlab安装"><a href="#Gitlab安装" class="headerlink" title="Gitlab安装"></a>Gitlab安装</h3><pre><code>1.安装相关依赖    yum -y install policycoreutils openssh-server openssh-clients postfix2.启动ssh服务&amp;设置为开机启动    systemctl enable sshd &amp;&amp; sudo systemctl start sshd3.设置postfix开机自启，并启动，postfix支持gitlab发信功能    systemctl enable postfix &amp;&amp; systemctl start postfix4.开放ssh以及http服务，然后重新加载防火墙列表    firewall-cmd --add-service=ssh --permanent    firewall-cmd --add-service=http --permanent    firewall-cmd --reload5. 下载gitlab包，并且安装    在线下载安装包：        wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-12.4.2-ce.0.el7.x86_64.rpm    安装：        rpm -i gitlab-ce-12.4.2-ce.0.el7.x86_64.rpm6.修改gitlab配置    vi /etc/gitlab/gitlab.rb    修改gitlab访问地址和端口，默认为80，我们改为82    external_url &#39;http://192.168.159.100:82    nginx[&#39;listen_port&#39;] = 827.重载配置及启动gitlab    gitlab-ctl reconfigure    gitlab-ctl restart8.把端口添加到防火墙   firewall-cmd --zone=public --add-port=82/tcp --permanent   firewall-cmd --reload</code></pre>]]></content>
      
      
      <categories>
          
          <category> Jenkins </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql数据库</title>
      <link href="/2019/12/28/mysql%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>/2019/12/28/mysql%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><h3 id="1-树"><a href="#1-树" class="headerlink" title="1.树"></a>1.树</h3><pre><code>二叉树：二叉树是指每个结点最多有两个子树的树结构。平衡二叉搜索树：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。</code></pre><h3 id="2-索引的本质"><a href="#2-索引的本质" class="headerlink" title="2.索引的本质"></a>2.索引的本质</h3><pre><code> 索引是帮助mysql数据库快速获取数据排好顺序的而数据结构。</code></pre><h3 id="3-mysql数据库中锁"><a href="#3-mysql数据库中锁" class="headerlink" title="3.mysql数据库中锁"></a>3.mysql数据库中锁</h3><pre><code>  悲观锁，假设丢失更新一定存在；sql后面加上for update；这是数据库的一种机制。  乐观锁，假设丢失更新不一定发生。update时候存在版本，更新时候按版本号进行更新。   表级锁：开销小，加锁块；不会出现死锁，锁定粒度大，发生锁冲突的概率最高，并发度最低。</code></pre><p>　　　　行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发性也最高。</p><p>　　　　页面锁：开销和加锁界于表锁和行锁之间，会出现死锁；锁定粒度界与表锁和行锁之间，并发一般。</p><pre><code>   共享锁：就是允许多个线程同时获取一个锁，一个锁可以同时被多个线程拥有。   排它锁：也称作独占锁，一个锁在某一时刻只能被一个线程占有，其它线程必须等待锁被释放之后才可能获取到锁。</code></pre><h3 id="4-事务的四大特性（ACID）"><a href="#4-事务的四大特性（ACID）" class="headerlink" title="4.事务的四大特性（ACID）"></a>4.事务的四大特性（ACID）</h3><pre><code> 原子性（Atomicity）： 事务开始后所有操作，要么全部成功，要么全部失败，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像 没  有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。 一致性（Consistency）：一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 隔离性（Isolation）:隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。  持久性（Durability）:持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。</code></pre><h3 id="5-事务的并发问题"><a href="#5-事务的并发问题" class="headerlink" title="5.事务的并发问题"></a>5.事务的并发问题</h3><pre><code>  脏读： 在一个事务处理过程里读取了另一个未提交的事务中的数据。  不可重复读: 是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。  幻读: 第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入或删除一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。</code></pre><h3 id="6-隔离级别及并发"><a href="#6-隔离级别及并发" class="headerlink" title="6.隔离级别及并发"></a>6.隔离级别及并发</h3><pre><code>         事务隔离级别           脏读       不可重复读    幻读   读未提交（read-uncommitted）    是           是             是   读已提交 （read-committed）    否        是            是   可重复读（repeatable-read）    否        否            是   串行化（serializable）          否        否            否   MySQL默认的是 可重复读（repeatable-read），而其它的数据库默认的是 读已提交 （read-committed）</code></pre><h3 id="7-事务的七大传播机制"><a href="#7-事务的七大传播机制" class="headerlink" title="7.事务的七大传播机制"></a>7.事务的七大传播机制</h3><pre><code>               类型                          说明    PROPAGATION_REQUIRED            如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。    PROPAGATION_SUPPORTS            支持当前事务，如果当前没有事务，就以非事务方式执行。    PROPAGATION_MANDATORY            使用当前的事务，如果当前没有事务，就抛出异常。    PROPAGATION_REQUIRES_NEW        新建事务，如果当前存在事务，把当前事务挂起。    PROPAGATION_NOT_SUPPORTED        以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。    PROPAGATION_NEVER                以非事务方式执行，如果当前存在事务，则抛出异常。    PROPAGATION_NESTED                如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。    注意：MySQL默认的是 PROPAGATION_REQUIRED</code></pre><h3 id="8-导致索引失效"><a href="#8-导致索引失效" class="headerlink" title="8.导致索引失效"></a>8.导致索引失效</h3><pre><code>    1.如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)    2.对于多列索引，不是使用的第一部分，则不会使用索引    3.like查询是以%开头    4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引    5.如果mysql估计使用全表扫描要比使用索引快,则不使用索引</code></pre><h3 id="9-jdbc执行过程"><a href="#9-jdbc执行过程" class="headerlink" title="9.jdbc执行过程"></a>9.jdbc执行过程</h3><pre><code>    获得连接-》预编译sql-》设置参数-》执行</code></pre><h3 id="10-红黑树和B十树的区别"><a href="#10-红黑树和B十树的区别" class="headerlink" title="10.红黑树和B十树的区别"></a>10.红黑树和B十树的区别</h3><pre><code>结构：  红黑树：红黑树是一种二叉搜索树，每个节点最多只能包含两个子节点。  b树：B树是一种多路搜索树，它的每个节点可以包含多个键值和子节点。效率不同：  红黑树：对于查找较少数据的情况下，红黑树的常数操作次数更小，效率优于B树。  b树：B树相比红黑树因为其每个节点可以存储多个键值，所以在查找大量数据时，B树的磁盘读取次数通常比红黑树要少。策略不同：  红黑树：红黑树属于内排序，内排序是被排序的数据元素全部存放在计算机内存中的排序算法。  b树：b树属于外排序，外排序是指数据存放在外存中,数据排序时涉及内、外存数据交换的排序方法。应用场景不同：  红黑树：红黑树更适用于实现集合和映射等数据结构，以及其它查找频繁的场景。  b树：B树更适用于实现数据库索引等需要频繁插入和删除操作的场景。维护平衡性手段不同：  红黑树：红黑树通过每个节点要么是红色要么是黑色，并且满足一定的红黑规则来保持平衡。  b树：B树则是维护节点的高度平衡，通过节点的平衡因子来判断平衡状态。</code></pre><h3 id="11-MySQL-性能优化"><a href="#11-MySQL-性能优化" class="headerlink" title="11.MySQL 性能优化"></a>11.MySQL 性能优化</h3><p>  11.1 硬件优化<br>      11.1.1. 增加内存</p><pre><code>    SHOW VARIABLES LIKE &#39;innodb_buffer_pool_size&#39;;    SET GLOBAL max_connections = 10000;    SET GLOBAL innodb_buffer_pool_size = 23622320128;    确保有足够的内存来缓存索引和数据，以减少磁盘I/O。    设置innodb_buffer_pool_size，通常应设置为物理内存的70%-80%。  11.1.2. 使用快速存储设备    使用SSD代替HDD，以提高读取和写入速度。    确保存储设备的I/O能力能够满足数据库的需求。</code></pre><p>  11.2配置优化<br>       11.2.1. MySQL配置<br>        调整innodb_buffer_pool_size，增加InnoDB缓冲池大小。<br>        设置query_cache_size和query_cache_type以利用查询缓存。<br>        配置thread_cache_size，减少线程创建和销毁的开销。<br>        调整table_open_cache和table_definition_cache以适应更多的表打开需求。<br>      11.2.2. 连接管理<br>        使用连接池（如HikariCP、C3P0）来管理数据库连接，减少连接创建和关闭的开销。<br> 11.3架构优化<br>      11.3.1. 数据库分片<br>        将数据库分片，将数据分布到多个服务器上，以减少单个服务器的负载。<br>      11.3.2. 主从复制<br>        使用主从复制（Master-Slave Replication）来分担读负载，提高读性能。<br>      11.3.3. 读写分离<br>        通过读写分离，将写操作发送到主库，读操作发送到从库，平衡负载。<br> 11.4查询优化<br>      11.4.1. 使用索引<br>        创建适当的索引来加速查询，特别是针对WHERE、JOIN、ORDER BY、GROUP BY等操作。<br>        使用覆盖索引（covering index），以减少回表操作。<br>        避免在索引列上使用函数和操作符，这会使索引失效。<br>      11.4.2. 优化查询语句<br>        避免使用SELECT *，只查询需要的列。<br>        使用EXPLAIN分析查询计划，优化查询路径。<br>        避免子查询（Subquery），尽量使用JOIN替代。<br>        使用批量插入（Batch Insert）和更新，以减少单次操作的开销。<br>      11.4.3. 拆分复杂查询<br>        将复杂查询拆分为多个简单查询，减少锁定时间和资源消耗。<br> 11.5索引优化<br>      11.5.1. 合理使用索引<br>        对频繁查询的列创建索引，如主键、外键、JOIN列和过滤条件列。<br>        避免过多索引，因为索引也会占用存储空间和影响写性能。<br>      11.5.2. 定期维护索引<br>        使用ANALYZE TABLE和OPTIMIZE TABLE定期维护表和索引，确保索引统计信息的准确性。</p><p>  11.6表设计优化<br>      11.6.1. 正规化与反规范化<br>        根据实际情况进行表的正规化和反规范化，平衡存储和查询性能。<br>      11.6.2. 数据类型选择<br>        使用合适的数据类型，尽量使用定长数据类型，以节省存储空间和提高查询速度。<br>        避免使用TEXT和BLOB类型，尽量使用VARCHAR或其他更小的数据类型。<br>      11.6.3. 分区表<br>        对大表进行分区（Partitioning），提高查询性能和管理效率。</p><p>  11.7缓存优化<br>      11.7.1. 查询缓存<br>        使用MySQL的查询缓存（Query Cache）来缓存查询结果，提高相同查询的响应速度。<br>      11.7.2. 应用级缓存<br>        在应用层使用缓存（如Redis、Memcached）来缓存频繁访问的数据，减轻数据库负载。</p><p>  11.8监控与调优<br>     11.8.1. 监控工具<br>        使用监控工具（如Percona Monitoring and Management、New Relic、Zabbix）来监控数据库性能，发现瓶颈。<br>     11.8.2. 定期调优<br>        定期检查和优化数据库配置、查询和索引，确保数据库保持最佳性能。</p><h3 id="12-MySQL-命令行登录"><a href="#12-MySQL-命令行登录" class="headerlink" title="12.MySQL 命令行登录"></a>12.MySQL 命令行登录</h3><pre><code>mysql -h 127.0.0.1 -P 3306 -u root -p</code></pre><h3 id="13-MySQL-查看当前进程"><a href="#13-MySQL-查看当前进程" class="headerlink" title="13.MySQL 查看当前进程"></a>13.MySQL 查看当前进程</h3><pre><code>SELECT * FROM INFORMATION_SCHEMA.PROCESSLIST;查询出来的结果都是什么意思。    Id: 就是这个线程的唯一标识，当我们发现这个线程有问题的时候，可以通过 kill 命令，加上这个Id值将这个线程杀掉。前面我们说了show processlist 显示的信息时来自information_schema.processlist 表，所以这个Id就是这个表的主键。    User: 就是指启动这个线程的用户。    Host: 记录了发送请求的客户端的 IP 和 端口号。通过这些信息在排查问题的时候，我们可以定位到是哪个客户端的哪个进程发送的请求。    DB: 当前执行的命令是在哪一个数据库上。如果没有指定数据库，则该值为 NULL 。    Command: 是指此刻该线程正在执行的命令。这个很复杂，下面单独解释    Time: 表示该线程处于当前状态的时间。    State: 线程的状态，和 Command 对应，下面单独解释。    Info: 一般记录的是线程执行的语句。默认只显示前100个字符，也就是你看到的语句可能是截断了的，要看全部信息，需要使用 show full processlist。Command 的值：    Binlog Dump: 主节点正在将二进制日志 ，同步到从节点    Change User: 正在执行一个 change-user 的操作    Close Stmt: 正在关闭一个Prepared Statement 对象    Connect: 一个从节点连上了主节点    Connect Out: 一个从节点正在连主节点    Create DB: 正在执行一个create-database 的操作    Daemon: 服务器内部线程，而不是来自客户端的链接    Debug: 线程正在生成调试信息    Delayed Insert: 该线程是一个延迟插入的处理程序    Drop DB: 正在执行一个 drop-database 的操作    Execute: 正在执行一个 Prepared Statement    Fetch: 正在从Prepared Statement 中获取执行结果    Field List: 正在获取表的列信息    Init DB: 该线程正在选取一个默认的数据库    Kill : 正在执行 kill 语句，杀死指定线程    Long Data: 正在从Prepared Statement 中检索 long data    Ping: 正在处理 server-ping 的请求    Prepare: 该线程正在准备一个 Prepared Statement    ProcessList: 该线程正在生成服务器线程相关信息    Query: 该线程正在执行一个语句    Quit: 该线程正在退出    Refresh：该线程正在刷表，日志或缓存；或者在重置状态变量，或者在复制服务器信息    Register Slave： 正在注册从节点    Reset Stmt: 正在重置 prepared statement    Set Option: 正在设置或重置客户端的 statement-execution 选项    Shutdown: 正在关闭服务器    Sleep: 正在等待客户端向它发送执行语句    Statistics: 该线程正在生成 server-status 信息    Table Dump: 正在发送表的内容到从服务器    Time: Unused</code></pre><h3 id="14-mysql-三大日志"><a href="#14-mysql-三大日志" class="headerlink" title="14.mysql 三大日志"></a>14.mysql 三大日志</h3><pre><code>    MySQL三大日志分别是：重做日志（redo log）、回滚日志（undo log）和二进制日志（binlog）。    重做日志（redo log）：确保事务的持久性。MySQL在事务提交后，会将提交的事务写入重做日志中，之后再更新磁盘上的数据页。    回滚日志（undo log）：保证事务的原子性和隔离性。当事务对数据库进行修改时，Undo Log会记录旧的数据的版本，以便在事务失败时回滚到修改前的状态，或者在事务回滚时回滚到回滚点。    二进制日志（binlog）：支持数据的复制和恢复。MySQL的二进制日志（binary log）记录了所有的DDL和DML语句，用于复制功能，也可以用于数据恢复。    实例代码：    重做日志和回滚日志通常是在存储引擎层由各个存储引擎如InnoDB自行管理和使用的，而二进制日志则通过MySQL服务器层的日志管理工具来管理和使用    开启二进制日志：    SET sql_log_bin = 1; -- 开启    SET sql_log_bin = 0; -- 关闭    查看二进制日志事件：    SHOW BINARY LOGS; -- 查看二进制日志列表    SHOW BINLOG EVENTS IN &#39;mysql-bin.000001&#39;; -- 查看指定二进制日志的事件    配置二进制日志：    [mysqld]    log_bin = /var/log/mysql/mysql-bin.log    expire_logs_days = 7    max_binlog_size = 100M    查看正在写入的二进制日志：    SHOW MASTER STATUS;    注意：重做日志和回滚日志是InnoDB存储引擎特有的日志，而二进制日志则是MySQL服务器层面的日志，不同的存储引擎可能不一样。</code></pre><h3 id="15-MySQL索引类型"><a href="#15-MySQL索引类型" class="headerlink" title="15.MySQL索引类型"></a>15.MySQL索引类型</h3><pre><code>    1.普通索引        是最基本的索引，它没有任何限制。仅加速查询    2.唯一索引        索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。加速查询 + 列值唯一（可以有null）    3.主键索引         是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引。加速查询 + 列值唯一（不可以有null）+ 表中只有一个。    4.组合索引          指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合，多列值组成一个索引，专门用于组合搜索，其效率大于索引合并    5.全文索引          对文本的内容进行分词，进行搜索，</code></pre><h3 id="16-MySQL回表"><a href="#16-MySQL回表" class="headerlink" title="16.MySQL回表"></a>16.MySQL回表</h3><pre><code>指的是在进行索引查询时，首先通过索引定位到对应页，然后再根据行的物理地址找到所需的数据行。换句话说，回表是指根据索引查询到的主键值再去访问主键索引，从而获取完整的数据记录。</code></pre><h3 id="17-sql执行过程"><a href="#17-sql执行过程" class="headerlink" title="17.sql执行过程"></a>17.sql执行过程</h3><p><img src="/image/sql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B.png" alt="效果图预览"><br>    undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。<br>    redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复；<br>    binlog （归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制；</p><h3 id="18-mysql中关键字执行顺序"><a href="#18-mysql中关键字执行顺序" class="headerlink" title="18.mysql中关键字执行顺序"></a>18.mysql中关键字执行顺序</h3><pre><code>MySQL的SQL查询语句的关键词执行顺序大致如下：    (SELECT DISTINCT ...)    FROM ...    JOIN ...    ON ...    WHERE ...    GROUP BY ...    HAVING ...    ORDER BY ...    LIMIT ...    具体的执行流程如下：    FROM：确定数据来源，将数据载入内存。    ON：执行JOIN条件，基于JOIN语句来关联两个表。    JOIN：如果有JOIN语句，将关联的表进行合并。    WHERE：过滤记录，删除不需要的数据。    GROUP BY：按指定的列分组数据。    HAVING：过滤分组，删除不需要的分组。    SELECT：选取特定的列。    DISTINCT：去除重复数据。    ORDER BY：按指定列排序最终结果。    LIMIT：限制输出的数量。</code></pre>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rabbitMq</title>
      <link href="/2019/12/21/rabbitMq/"/>
      <url>/2019/12/21/rabbitMq/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>消息中间件</p><h3 id="1、六种工作模式"><a href="#1、六种工作模式" class="headerlink" title="1、六种工作模式"></a>1、六种工作模式</h3><pre><code> 简单模式：一个生产者，一个消费者        1.消息产生着§将消息放入队列      2.消息的消费者(consumer) 监听(while) 消息队列,如果队列中有消息,就消费掉,消息被拿走后,自动从队列中删除(隐患 消息可能没有被消费者正确处理,已经从队列中消失了,造成消息的丢失)应用场景:聊天(中间有一个过度的服务器;p端,c端) work模式：一个生产者，多个消费者，每个消费者获取到的消息唯一。     1.消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2,同时监听同一个队列,消息被消费?C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患,高并发情况下,默认会产生某2.一个消息被多个消费者共同使用,可以设置一个开关(syncronize,与同步锁的性能不一样) 保证一条消息只能被一个消费者使用)     应用场景:红包;大项目中的资源调度(任务分配系统不需知道哪一个任务执行系统在空闲,直接将任务扔到消息队列中,空闲的系统自动争抢) 订阅模式：一个生产者发送的消息会被多个消费者获取。     1.X代表交换机rabbitMQ内部组件,erlang 消息产生者是代码完成,代码的执行效率不高,消息产生者将消息放入交换机,交换机发布订阅把消息发送到所有消息队列中,对应消息队列的消费者拿到消息进行消费    2.相关场景:邮件群发,群聊天,广播(广告) 路由模式：发送消息到交换机并且要指定路由key ，消费者将队列绑定到交换机时需要指定路由key    1.消息生产者将消息发送给交换机按照路由判断,路由是字符串(info) 当前产生的消息携带路由字符(对象的方法),交换机根据路由的key,只能匹配上路由key对应的消息队列,对应的消费者才能消费消息;    2.根据业务功能定义路由字符串    3.从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中业务场景:error 通知;EXCEPTION;错误通知的功能;传统意义的错误通知;客户通知;利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可以自定义消费者,实时接收错误; topic模式：将路由键和某模式进行匹配，此时队列需要绑定在一个模式上，“#”匹配一个词或多个词，“*”只匹配一个词。    1.星号井号代表通配符    2.星号代表多个单词,井号代表一个单词    3.路由功能添加模糊匹配    4.消息产生者产生消息,把消息交给交换机    5.交换机根据key的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消费</code></pre><h3 id="2、六种工作模式消息基于什么传输"><a href="#2、六种工作模式消息基于什么传输" class="headerlink" title="2、六种工作模式消息基于什么传输"></a>2、六种工作模式消息基于什么传输</h3><pre><code>  RabbitMQ使用信道的方式来传输数据。信道是建立在真实的TCP连接内的虚拟连接，且每条TCP连接上的信道数量没有限制。  channel 频道，exchange 交换机和 queue队列</code></pre><h3 id="3、消息怎么路由"><a href="#3、消息怎么路由" class="headerlink" title="3、消息怎么路由"></a>3、消息怎么路由</h3><pre><code> 消息路由必须有三部分：交换器、路由、绑定。生产者把消息发布到交换器上；绑定决定了消息如何从路由器路由到特定的队列；消息最终到达队列，并被消费者接收。 常用的交换器主要分为一下三种：    direct：如果路由键完全匹配，消息就被投递到相应的队列    fanout：如果交换器收到消息，将会广播到所有绑定的队列上    topic：可以使来自不同源头的消息能够到达同一个队列。 使用topic交换器时，可以使用通配符，比如：“*” 匹配特定位置的任意文本， “.” 把路由键分为了几部分，“#” 匹配所有规则等。特别注意：发往topic交换器的消息不能随意的设置选择键（routing_key），必须是由&quot;.&quot;隔开的一系列的标识符组成。</code></pre><h3 id="4、如何确保消息正确地发送至RabbitMQ"><a href="#4、如何确保消息正确地发送至RabbitMQ" class="headerlink" title="4、如何确保消息正确地发送至RabbitMQ"></a>4、如何确保消息正确地发送至RabbitMQ</h3><pre><code> RabbitMQ使用发送方确认模式，确保消息正确地发送到RabbitMQ。发送方确认模式：将信道设置成confirm模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的ID。一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一ID）。如果RabbitMQ发生内部错误从而导致消息丢失，会发送一条nack（not acknowledged，未确认）消息。发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。</code></pre><h3 id="5、如何解决丢数据的问题"><a href="#5、如何解决丢数据的问题" class="headerlink" title="5、如何解决丢数据的问题"></a>5、如何解决丢数据的问题</h3><pre><code> 从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。 transaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。 生产上用confirm模式的居多。一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</code></pre>]]></content>
      
      
      <categories>
          
          <category> rabbitMq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rabbitMq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper</title>
      <link href="/2019/09/14/Zookeeper/"/>
      <url>/2019/09/14/Zookeeper/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>Zookeeper</p><h3 id="1、Zookeeper介绍"><a href="#1、Zookeeper介绍" class="headerlink" title="1、Zookeeper介绍"></a>1、Zookeeper介绍</h3><pre><code>Zookeeper是一个分布式协调服务，用于维护配置信息、命名、提供分布式同步等。</code></pre><h3 id="2、zookeeper的特性"><a href="#2、zookeeper的特性" class="headerlink" title="2、zookeeper的特性"></a>2、zookeeper的特性</h3><pre><code>顺序一致性：数据按照顺序分批入库原子性：集体更新成功或失败，没有部分结果单一视图：客户端连接集群中的任一zk服务节点，它看到的数据都是相同的。可靠性：每次对zk的操作状态都会保存在服务端实时性：客户端可以读取到zk服务端的最新数据</code></pre><h3 id="3-zookeeper的安装"><a href="#3-zookeeper的安装" class="headerlink" title="3.zookeeper的安装"></a>3.zookeeper的安装</h3><pre><code>下载地址：https://zookeeper.apache.org/releases.html注意：需要JDK1.8_u211 以上本版将下载的 zookeeper 安装包上传到 linux 环境的 /usr/local 目录，进行tar -zxvf 解压缩配置 zookeeper 环境变量     vim /etc/profile    export ZOOKEEPER_HOME=/usr/local/zookeeper-3.8.0    export PATH=$PATH:$ZOOKEEPER_HOME/bin:$JAVA_HOME/bin    source /etc/profile</code></pre><h3 id="4-zookeeper的目录结构介绍"><a href="#4-zookeeper的目录结构介绍" class="headerlink" title="4.zookeeper的目录结构介绍"></a>4.zookeeper的目录结构介绍</h3><pre><code>bin：zookeeper的操作命令目录conf：存放配置文件，其中我们需要修改zoo_sample.cfg文件docs：帮助文档目录lib：依赖jar包目录zookeeper配置文件zoo_sample.cfg  配置时请 copy 重命名为 zoo.cfg 文件    # 每一次滴答的毫秒数，滴答：zookeeper基本时间单元    tickTime=2000    # 初始同步阶段可以执行的滴答数，用于集群，配置主节点等待从节点启动并完成数据同步的时间，以 tickTime 的倍数来表示，默认是10 那么就是 10*tickTime    initLimit=10    # 在发送请求和获得确认之间可以经过的滴答数，用于集群，配置 主节点 与 从节点 之间心跳检测的最大时间长度，默认值是 5，也就是 5*tickTime    syncLimit=5    # zookeeper服务存储快照目录，必须配置，不能配置在/tmp目录下，该目录下的文件会被自动删除    dataDir=/usr/local/zookeeper-3.8.0/dataDir    # 日志目录，如果不配置会共用dataDir目录    dataLogDir=/usr/local/zookeeper-3.8.0/dataLogDir    # 客户端连接的端口，服务器对外暴露的端口，默认 2181    clientPort=2181</code></pre><h3 id="5-zookeeper启动"><a href="#5-zookeeper启动" class="headerlink" title="5.zookeeper启动"></a>5.zookeeper启动</h3><pre><code>进入 zk  的 bin 目录下，使用 ./zkServer.sh start 启动# 启动 zk，其他参数有 {start|start-foreground|stop|version|restart|status|print-cmd}./zkServer.sh start</code></pre><h3 id="6-zookeeper命令"><a href="#6-zookeeper命令" class="headerlink" title="6.zookeeper命令"></a>6.zookeeper命令</h3><p>   注意：zk的命令工具，在 zookeeper/bin 目录下<br>   启动 zk 服务端<br>    ./zkServer.sh start    # start：启动，stop：关闭，restart：重启，status：查看zk状态</p><p>   客户端连接服务端<br>    ./zkCli.sh             # 连接到 localhost:2181 服务端<br>    ./zkCli.sh -server 192.168.189.77:2181        # 连接到远程 服务端，指定ip:端口<br>   ls 命令<br>    作用和 linux 的 ls 命令相似，用于查看指定目录下有哪些节点</p>]]></content>
      
      
      <categories>
          
          <category> Zookeeper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Activiti</title>
      <link href="/2019/06/21/Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/"/>
      <url>/2019/06/21/Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>Activiti工作流</p><h3 id="1、Activiti工作流表"><a href="#1、Activiti工作流表" class="headerlink" title="1、Activiti工作流表"></a>1、Activiti工作流表</h3><pre><code>      ACT_RE_*: &#39;RE&#39;表示repository。 这个前缀的表包含了流程定义和流程静态资源 （图片，规则，等等）。      ACT_RU_*: &#39;RU&#39;表示runtime。 这些运行时的表，包含流程实例，任务，变量，异步任务，等运行中的数据。 Activiti只在流程实例执行过程中保存这些数据， 在流程结束时就会删除这些记录。 这 样运行时表可以一直很小速度很快。      ACT_ID_*: &#39;ID&#39;表示identity。 这些表包含身份信息，比如用户，组等等。      ACT_HI_*: &#39;HI&#39;表示history。 这些表包含历史数据，比如历史流程实例， 变量，任务等等。      ACT_GE_*: 通用数据， 用于不同场景下，如存放资源文件。</code></pre><h3 id="2、Activiti核心"><a href="#2、Activiti核心" class="headerlink" title="2、Activiti核心"></a>2、Activiti核心</h3><pre><code>     ProcessEngine对象，这是Activiti工作的核心。负责生成流程运行时的各种实例及数据、监控和管理流程的运行。     repositoryService：管理流程定义     runtimeService： 执行管理，包括启动、推进、删除流程实例等操作     taskService：    任务管理     HistoryService： 历史管理(执行完的数据的管理)     identityService：单位岗位管理</code></pre>]]></content>
      
      
      <categories>
          
          <category> Activiti </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工作流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM</title>
      <link href="/2019/06/15/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
      <url>/2019/06/15/JVM%E8%99%9A%E6%8B%9F%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>  JVM虚拟机.</p><a id="more"></a><h3 id="一：JVM图例"><a href="#一：JVM图例" class="headerlink" title="一：JVM图例"></a>一：JVM图例</h3><p><img src="/image/JVM2.png" alt="效果图预览"></p><pre><code>  1.程序计数器:    内存空间小，线程私有。字节码解释器工作是就是通过改变这个计数器的值来选取下一条需要执行指令的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖计数器完成。  2.Java 虚拟机栈     线程私有，生命周期和线程一致。描述的是 Java 方法执行的内存模型：每个方法在执行时都会床创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行结束，就对应着一个栈帧从虚拟机栈中入栈到出栈的过程     局部变量表：存放了编译期可知的各种基本类型(boolean、byte、char、short、int、float、long、double)、对象引用(reference 类型)和 returnAddress 类型(指向了一条字节码指令的地址)     StackOverflowError：线程请求的栈深度大于虚拟机所允许的深度。     OutOfMemoryError：如果虚拟机栈可以动态扩展，而扩展时无法申请到足够的内存。  3.本地方法栈     区别于 Java 虚拟机栈的是，Java 虚拟机栈为虚拟机执行 Java 方法(也就是字节码)服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。也会有 StackOverflowError 和 OutOfMemoryError 异常。  4.Java 堆     对于绝大多数应用来说，这块区域是 JVM 所管理的内存中最大的一块。线程共享，主要是存放对象实例和数组。内部会划分出多个线程私有的分配缓冲区。可以位于物理上不连续的空间，但是逻辑上要连续。如果堆中没有内存完成实例分配，并且堆也无法再扩展时，抛出该异常  5.方法区     属于共享内存区域，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。  6.运行时常量池    属于方法区一部分，用于存放编译期生成的各种字面量和符号引用。编译器和运行期(String 的 intern() )都可以将常量放入池中。内存有限，无法申请时抛出 OutOfMemoryError。  7.直接内存    非虚拟机运行时数据区的部分</code></pre><h3 id="二：-多线程并发编程如何正确的执行程序"><a href="#二：-多线程并发编程如何正确的执行程序" class="headerlink" title="二： 多线程并发编程如何正确的执行程序"></a>二： 多线程并发编程如何正确的执行程序</h3><pre><code>  原子性：执行过程要么成功要么失败，比如经典的银行转账问题。  可见性：多线程并发时，一个线程修改了工作内存中的值（主存中的值），会立刻改变主存相应地址的值，其它线程工作内存的值无效，重新获取主存的值。  有序性：程序执行的顺序，单个线程中没有依赖的代码，cpu会进行指令重排，使代码执行顺序调换，但是不影响最终执行的结果（单线程没有任何问题，多线程就会出现问题）</code></pre><h3 id="三：volatile关键字"><a href="#三：volatile关键字" class="headerlink" title="三：volatile关键字"></a>三：volatile关键字</h3><pre><code>  volatile能保证可见性，volatile能禁止指令重排序（所以volatile能在一定程度上保证有序性），但是这里只能保证volatile所修饰的变量之前的程序不会在该变量之后执行，该变量之后的代码不会在变量之前执行。</code></pre><h3 id="四：引用"><a href="#四：引用" class="headerlink" title="四：引用"></a>四：引用</h3><pre><code>  强引用StrongReference）：强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。如下：     Object o=new Object();   //  强引用     当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。  弱引用（WeakReference）：弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。     String str=new String(&quot;abc&quot;);     WeakReference&lt;String&gt; abcWeakRef = new WeakReference&lt;String&gt;(str);  软引用（SoftReference）：如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。     String str=new String(&quot;abc&quot;); // 强引用     SoftReference&lt;String&gt; softRef=new SoftReference&lt;String&gt;(str);       虚引用（PhantomReference）：虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之 关联的引用队列中。  java4种引用的级别由高到低依次为：   强引用 &gt; 软引用 &gt; 弱引用 &gt; 虚引用  引用类型    被垃圾回收时间     用途                 生存时间   强引用    从来不会         对象的一般状态    JVM停止运行时终止   软引用    在内存不足时    对象缓存          内存不足时终止   弱引用    在垃圾回收时    对象缓存          gc运行后终止   虚引用    Unknown         Unknown        Unknown</code></pre><h3 id="五：JVM垃圾收集算法之标记算法"><a href="#五：JVM垃圾收集算法之标记算法" class="headerlink" title="五：JVM垃圾收集算法之标记算法"></a>五：JVM垃圾收集算法之标记算法</h3><pre><code>   引用计数法非常容易理解，jvm为每一个对象设立一个引用计数器，当该对象被引用时，计数器就加一，引用取消时则减一。   当jvm开始gc时，jvm判断该对象的引用计数器是否为0，若为0则标记为可清除对象。   引用计数器有个致命的缺点是无法解决循环依赖问题，这也导致这个算法被弃用。   根搜索算法       根搜索算法是目前大部分JVM所使用的标记算法。       根搜索算法会以根对象集合中的根对象出发，进行自上往下的搜索，与根对象直接连接或间接连接的对象都可以被搜索。       当JVM无法到达某个对象时，它会被标记为可清除对象。  根对象集合指的是：     JAVA栈中的对象引用     本地方法栈的对象引用     运行时常量池中的对象引用     方法区中的类静态属性的对象引用     类对应的唯一数据类型的Class对象（这句话有点抽象，实际上每个类都有一个Class对象用于表示这个类在运行时被JVM加载的相关信息，如类名、方法、属性等）                 可以使用ClassName.class、实例化对象.class、Class.forName()，获取该类的Class对象  STW，是在执行垃圾收集算法时，Java应用程序的其他所有线程都被挂起（除了垃圾收集帮助器之外）。Java中一种全局暂停现象，全局停顿，所有Java代码停止，native代码可以执行，但不能与JVM交互；这些现象多半是由于gc引起。</code></pre><h3 id="六：JVM垃圾回收"><a href="#六：JVM垃圾回收" class="headerlink" title="六：JVM垃圾回收"></a>六：JVM垃圾回收</h3><pre><code>  对新生代的对象的收集称为minor GC；  对老年代的对象的收集称为full GC;  程序中主动调用System.gc()强制执行的GC为full GC；  强引用：默认情况下，对象采用的均为强引用；  软引用：适用于缓存场景（只有在内存不够用的情况下才会被回收）  弱引用：在GC时一定会被GC回收  虚引用：用于判断对象是否被GC</code></pre><h3 id="七、垃圾收集器"><a href="#七、垃圾收集器" class="headerlink" title="七、垃圾收集器"></a>七、垃圾收集器</h3><pre><code>  Serial收集器：是最基本、历史最久的收集器，单线程，并且在收集是必须暂停所有的工作线程；  ParNew收集器：是Serial收集器的多线程版本；  Parallel Scavenge收集器：新生代收集器，并行的多线程收集器。它的目标是达到一个可控的吞吐量，这样可以高效率的利用CPU时间，尽快完成程序的运算任务，适合在后台运算；  Serial Old收集器：Serial 收集器的老年代版本，单线程，主要是标记—整理算法来收集垃圾；  Parallel Old收集器：Parallel Scavenge的老年代版本，多线程，主要是标记—整理算法来收集垃圾；Parallel Old 和 Serial Old 不能同时搭配使用，后者性能较差发挥不出前者的作用；  CMS收集器：收集器是一种以获取最短回收停顿时间为目标的收集器；基于标记清除算法，并发收集、低停顿、运作过程复杂（初始标记、并发标记、重新标记、并发清除）。CMS收集器有3个缺点：1。对CPU资源非常敏感（占用资源）；2。无法处理浮动垃圾（在并发清除时，用户线程新产生的垃圾叫浮动垃圾），可能出现“Concurrent Mode Failure”失败；3。产生大量内存碎片　　  G1收集器：  特点：     分代收集，G1可以不需要其他GC收集器的配合就能独立管理整个堆，采用不同的方式处理新生对象和已经存活一段时间的对象；     空间整合：采用标记整理算法，局部采用复制算法（Region之间），不会有内存碎片，不会因为大对象找不到足够的连续空间而提前触发GC；     可预测的停顿：能够让使用者明确指定一个时间片段内，消耗在垃圾收集上的时间不超过时间范围</code></pre><h3 id="八、哪些对象可以作为GC-ROOT"><a href="#八、哪些对象可以作为GC-ROOT" class="headerlink" title="八、哪些对象可以作为GC ROOT"></a>八、哪些对象可以作为GC ROOT</h3><pre><code>  栈  本地方法栈（Native方法）  方法区：常量、静态变量</code></pre><h3 id="九、GC"><a href="#九、GC" class="headerlink" title="九、GC"></a>九、GC</h3><pre><code>  gc是通过垃圾收集器来实现的，现代垃圾收集器大部分都是基于分代收集理论设计的，也就是将对象划分为新生代，老年代。其中新生代分为Eden区和两块Survivor区，比例为8：1：1。</code></pre><h3 id="十、对象如何直接到老年代"><a href="#十、对象如何直接到老年代" class="headerlink" title="十、对象如何直接到老年代"></a>十、对象如何直接到老年代</h3><pre><code>  对象太大，Eden放不下  存放存活对象的Survivor区太小，不足以存下存活对象  经历超过默认15次gc或者设定的  Survivor空间中相同年龄的所有对象总和大于等于Survivor空间的一半，那么这些对象就会直接进入到老年代中</code></pre><h3 id="十一、java内存泄漏的根本原因是"><a href="#十一、java内存泄漏的根本原因是" class="headerlink" title="十一、java内存泄漏的根本原因是"></a>十一、java内存泄漏的根本原因是</h3><pre><code>  内存对象明明已经不需要的时候，还仍然保留着这块内存和它的访问方式（引用）。</code></pre><h3 id="十二、内存泄漏在常见情况"><a href="#十二、内存泄漏在常见情况" class="headerlink" title="十二、内存泄漏在常见情况"></a>十二、内存泄漏在常见情况</h3><pre><code>  1. 静态集合类泄漏     静态集合类像HashMap，Vector等的使用最容易出现内存泄漏，静态变量的声明周期与应用程序一直，所有的对象Object也不能内释放，因为被其他对象引用着。  2. 单例造成的泄漏     单例对象在初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有外部的引用，那么这个对象将不能被JVM正常回收，导致内存泄漏。  3.数据库连接     网络连接，IO连接等没有显式调用close()关闭，会导致内存泄漏。  4.监听器的使用     在释放对象的同时，没有删除相应监听器，也会造成内存泄漏。</code></pre><h3 id="十三、如何避免内存泄露呢"><a href="#十三、如何避免内存泄露呢" class="headerlink" title="十三、如何避免内存泄露呢"></a>十三、如何避免内存泄露呢</h3><pre><code>  要避免内存泄露，可以考虑以下几个方法：     1、及时关闭资源：对于使用完的资源，如数据库连接、网络连接、文件流等，应该及时关闭，以确保资源能够及时释放，避免内存泄露。     2、注意对象的引用关系：避免创建过多的对象引用，或者不必要的对象引用。例如，在对象使用完毕后，及时将引用置为null，以便垃圾回收器能够回收该对象占用的内存。     3、使用缓存技术：对于经常使用的对象，可以使用缓存技术来缓存它们，以避免频繁地创建和销毁对象，从而减少内存的使用。     4、避免使用静态变量：静态变量在程序整个运行期间都存在，不会被垃圾回收器回收。因此，应该避免过多地使用静态变量，尤其是大对象或集合类对象。     5、优化数据结构和算法：优化数据结构和算法也可以有效地减少内存的使用。例如，使用更加紧凑的数据结构，或者优化算法以减少不必要的内存占用。     6、使用垃圾回收器的性能分析工具：可以使用垃圾回收器的性能分析工具来分析程序的内存使用情况，找出可能的内存泄露问题。例如，可以使用Java的内存分析工具来分析程序的内存使用情况，找出哪些对象占用了过多的内存，以及哪些对象没有被及时回收。     7、弱引用、软引用和虚引用的适当使用：在Java中，除了强引用之外，还有弱引用、软引用和虚引用。它们可以在一定程度上帮助减少内存泄露的风险。例如，弱引用不阻止其引用的对象被垃圾回收，因此在某些场景下（如缓存）非常有用。     8、要避免这种情况下的内存泄露，要求我们以C/C++ 的内存管理思维来管理自己分配的内存：        第一，是在声明对象引用之前，明确内存对象的有效作用域。在一个函数内有效的内存对象，应该声明为 local 变量，与类实例生命周期相同的要声明为实例变量……以此类推。        第二，在内存对象不再需要时，记得手动将其引用置空。</code></pre><h3 id="十四、JVM-中的三色标记法"><a href="#十四、JVM-中的三色标记法" class="headerlink" title="十四、JVM 中的三色标记法"></a>十四、JVM 中的三色标记法</h3><pre><code>     三色标记（Tri-color Marking）作为工具来辅助推导，把遍历对象图过程中遇到的对象，按照“是否访问过”这个条件标记成以下三种颜色：        白色：表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达。        黑色：表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色的对象代 表已经扫描过，它是安全存活的，如果有其他对象引用指向了黑色对象，无须重新扫描一遍。黑色对 象不可能直接（不经过灰色对象）指向某个白色对象。        灰色：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过。</code></pre><h3 id="十五、内存溢出和内存泄漏"><a href="#十五、内存溢出和内存泄漏" class="headerlink" title="十五、内存溢出和内存泄漏"></a>十五、内存溢出和内存泄漏</h3><pre><code>     内存溢出(out of memory)：简单地说内存溢出就是指程序运行过程中申请的内存大于系统能够提供的内存，导致无法申请到足够的内存，于是就发生了内存溢出。     内存泄漏(memory leak)：内存泄漏指程序运行过程中分配内存给临时变量，用完之后却没有被GC回收，始终占用着内存，既不能被使用也不能分配给其他程序，于是就发生了内存泄漏。     内存溢出的解决方案           第一步，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)           第二步，检查错误日志，查看“OutOfMemory”错误前是否有其 它异常或错误。           第三步，对代码进行走查和分析，找出可能发生内存溢出的位置。   内存泄漏           因为内存泄漏是在堆内存中，所以对我们来说并不是可见的。通常我们可以借助MAT、LeakCanary等工具来检测应用程序是否存在内存泄漏。              1、MAT是一款强大的内存分析工具，功能繁多而复杂。              2、LeakCanary则是由Square开源的一款轻量级的第三方内存泄漏检测工具，当检测到程序中产生内存泄漏时，它将以最直观的方式告诉我们哪里产生了内存泄漏和导致谁泄漏了而不能被回收。</code></pre><h3 id="十六、Java-对象模型"><a href="#十六、Java-对象模型" class="headerlink" title="十六、Java 对象模型"></a>十六、Java 对象模型</h3><p><img src="/image/Java%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B.png" alt="效果图预览"><br>   在 Hotspot VM 中，对象在内存中的存储布局分为 3 块区域：<br>      对象头（Header）<br>      实例数据（Instance Data）<br>      对齐填充（Padding）</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring</title>
      <link href="/2019/03/16/spring/"/>
      <url>/2019/03/16/spring/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>  <a href="https://spring.io/" target="_blank" rel="noopener">https://spring.io/</a></p><a id="more"></a><h3 id="一：Spring-包括哪些东西"><a href="#一：Spring-包括哪些东西" class="headerlink" title="一：Spring 包括哪些东西"></a>一：Spring 包括哪些东西</h3><pre><code>核心技术 IoC 和 AOP数据访问 （持久层解决方案）Web层解决方案 SpringMVC集成 （整合其他开源框架）</code></pre><h3 id="二：IoC控制反转和DI依赖注入"><a href="#二：IoC控制反转和DI依赖注入" class="headerlink" title="二：IoC控制反转和DI依赖注入"></a>二：IoC控制反转和DI依赖注入</h3><pre><code> IoC： IoC Inverse of Control 反转控制的概念，就是将原本在程序中手动创建对象的控制权，交由Spring框架管理，简单说，就是创建对象控制权被反转到了Spring框架。 DI：Dependency Injection 依赖注入，在Spring框架负责创建Bean对象时，动态的将依赖对象注入到Bean组件</code></pre><h3 id="三：-IoC-和-DI的区别"><a href="#三：-IoC-和-DI的区别" class="headerlink" title="三： IoC 和 DI的区别"></a>三： IoC 和 DI的区别</h3><pre><code>IoC 控制反转，指将对象的创建权，反转到Spring容器 。DI 依赖注入，指Spring创建对象的过程中，将对象依赖属性通过配置进行注入</code></pre><h3 id="四：-Spring读取配置文件中的bean"><a href="#四：-Spring读取配置文件中的bean" class="headerlink" title="四： Spring读取配置文件中的bean"></a>四： Spring读取配置文件中的bean</h3><pre><code> 加载classpath （src）：        new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); 加载磁盘路径：        new FileSystemXmlApplicationContext(&quot;applicationContext.xml&quot;); 创建Spring 核心工厂对象        通过工厂的getBean 获得配置实例对象 (IService) applicationContext.getBean(&quot;service&quot;);</code></pre><h3 id="五：Spring-工厂接口"><a href="#五：Spring-工厂接口" class="headerlink" title="五：Spring 工厂接口"></a>五：Spring 工厂接口</h3><pre><code>  ApplicationContext 接口是继承 BeanFactory 接口 ，Spring 核心工厂是BeanFactory ,BeanFactory 采取延迟加载，第一次getBean时才会初始化Bean ,   ApplicationContext 是会在加载配置文件时 初始化Bean，ApplicationContext是对BeanFactory扩展。  Spring 工厂接口（开发中基本都在使用ApplicationContext, web项目使用WebApplicationContext ，很少用到BeanFactory）      BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;applicationContext.xml&quot;));      IService service = (IService) beanFactory.getBean(&quot;service&quot;);      service.sayHello();</code></pre><h3 id="六：-IoC容器装配Bean"><a href="#六：-IoC容器装配Bean" class="headerlink" title="六： IoC容器装配Bean"></a>六： IoC容器装配Bean</h3><pre><code>   6.1xml配置方式           使用类构造器实例化(默认无参数)              &lt;bean id=&quot;bean1&quot; class=&quot;cn.hb.spring.b_instance.Bean1&quot;&gt;&lt;/bean&gt;           使用静态工厂方法实例化(简单工厂模式)              &lt;bean id=&quot;bean2&quot; class=&quot;cn.hb.spring.b_instance.Bean2Factory&quot; factorymethod=&quot;getBean2&quot;&gt;&lt;/bean&gt;           使用实例工厂方法实例化(工厂方法模式)              &lt;bean id=&quot;bean3Factory&quot; class=&quot;cn.hb.spring.b_instance.Bean3Factory&quot;&gt;&lt;/bean&gt;                          &lt;bean id=&quot;bean3&quot; factory-bean=&quot;bean3Factory&quot; factory-method=&quot;getBean3&quot;&gt;&lt;/bean&gt;          &lt;bean&gt;元素scope属性              scope=&quot;singleton&quot; 单例 ，在Spring IoC容器中仅存在一个Bean实例 （默认的scope）。              scope=&quot;prototype&quot; 多例 ，每次从容器中调用Bean时，都返回一个新的实例，即每次调用getBean()时 ，相当于执行new XxxBean()。              scope=&quot;request&quot; 用于web开发，将Bean放入request范围 ，request.setAttribute(&quot;xxx&quot;) ， 在同一个request 获得同一个Bean。              scope=&quot;session&quot; 用于web开发，将Bean 放入Session范围，在同一个Session 获得同一个Bean。              scope=&quot;globalSession&quot; 一般用于Porlet应用环境 , 分布式系统存在全局session概念 ，如果不是porlet环境，globalSession 等同于Session。  6.2注解方式           编写Class，在声明上 添加 @Component              @Component(&quot;helloService&quot;)                public class HelloService {                }           编写applicationContext.xml               需要引入 context 名称空间               &lt;context:component-scan base-package=&quot;cn.hb.spring.a_beandefinition&quot;&gt;&lt;/context:componentscan&gt;           spring2.5 引入@Component 等效三个衍生注解               @Repository 用于对DAO实现类进行标注（持久层）               @Service 用于对Service实现类进行标注（业务层）               @Controller 用于对Controller实现类进行标注(表现层) 6.3Bean的生命周期          在配置 &lt;bean&gt; 元素，通过 init-method 指定Bean的初始化方法，通过 destroy-method 指定Bean销毁方法。          destroy-method 只对 scope=&quot;singleton&quot; 有效          销毁方法，必须关闭ApplicationContext对象，才会被调用               ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);               applicationContext.close();                销毁方法destroy-method，必须关闭ApplicationContext对象，才会被调用。          Bean的完整生命周期              1、instantiate bean对象实例化              2、populate properties 封装属性              3、如果Bean实现BeanNameAware 执行 setBeanName              4、如果Bean实现BeanFactoryAware 或者 ApplicationContextAware 设置工厂 setBeanFactory 或者上下文对象 setApplicationContext              5、如果存在类实现 BeanPostProcessor（后处理Bean） ，执行postProcessBeforeInitialization              6、如果Bean实现InitializingBean 执行 afterPropertiesSet              7、调用&lt;bean init-method=&quot;init&quot;&gt; 指定初始化方法 init              8、如果存在类实现 BeanPostProcessor（处理Bean） ，执行postProcessAfterInitialization              9、执行业务处理              10、如果Bean实现 DisposableBean 执行 destroy              11、调用&lt;bean destroy-method=&quot;&quot;&gt; 指定销毁方法 customerDestroy</code></pre><h3 id="七：AOP-面向切面编程"><a href="#七：AOP-面向切面编程" class="headerlink" title="七：AOP 面向切面编程"></a>七：AOP 面向切面编程</h3><pre><code>  Joinpoint(连接点):所谓连接点是指那些被拦截到的点。在spring中,这些点指的是方法,因为spring只支持方法类型的连接点.  Pointcut(切入点):所谓切入点是指我们要对哪些Joinpoint进行拦截的定义.  Advice(通知/增强):所谓通知是指拦截到Joinpoint之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能)。  Introduction(引介):引介是一种特殊的通知在不修改类代码的前提下, Introduction可以在运行期为类动态地添加一些方法或Field.  Target(目标对象):代理的目标对象。  Weaving(织入):是指把增强应用到目标对象来创建新的代理对象的过程.     spring采用动态代理织入，而AspectJ采用编译期织入和类装在期织入.  Proxy（代理）:一个类被AOP织入增强后，就产生一个结果代理类.  Aspect(切面): 是切入点和通知（引介）的结合.   AOP 的底层实现:        JDK动态代理 和 CGlib的动态代理.   JDK动态代理:         针对内存中Class对象，使用类加载器 动态为目标对象实现接口的创建代理类.         代理类 是动态创建的， 代理类 和 被代理对象 实现相同接口.         被代理对象 必须要实现 接口 （JDK代理 只能针对接口 进行代理 ）.</code></pre><h3 id="八：spring中循环依赖问题"><a href="#八：spring中循环依赖问题" class="headerlink" title="八：spring中循环依赖问题"></a>八：spring中循环依赖问题</h3><pre><code>  private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap(256);  private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap(16);  private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap(16);  private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap(16));  singletonsCurrentlyInCreation：保存对象的BeanName，在创建对象之前就会把对象的beanName保存起来。  singletonFactories：保存对象的BeanName和创建bean的工厂AbstractAutowireCapableBeanFactory(ObjectFactory)，（对象的构造函数是在这一步完成的）  earlySingletonObjects：保存对象BeanName和对象的早期实例（ObjectFactory#getObject得到的对象）（此时对象还没注入属性），此时可以作为对象填充依赖。  singletonObjects：保存BeanName和bean的实例（此时对象已经完成了属性注入）</code></pre><h3 id="九：spring对事物支持"><a href="#九：spring对事物支持" class="headerlink" title="九：spring对事物支持"></a>九：spring对事物支持</h3><pre><code>  TransactionDefinition：事务的定义信息：包含事务操作的 隔离级别，传播行为，是否超时 ，是否是只读的等信息。  PlatformTransactionManager 平台事务管理器：真正用来管理事务的接口，包含 事务的提交，回滚等信息  TransactionStatus 事务的具体运行状态：该接口提供的方法可以获取或者判断事务的相关状态。事务是否有保存点，事务是否已经完成，事务是不是一个新的事务等等。  回滚RuntimeException 和 Error类型异常  不回滚 checked exceptions  编程式事务使用TransactionTemplate或者直接使用底层的PlatformTransactionManager。</code></pre><h3 id="十：controller的三种实现方式"><a href="#十：controller的三种实现方式" class="headerlink" title="十：controller的三种实现方式"></a>十：controller的三种实现方式</h3><pre><code>    第一种：实现Controller接口        public class Contrller implements Controller{        @Override        //重写handleRequest方法        public ModelAndVIew handleRequest(HttpServletRequest request,HttpServletResponse response){        }        &lt;bean id=&quot;/hello&quot; class=&quot;Hello.java&quot;&gt;&lt;/bean&gt;        &lt;!--配置controllerbean让spring管理--&gt;    第二种：实现HttpRequestHandler接口        public class Contrller implements HttpRequestHandler{            @Override            //重写handleRequest方法            public void handleRequest(HttpServletRequest request,HttpServletResponse response){                //没有modelAndView,所以需要request转发或重定向到页面 request转发 req.getrequestDispatcher(&quot;需要跳转的页面路径&quot;).forward(req,resp)            //重定向sendRedirect            }        }        &lt;!--配置controllerbean让spring管理--&gt;    第三种：实现HttpRequestHandler接口        @Controller        //注解需要扫描需要配置spring-context context-component-scan base-package=&quot;扫描包路径&quot;        public class Contrller{        @RequestMapping(&quot;路径&quot;)            public void hello(){            }        }</code></pre><h3 id="十：事物失效"><a href="#十：事物失效" class="headerlink" title="十：事物失效"></a>十：事物失效</h3><pre><code> 1.作用于接口：不推荐这种使用方法，因为一旦标注在Interface上并且配置了Spring AOP 使用CGLib动态代理。 2.@Transactional 应用在非 public 修饰的方法上 3.同一个类中方法调用，导致@Transactional失效 4.异常被你的 catch“吃了”导致@Transactional失效 5.数据库引擎不支持事务 6.事务属性配置错误</code></pre><h3 id="十一：AOP哪些情况下不能做切面"><a href="#十一：AOP哪些情况下不能做切面" class="headerlink" title="十一：AOP哪些情况下不能做切面"></a>十一：AOP哪些情况下不能做切面</h3><pre><code> 1、AOP无法切入方法内部调用 2、AOP无法切入private</code></pre><h3 id="十二：JDK-动态代理为什么只能代理有接口的类"><a href="#十二：JDK-动态代理为什么只能代理有接口的类" class="headerlink" title="十二：JDK 动态代理为什么只能代理有接口的类"></a>十二：JDK 动态代理为什么只能代理有接口的类</h3><pre><code>动态代理实际上是程序在运行中，    根据被代理的接口来动态生成代理类的 class 文件，    并加载 class 文件运行的过程，    通过反编译被生成的 $Proxy0.class 文件发现        public final class $Proxy0 extends Proxy implements Interface {            public $Proxy0(InvocationHandler paramInvocationHandler) {                super(paramInvocationHandler);            }            // 该方法为被代理接口的业务方法，代理类都会自动生成相应的方法，里面去执行invocationHandler 的invoke方法。            public final void sayHello(String paramString) {                try {                    this.h.invoke(this, m3, new Object[] { paramString });                    return;                }                catch (Error|RuntimeException localError) {                    throw localError;                }                catch (Throwable localThrowable) {                    throw new UndeclaredThrowableException(localThrowable);                }            }        }java 是单继承    动态生成的代理类已经继承了 Proxy 类的，就不能再继承其他的类，    所以只能靠实现被代理类的接口的形式，故 JDK 的动态代理必须有接口。</code></pre><h3 id="十三：两种类型的动态代理"><a href="#十三：两种类型的动态代理" class="headerlink" title="十三：两种类型的动态代理"></a>十三：两种类型的动态代理</h3><pre><code>基于接口的动态代理：基于接口的动态代理是通过Java的java.lang.reflect.Proxy类实现的。对于被代理的类（或接口），必须实现至少一个接口。代理对象在运行时实现了这些接口，并将方法调用转发给InvocationHandler接口的实现类。InvocationHandler接口包含一个invoke()方法，当调用代理对象的方法时，实际上是调用了InvocationHandler的invoke()方法，在其中可以进行相关的增强逻辑。基于类的动态代理：基于类的动态代理是通过Java的java.lang.reflect.InvocationHandler接口和java.lang.reflect.Proxy类结合实现的。不同于基于接口的动态代理，基于类的动态代理是在运行时动态地创建目标类的子类，并将方法调用转发给InvocationHandler接口的实现类。这种代理方式允许对没有实现接口的类进行代理，但是需要注意的是，被代理的类不能是final类。</code></pre><h3 id="十四：Spring-中的-Service-有多个实现类"><a href="#十四：Spring-中的-Service-有多个实现类" class="headerlink" title="十四：Spring 中的 Service 有多个实现类"></a>十四：Spring 中的 Service 有多个实现类</h3><pre><code>方法一：     Controller中注入service的时候使用@Autowired自动注入，@Qualifier(“beanId”)来指定注入哪一个。方法二：     Controller中注入service的时候使用@Resource(type = 类名.class)来指定注入哪一个。方法三：    每个service的impl都可以指定名称（使用@Service（“名称”））    Controller中注入service的时候使用名称来指定注入哪一个（使用@Resource(name=“名称”)）</code></pre><h3 id="十五：Autowired和-Resource两个注解的区别"><a href="#十五：Autowired和-Resource两个注解的区别" class="headerlink" title="十五：Autowired和@Resource两个注解的区别"></a>十五：Autowired和@Resource两个注解的区别</h3><pre><code>1.@Autowired是Spring的注解，@Resource是J2EE的注解，这个看一下导入注解的时候这两个注解的包名就一清二楚了。2.@Autowired默认按照byType方式进行bean匹配，@Resource默认按照byName方式进行bean匹配。3.@Autowired默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，如：@Autowired(required=false)。</code></pre><h3 id="十六：请求在Spring-Web应用中的处理流程"><a href="#十六：请求在Spring-Web应用中的处理流程" class="headerlink" title="十六：请求在Spring Web应用中的处理流程"></a>十六：请求在Spring Web应用中的处理流程</h3><pre><code>    Spring MVC 中的 DispatcherServlet 充当了 Web 应用中的 Serlvet，负责将任务分配给对应的Controller，并将最终视图返回给 Web 容器。    Spring MVC的核心组件    DispatcherServlet：        DispatcherServlet 是整个流程控制的中心，由它来接收请求并调用其它组件处理用户的请求，同时还负责响应结果。DispatcherServlet的存在降低了组件之间的耦合性。    HandlerMapping：        HandlerMapping 负责根据用户请求映射获得对应的 Handler和 HandlerInterceptor。处理方法为从 URL 获得 URI，在通过 URI 从 HandlerMapping 中找到对应的 Handler 和 HandlerInterceptor，即处理器和拦截器。    HandlerAdapter：        HandlerAdapter 负责按照特定规则去执行 Handler。        如果 Handler 有对应的 HandlerAdapater，HandlerAdapater 则会在调用 Handler 之前执行 HandlerInterceptor 的 preHandler() 方法对 Handler 进行拦截。    HandlerInterceptor：        HandlerInterceptor 主要负责在执行 Handler 前对其进行拦截。HandlerInterceptor 中的 preHandler() 方法将会提取 HTTP 请求中的数据填充到处理器 Handler 的中。    Handler：        Handler 即Controller ，是处理业务代码的核心器件。这部分由程序员自行编写，一般的SSM框架中，其下层还有Service和Dao</code></pre><p>Spring MVC处理请求流程：<br><img src="/image/SpringMVC.png" alt="效果图预览"><br>    当 Web 容器中的 Host 会选择对应的 Web应用来处理请求，这里将请求交给了 Spring MVC 中的 DispatcherServlet 来进一步处理请求。</p><pre><code>    DispatcherServlet 通过解析 HTTP 请求的 URL 获得 URI，再根据该 URI 从 HandlerMapping 当中获得该请求对应的 Handler 和 HandlerInterceptor    DispatcherServlet 根据获得的 Handler 选择合适的 HandlerAdapter。如果成功获得 HandlerAdapter，HandlerAdapater 则会在调用 Handler 之前执行 HandlerInterceptor 的 preHandler() 方法对 Handler 进行拦截    Handler 即 Controller 会进行请求的处理，并向下调用 Service 和 Dao 来处理请求    Hander 处理完成请求后会返回模型数据，模型数据由 DispatcherServlet 封装后返回给Web 容器</code></pre><h3 id="十七-Spring-中的一些注解"><a href="#十七-Spring-中的一些注解" class="headerlink" title="十七 Spring 中的一些注解"></a>十七 Spring 中的一些注解</h3><pre><code>    @Resource装配顺序    　　1. 如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常    　　2. 如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常    　　3. 如果指定了type，则从上下文中找到类型匹配的唯一bean进行装配，找不到或者找到多个，都会抛出异常    　　4. 如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配；    @Component 和 @Bean 的区别        作用对象不同：@Component 注解作用于类，而 @Bean 注解作用于方法、        @Component 通常是通过路径扫描来自动侦测以及自动装配到 Spring 容器中(我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中)。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean，@Bean 告诉了 Spring 这是某个类的实例，当我们需要用它的时候还给我。        @Bean 注解比 @Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 Spring 容器时，只能通过 @Bean 来实现。    @Autowire 和 @Resource 的区别        @Autowire 和 @Resource都可以用来装配bean，都可以用于字段或setter方法。        @Autowire 默认按类型装配，默认情况下必须要求依赖对象必须存在，如果要允许 null 值，可以设置它的 required 属性为 false。        @Resource 默认按名称装配，当找不到与名称匹配的 bean 时才按照类型进行装配。名称可以通过 name 属性指定，如果没有指定 name 属性，当注解写在字段上时，默认取字段名，当注解写在 setter 方法上时，默认取属性名进行装配。</code></pre>]]></content>
      
      
      <categories>
          
          <category> spring </category>
          
          <category> 框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> 框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis</title>
      <link href="/2019/03/15/Redis/"/>
      <url>/2019/03/15/Redis/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>  Redis是一个开源的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件</p><a id="more"></a><h3 id="第一步：Redis支持的数据类型"><a href="#第一步：Redis支持的数据类型" class="headerlink" title="第一步：Redis支持的数据类型"></a>第一步：Redis支持的数据类型</h3><pre><code>  String字符串：  格式: set key value  string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。  string类型是Redis最基本的数据类型，一个键最大能存储512MB。  Hash（哈希）：  格式: hmset name  key1 value1 key2 value2  Redis hash 是一个键值(key=&gt;value)对集合。  Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。  List（列表）：  Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）  格式: lpush  name  value  在 key 对应 list 的头部添加字符串元素  格式: rpush  name  value  在 key 对应 list 的尾部添加字符串元素  格式: lrem name  index  key 对应 list 中删除 count 个和 value 相同的元素  格式: llen name    返回 key 对应 list 的长度  Set（集合）：  格式: sadd  name  value  Redis的Set是string类型的无序集合。  集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。  zset(sorted set：有序集合)：  格式: zadd  name score value  Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。  不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。  zset的成员是唯一的,但分数(score)却可以重复。</code></pre><h3 id="二：Redis分布式锁基础指令"><a href="#二：Redis分布式锁基础指令" class="headerlink" title="二：Redis分布式锁基础指令"></a>二：Redis分布式锁基础指令</h3><pre><code> SETNX key value    将key设置值为value，如果key不存在，这种情况下等同SET命令。 当key存在时，什么也不做。SETNX是”SET if Not eXists”的简写。 返回值：    1 如果key被设置了    0 如果key没有被设置 用途：可以用来枷锁。比如给商品id加锁。 GETSET  key value    自动将key对应到value并且返回原来key对应的value。如果key存在但是对应的value不是字符串，就返回错误。</code></pre><h3 id="三-redis持久化方式和原理"><a href="#三-redis持久化方式和原理" class="headerlink" title="三.redis持久化方式和原理"></a>三.redis持久化方式和原理</h3><pre><code>RDB方式原理：当redis需要做持久化时（执行SAVA或者BGSAVA命令，或者是达到配置条件时执行），redis会fork一个子进程，子进程将数据写到磁盘上一个临时RDB文件中，当子进程完成写临时文件后，将原来的RDB替换掉（默认文件名为dump.rdb）AOF方式原理：AOF就可以做到全程持久化，Redis每执行一个修改数据的命令，都会把这个命令添加到AOF文件中，当Redis重启时，将会读取AOF文件进行“重放”以恢复到 Redis关闭前的最后时刻。由于os会在内核中缓存 write做的修改，所以可能不是立即写到磁盘上。这样aof方式的持久化也还是有可能会丢失部分修改。不过我们可以通过配置文件告诉redis我们想要 通过fsync函数强制os写入到磁盘的时机。有三种方式如下（默认是：每秒fsync一次）  Redis内建支持两种持久化方案，snapshot快照和AOF 增量Log方式。快照顾名思义就是隔一段时间将完整的数据Dump下来存储在文件中。AOF增量Log则是记录对数据的修改操作（实际上记录的就是每个对数据产生修改的命令本身），两种方案可以并存，也各有优缺点，具体参见</code></pre><h3 id="四-过期数据删除策略"><a href="#四-过期数据删除策略" class="headerlink" title="四.过期数据删除策略"></a>四.过期数据删除策略</h3><pre><code>惰性删除发生在redis处理读写请求的过程，如get/set等命令。定期删除发生在redis内部定时任务执行过程中，限制占用cpu的时间。redis的定期删除是通过定时任务实现的，也就是定时任务会循环调用serverCron方法。然后定时检查过期数据的方法是databasesCron。</code></pre><p>    定期删除的一大特点就是考虑了定时删除过期数据会占用cpu时间，所以每次执行databasesCron的时候会限制cpu的占用不超过25%。</p><h3 id="五-Redis为什么这么快"><a href="#五-Redis为什么这么快" class="headerlink" title="五.Redis为什么这么快"></a>五.Redis为什么这么快</h3><pre><code> 1. 内存存储：Redis将数据存储在内存中，而不是磁盘上。由于内存的读写速度远远快于磁盘，这使得Redis能够实现非常低延迟的数据访问。 2. 单线程模型：Redis采用单线程模型来处理客户端请求。这意味着所有的请求都是按顺序依次执行的，避免了多线程之间的竞争和同步开销。虽然单线程看起来效率较低，但由于Redis主要进行内存操作，而不是计算密集型任务，因此单线程足以应对大多数场景。 3. IO多路复用模型-非阻塞I/O：Redis使用了非阻塞I/O模型来处理网络请求。它通过使用事件轮询机制（如epoll、kqueue等）来监听客户端连接和数据到达事件，并立即响应这些事件。这种方式避免了传统阻塞I/O模型中的等待时间，提高了系统的并发性能。 4. 基于异步方式持久化数据：Redis支持多种持久化方式，包括RDB（快照）和AOF（日志）。其中AOF采用了异步方式将写入操作追加到文件中，而不是每次写入都同步到磁盘上。这种异步方式可以大大提高写入性能。 5. 数据结构优化：Redis提供了丰富的数据结构（如字符串、哈希表、列表、集合等），并对每种数据结构进行了优化。例如，在哈希表中使用了散列表来实现O(1)时间复杂度的查找和插入操作，在列表中使用了双向链表来支持快速插入和删除操作等。</code></pre><h3 id="六-缓存击穿、缓存穿透、缓存雪崩"><a href="#六-缓存击穿、缓存穿透、缓存雪崩" class="headerlink" title="六.缓存击穿、缓存穿透、缓存雪崩"></a>六.缓存击穿、缓存穿透、缓存雪崩</h3><pre><code> 缓存击穿：     定义：某个热点key在某个时间点过期的时候，恰好在这个时间点对这个Key的查询请求特别多，这些请求发现缓存中没有这个key的数据，于是都去请求数据库，导致数据库压力瞬间增大。     解决方案：可以设置热点数据永不过期。  缓存穿透：     定义：用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。     解决方案：可以将空对象也缓存起来，或者采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。  缓存雪崩：     定义：由于原有缓存失效，新缓存未到时间，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。     解决方案：尽量让失效的时间点不分布在同一个时间点，避免缓存集体失效。</code></pre><h3 id="七-RDB快照和AOF日志"><a href="#七-RDB快照和AOF日志" class="headerlink" title="七.RDB快照和AOF日志"></a>七.RDB快照和AOF日志</h3><pre><code> RDB快照是一种全量持久化方式，它会周期性地将内存中的数据以二进制格式保存到磁盘上的RDB文件。RDB文件是一个经过压缩的二进制文件，包含了数据库在某个时间点的数据快照。RDB快照有助于实现紧凑的数据存储，适合用于备份和恢复。  优点：     紧凑的数据格式： RDB文件是一个二进制文件，采用了紧凑的编码格式，因此在磁盘上占用的空间相对较小。     快速恢复： 在恢复数据时，通过加载RDB文件，可以快速地将数据恢复到指定时间点的状态。     适用于备份和恢复： RDB文件适用于进行数据备份、迁移和灾难恢复，可以方便地复制到其他服务器上。  缺点：     数据丢失： 由于RDB是周期性的全量持久化，可能会导致某个时间点之后的数据丢失。     IO开销： RDB持久化时，需要将整个数据集写入磁盘，可能在大数据集上引起IO开销，影响性能。     耗时： 在生成RDB快照的过程中，如果数据集很大，可能会占用较多的CPU资源，导致短时间内的性能下降。 AOF日志是一种追加式持久化方式，它记录了每个写操作命令，以追加的方式将命令写入AOF文件。通过重新执行AOF文件中的命令，可以重建出数据在内存中的状态。AOF日志提供了更精确的持久化，适用于需要更高数据安全性和实时性的场景。优点：  AOF日志可以实现更精确的数据持久化，每个写操作都会被记录。  在AOF文件中，数据可以更好地恢复，因为它保存了所有的写操作历史。  AOF日志适用于需要实时恢复数据的场景，如秒级数据恢复要求。缺点：  AOF日志相对于RDB快照来说，可能会占用更多的磁盘空间，因为它是记录每个写操作的文本文件。  AOF日志在恢复大数据集时可能会比RDB快照慢，因为需要逐条执行写操作。 生成RDB文件方式：     手动触发 SAVE命令，     后台触发 GSAVE命令，     自动触发 配置文件（redis.conf）中可以设置save参数 AOF日志三种写回策略：     (1). always（始终同步）、     (2). everysec（每秒同步）     (3). no（不同步）</code></pre><h3 id="八-跳跃表"><a href="#八-跳跃表" class="headerlink" title="八.跳跃表"></a>八.跳跃表</h3><pre><code>Redis 有一个叫做 有序列表 zset 的数据结构，它类似于 Java 中的 SortedSet 和 HashMap 的结合体，一方面它是一个 set 保证了内部 value 的唯一性，另一方面又可以给每个 value 赋予一个排序的权重值 score，来达到 排序 的目的。跳跃表（Skip List）是一种基于链表的数据结构，它可以实现诸如有序集合（Sorted Set）等数据结构，能够提供平均 O(log n) 的查找效率。Redis中就使用跳跃表来实现有序集合。</code></pre><p>   跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。和链表、字典等数据结构被广泛地应用在 Redis 内部不同，Redis 只在两个地方用到了跳跃表，一个是实现有序集合健，另一个是在集群节点中用做内部数据结构，除此之外，跳跃表在 Redis 里没有其它用途。</p><h3 id="九-Redis-与-MySQL如何保证双写一致性"><a href="#九-Redis-与-MySQL如何保证双写一致性" class="headerlink" title="九.Redis 与 MySQL如何保证双写一致性"></a>九.Redis 与 MySQL如何保证双写一致性</h3><p>   1.选择合适的数据同步方式：根据应用的需求和数据访问模式，选择合适的数据同步方式。同步方式包括单向同步、双向同步和不同步等。<br>   2.使用事务：在 MySQL 中使用事务来确保数据的原子性。在 Redis 中，可以使用 MULTI/EXEC 命令组来执行事务操作。<br>   3.避免长时间的事务：MySQL 中的长时间事务可能会导致 Redis 中的数据不同步。因此，在设计数据库操作时，应尽量避免长时间的事务。<br>   4.主从复制：使用 MySQL 的主从复制功能，将数据变更同步到从数据库。然后，使用 Redis 的订阅/发布功能，将从数据库中的数据变更同步到 Redis。这种方式可以实现 MySQL 和 Redis 的双向同步。<br>   5.分布式事务：使用分布式事务协议，如两阶段提交或三阶段提交，来确保 Redis 和 MySQL 之间的数据一致性。分布式事务可以保证多个数据库之间的数据一致性。<br>   6.定时同步：对于一些不需要实时同步的数据，可以使用定时同步的方式。例如，每天定时将 MySQL 中的数据同步到 Redis 中。<br>   7.数据校验：定期进行数据校验，以确保 Redis 和 MySQL 中的数据一致。如果数据不一致，及时进行修复。</p><pre><code>具体解决方案：   1、延时双删   2、Binlog实现异步重试删除</code></pre><h3 id="十-Redis-为什么是单线程"><a href="#十-Redis-为什么是单线程" class="headerlink" title="十.Redis 为什么是单线程"></a>十.Redis 为什么是单线程</h3><pre><code>  Redis操作基于内存，绝大多数操作的性能瓶颈不在CPU  单线程模型，避免了线程间切换带来的性能开销  使用单线程模型也能并发的处理客户端的请求（多路复用I/O）  使用单线程模型，可维护性更高，开发，调试和维护的成本更低</code></pre><h3 id="十一-Redis-的Hash-冲突"><a href="#十一-Redis-的Hash-冲突" class="headerlink" title="十一.Redis 的Hash 冲突"></a>十一.Redis 的Hash 冲突</h3><pre><code> Redis通过链式哈希解决冲突，也就是同一个桶里面的元素使用链表保存。但是当链表过长就会导致查找性能变差可能。所以redis为了追求块，使用了两个全局哈希表。用于rehash操作，增加现有的哈希桶数量，减少哈希冲突。</code></pre><h3 id="十二-redis高可用"><a href="#十二-redis高可用" class="headerlink" title="十二.redis高可用"></a>十二.redis高可用</h3><pre><code> Redis 实现高可用有三种部署模式：  主从模式：     主从模式是Redis提供的一种数据复制方式。一个主节点（Master）可以有一个或多个从节点（Slave）与之复制。  哨兵模式：     哨兵模式是主从模式的升级版，可以实现自动故障转移。哨兵是一个独立的进程，它会监控主节点和从节点，并在主节点出现故障时自动进行故障转移。  集群模式:     集群模式是Redis提供的一种处理数据分片和提高并发能力的解决方案。在集群模式下，数据会被分布在不同的节点上，并且节点会有自动的故障转移功能。</code></pre><h3 id="十三-Redis-的内存用完了会发生什么"><a href="#十三-Redis-的内存用完了会发生什么" class="headerlink" title="十三.Redis 的内存用完了会发生什么"></a>十三.Redis 的内存用完了会发生什么</h3><p>   写操作失败：当 Redis 内存用尽时，无法再接受新的写入操作。此时，任何尝试写入数据的操作（如 SET、INCRBY、LPUSH 等）都会失败，并返回错误消息。</p><p>   读操作仍可继续：尽管 Redis 的内存用完，但仍然可以执行读取操作（如 GET、HGET、LINDEX 等）。这是因为 Redis 的数据仍然保存在磁盘上的持久化文件中，而不是完全依赖于内存。但是，需要注意的是，读操作的性能可能会受到影响，因为 Redis 需要频繁地从磁盘加载数据到内存中。</p><p>   内存淘汰策略：Redis 提供了多种内存淘汰策略来处理内存耗尽的情况。当内存用完时，根据配置的淘汰策略，Redis 会尝试清理一些数据以腾出空间给新的写入操作。常见的淘汰策略包括：</p><p>   LRU（Least Recently Used）：选择最近最少使用的键进行淘汰。<br>   LFU（Least Frequently Used）：选择最不经常使用的键进行淘汰。<br>   Random（随机）：随机选择键进行淘汰。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elastic-job</title>
      <link href="/2019/01/30/elastic-job/"/>
      <url>/2019/01/30/elastic-job/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="任务调度：是指系统为了自动完成特定任务，在约定的特定时刻去执行任务的过程。"><a href="#任务调度：是指系统为了自动完成特定任务，在约定的特定时刻去执行任务的过程。" class="headerlink" title="任务调度：是指系统为了自动完成特定任务，在约定的特定时刻去执行任务的过程。"></a>任务调度：是指系统为了自动完成特定任务，在约定的特定时刻去执行任务的过程。</h2><h3 id="elastic-job"><a href="#elastic-job" class="headerlink" title="elastic-job"></a>elastic-job</h3><pre><code>Elastic-Job 是当当开源的一款非常好用的分布式任务调度框架,由两个相互独立的子项目Elastic-Job-lite和Elastic-Job-cloud 组成。</code></pre><h3 id="调度方案"><a href="#调度方案" class="headerlink" title="调度方案"></a>调度方案</h3><pre><code>    非中心化调度方案（ElasticJob）：        ElasticJob 的非中心化调度方案是指每个作业实例都有独立的调度能力，作业的调度逻辑分散在各个作业实例中。        每个作业实例都有能力自主决定何时执行作业，不依赖于中心化的调度中心。        这种方式可以更好地支持作业的分布式部署和水平扩展，减少单点故障的风险。    中心化调度方案（xxl-job）：        xxl-job 的中心化调度方案是指作业的调度逻辑集中在一个中心化的调度中心，作业实例只负责执行任务，而不负责调度逻辑。        调度中心负责统一管理作业的调度策略、执行情况等，作业实例按照调度中心的指令执行任务。        这种方式集中管理调度逻辑，能够更好地监控和管理作业的执行情况，但也存在单点故障和性能瓶颈的风险。    总的来说，非中心化调度方案更适合分布式、高可用的场景，而中心化调度方案更适合需要集中管理和监控的场景。ElasticJob 和 xxl-job 分别采用了不同的调度方案，以满足不同的需求和场景。</code></pre><h3 id="组件概念讲解"><a href="#组件概念讲解" class="headerlink" title="组件概念讲解"></a>组件概念讲解</h3><h4 id="注册中心（zookeeper）"><a href="#注册中心（zookeeper）" class="headerlink" title="注册中心（zookeeper）"></a>注册中心（zookeeper）</h4><pre><code>1.作用    1.执行任务信息的存储：如任务名称、任务参与实例、任务执行策略等;    2.实现选举机制：在任务执行实例数量变化时(如在快速上手中的启动新实例或停止实例)，会触发选举机制来决定让哪个实例去执行该任务。2.zookeeper目录结构</code></pre><p> <img src="/image/zookeeper%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.png" alt="效果图预览"><br>            config节点：<br>                记录了任务的配置信息，包含执行类，cron表达式，分片算法类，分片数量，分片参数。默认状态下如果你修改了job的配置比如cron表达式，分片数量等是不会更新到zookeeper上去的,需要把LiteJobConfiguration的参数overwrite修改成true,或者删除zk的结点再启动作业重新创建。<br>            instances节点:<br>                同一个ob下的elastic-job的部署实例。一台机器上可以启动多个ob实例，也就是jar包。instances的命名是IP+@-@+PID.<br>            leader节点:<br>            任务实例的主节点信息，通过zookeeper的主节点选举,选出来的主节点信息。下面的子节点分为electionsharding和failover三个子节点。分别用于生节点选举,分片和失效转移处理。election下面的instance节点显式了当前主节点的实例ID:jobInstanceld。latch节点也是一个永久节点用于选举时候的实现分布式锁。sharding节点下面有一个临时节点necessary，是否需要重新分片的标记,如果分片总数变化或任务实例节点上下线，以及主节点选举，都会触发设置重分片标记，主节点会进行分片计算。<br>            sharding节点:<br>                任务的分片信息，子节点是分片项序号，从零开始，至分片总数减一。从这个节点可以看出哪个分片在哪个实例运行</p><h3 id="SpringBoot配置"><a href="#SpringBoot配置" class="headerlink" title="SpringBoot配置"></a>SpringBoot配置</h3><pre><code>    //zoopkeeper端口    private static final int  ZOOKEEPER_PORT = 2181;    //zookeeper链接字符串    private static final String ZOOKEEPER_CONNECTION_STRING=&quot;localhost:&quot;+ZOOKEEPER_PORT;    //定时任务命名空间    private static  final  String JOB_NAMESPACE = &quot;elastic-job-example-java&quot;;    @Bean(initMethod = &quot;init&quot;)    private static CoordinatorRegistryCenter  setUpRegestryCenter(){        //zk配置        ZookeeperConfiguration zookeeperConfiguration = new ZookeeperConfiguration(ZOOKEEPER_CONNECTION_STRING, JOB_NAMESPACE);        //减少ZK超时时间        zookeeperConfiguration.setSessionTimeoutMilliseconds(100);        //创建注册中心        CoordinatorRegistryCenter zookeeperRegistryCenter = new ZookeeperRegistryCenter(zookeeperConfiguration);        return zookeeperRegistryCenter;    }</code></pre><h3 id="作业及分片"><a href="#作业及分片" class="headerlink" title="作业及分片"></a>作业及分片</h3><pre><code> 作业即调度任务的处理逻辑，Elastic-Job 提供 simple、Dataflow和 script 3 种作业类型。 方法参数 shardingcontext包含作业配置、分片和运行时信息。可通过 getshamingrotalcount()，getshardingItem()等方法分别获职分片总数，运行在本作业服务器的分片序列号等。  1.作业类型        Simple 类型作业：意为简单实现，未经任何封装的类型。需实现 simpleJob 接口。该接口仅提供单一方法用于实现，此方法将定时执行。与 cuartz原生接口相似，但提供了弹性扩缩容和分片等功能。采用简单的任务执行模式，不涉及动态获取数据和处理流程        Dataflow类型作业：Dataflow 类型用于处理数据流，需实现 DataflowJob 接口。该接口提供2个方法可供实现，分别用于抓取(fetchpata)和处理(processData)数据。        流式处理数据：不停的抓取数据直至返回值为null或返回的集合长度为0，然后会等待 10 秒后再次尝试抓取数据        非流式处理数据：等待调度逻辑来抓取和处理数据        在 ElasticJob 的 dataflow 模式中，非流式处理数据意味着在每次作业执行过程中会执行一次 fetchData 方法和 processData 方法。&quot;每次作业执行过程&quot;指的是作业调度框架根据配置的调度策略，定期触发作业执行的过程。        在 ElasticJob 中，可以通过配置作业的调度策略来控制作业的执行时间间隔。这个时间间隔可以根据具体的需求进行配置，例如可以配置为每隔一小时执行一次作业。        在 ElasticJob 的 dataflow 模式中，如果设置了流式处理数据，即数据是动态流入的，那么设置调度策略来定期触发作业执行的过程可能会失去意义。因为在流式处理数据的情况下，作业会根据数据的动态流入情况来触发执行，而不是根据固定的调度策略来执行。        如果在 dataflow 模式中抓取不到数据，ElasticJob 默认会等待一段时间后再次尝试抓取数据。默认情况下，如果抓取不到数据，会等待 10 秒后再次尝试抓取数据。这个等待时间可以通过配置来进行调整，以适应不同的业务需求。        Script 类型作业：意为脚本类型作业，支持 ghel1，python，per1 等所有类型脚本。只需通过控制台或代码配置 seriptcommandzine 即可，无需编码。执行脚本路径可包含参数，参数传递完毕后，作业框架会自动追加最后一个参数为作业运行时信息。</code></pre><h3 id="作业分片策略"><a href="#作业分片策略" class="headerlink" title="作业分片策略"></a>作业分片策略</h3><pre><code>AverageAllocationjobshardingstrategy：全路径:    com.dangdang.ddframe.job.lite.api.strategy.impl.AverageAllocationobShardingStrategy策略说明:基于平均分配算法的分片策略，也是默认的分片策略。如果分片不能整除，则不能整除的多余分片将依次追加到序号小的服务器。如:如果有3台服务器，分成9片，则每台服务器分到的分片是:1=0,1,2,2=3,4,5,3=6,7,8如果有3台服务器，分成8片，则每台服务器分到的分片是:1=0,1,6,2=2,3,7,3=14,5]如果有3台服务器，分成10片，则每台服务器分到的分片是:1=0,1,2,9,2=3,4,5,3=6,7,8OdevitysortByNamejobshardingstrategy：全路径:    com.dangdang.ddframe.job.ite.api.strategy.impl.0devitySortByNamejobShardingStrategy策略说明:根据作业名的哈希值奇偶数决定IP升降序算法的分片策略作业名的哈希值为奇数则IP升序。作业名的哈希值为偶数则IP降序。用于不同的作业平均分配负载至不同的服务器。RotateServerByNamelobshardingstrategy：全路径:    com.dangdang.ddframe.job.ite.api.strategy.impl.RotateServerByNamejobShardingStrategy策略说明:根据作业名的哈希值对服务器列表进行轮转的分片策略。配置分片策略：与配置通常的作业属性相同，在spring命名空间或者lobConfiguration中配置jobshardingStrategyClass属性，居性值是作业分片策略类的全路径。</code></pre><h3 id="SpringBoot配置-1"><a href="#SpringBoot配置-1" class="headerlink" title="SpringBoot配置"></a>SpringBoot配置</h3><pre><code>    @Configuration    public class ElasticJobConfig {        @Resource        FileBackupJob fileBackupJob;        @Resource        CoordinatorRegistryCenter elasticJpbRegistryConfig;        @Bean(initMethod = &quot;init&quot;)        public SpringJobScheduler initJobScheduler(){            SpringJobScheduler springJobScheduler = new SpringJobScheduler(fileBackupJob, elasticJpbRegistryConfig,                    createJobConfiguration(fileBackupJob.getClass(), &quot;0/3 * * * * ?&quot;, 4, &quot;0=text,1=image,2=radio,4=vedio&quot;));            return springJobScheduler;        }        /**        * 配置任务详细信息        * @param jobClass 任务执行类        * @param cron  执行策略        * @param shardingTotalcount 分片数量        * @param shardingItemParameters 分片个性化参数        * @return        */        private LiteJobConfiguration createJobConfiguration(final Class&lt;?extends SimpleJob&gt; jobClass,                                                            final String cron,                                                            final int shardingTotalcount,                                                            final String shardingItemParameters){            //定义作业核心配置            JobCoreConfiguration.Builder builder = JobCoreConfiguration.newBuilder(jobClass.getCanonicalName(), cron, shardingTotalcount);            if (StringUtils.isEmpty(shardingItemParameters)){                builder.jobParameter(shardingItemParameters);            }            JobCoreConfiguration build = builder.build();            //定义SIMPLE类配置            SimpleJobConfiguration simpleJobConfiguration = new SimpleJobConfiguration(build, jobClass.getCanonicalName());            //定义Lite作业根配置            LiteJobConfiguration liteJobConfiguration = LiteJobConfiguration.newBuilder(simpleJobConfiguration).overwrite(true).build();            return liteJobConfiguration;        }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> elastic-job </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elastic-job </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式</title>
      <link href="/2018/12/20/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>/2018/12/20/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><h3 id="设计模式分类"><a href="#设计模式分类" class="headerlink" title="设计模式分类"></a>设计模式分类</h3><pre><code>设计模式是解决软件开发中常见问题的一些最佳实践。它们被分为三大类：创建型模式、结构型模式和行为型模式。创建型模式：这类模式主要关注对象的创建过程，涉及如何创建对象而减少客户端代码与对象实例化过程的耦合。具体包括工厂模式、抽象工厂模式、单例模式、建造者模式和原型模式等。结构型模式：这类模式关注类或对象之间的组合方式，如何组合类或对象以形成更大的结构。具体包括适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式和享元模式等。行为型模式：这类模式关注对象之间的交互和对象的行为，如何分配职责和算法。具体包括策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式和解释器模式等。</code></pre><h3 id="设计模式六大原则"><a href="#设计模式六大原则" class="headerlink" title="设计模式六大原则"></a>设计模式六大原则</h3><pre><code>    ‌单一职责原则（Single Responsibility Principle, SRP）：一个类应该只有一个引起它变化的原因。这意味着一个类应该只负责一项功能或业务逻辑，以提高内聚性和减少耦合。    ‌开闭原则（Open-Closed Principle, OCP）：软件实体（如类、模块或函数）应该对扩展开放，对修改关闭。这意味着当需要添加新功能时，应该通过添加新代码来实现，而不是修改现有的代码。    里氏替换原则（Liskov Substitution Principle, LSP）：子类型必须能够替换其基类型而不会引起程序行为的变化。这是面向对象编程中继承机制的基础原则之一。    ‌依赖倒置原则（Dependency Inversion Principle, DIP）：高层模块不应该依赖于低层模块，而应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。这有助于减少代码之间的耦合。    ‌接口隔离原则（Interface Segregation Principle, ISP）：客户端不应该依赖于它不使用的接口。接口设计应该尽可能细化，只暴露客户端需要的方法，隐藏不需要的方法。    ‌迪米特法则（Law of Demeter, LoD）：一个对象应当尽可能少地了解其他对象的内容，以减少对象之间的耦合。这有助于提高软件的可维护性和灵活性。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Eureka</title>
      <link href="/2018/10/10/Eureka/"/>
      <url>/2018/10/10/Eureka/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="Eureka是Netflix的一个子模块，也是核心模块之-。-Eureka是一个基于REST的服务，用于定位服务，以实现云端中间层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务发现与注册，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了"><a href="#Eureka是Netflix的一个子模块，也是核心模块之-。-Eureka是一个基于REST的服务，用于定位服务，以实现云端中间层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务发现与注册，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了" class="headerlink" title="Eureka是Netflix的一个子模块，也是核心模块之-。 Eureka是一个基于REST的服务，用于定位服务，以实现云端中间层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务发现与注册，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了"></a>Eureka是Netflix的一个子模块，也是核心模块之-。 Eureka是一个基于REST的服务，用于定位服务，以实现云端中间层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务发现与注册，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了</h2><h3 id="Eureka的基本架构"><a href="#Eureka的基本架构" class="headerlink" title="Eureka的基本架构"></a>Eureka的基本架构</h3><pre><code>SpringCloud封装了NetFlix公司开发的Eureka模块来实现服务注册和发现(对比Zookeeper)    Eureka采用了C-S的架构设计，EurekaServer 作为服务注册功能的服务器，他是服务注册中心    而系统中的其他微服务。使用Eureka的客户端连接到EurekaServer并维持心跳连接。 这样系统的维护人员就可以通过EurekaServer来监控系统中各个微服务是否正常运行，SpringCloud的一 些其他模块(此如Zuul)就可以通过EurekaServer来发现系统中的其他微服务, 并执行相关的逻辑;和Dubbo架构对比</code></pre><h3 id="Eureka包含两个组件"><a href="#Eureka包含两个组件" class="headerlink" title="Eureka包含两个组件"></a>Eureka包含两个组件</h3><pre><code>    Eureka Server提供服务注册服务，各个节点启动后，会在EurekaServer中进行注册， 这样Eureka Server中的服务注册表中将会村粗所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。    Eureka Client是一 -个Java客户端， 用于简化EurekaServer的交互,客户端同时也具备一个内置的，使用轮询负载算法的负载均衡器。在应用启动后，将会向EurekaServer发送心跳 (默认周期为30秒) .如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳, EurekaServer将会从服务注册表中把这个服务节点移除掉(默认周期为90秒)</code></pre><h3 id="Eureka-三大角色"><a href="#Eureka-三大角色" class="headerlink" title="Eureka 三大角色"></a>Eureka 三大角色</h3><pre><code>    Eureka Server：提供服务注册与发现。和zookeeper客户端一样    Service Provider：将自身服务注册到Eureka中，从而使消费方能够找到    Service Consumer：服务消费方从Eureka中获取注册服务列表，从而找到消费服务</code></pre><h3 id="Eureka-自我保护机制"><a href="#Eureka-自我保护机制" class="headerlink" title="Eureka 自我保护机制"></a>Eureka 自我保护机制</h3><pre><code>     默认情况下，如果EurekaServer在一定时间内没有接收到某 个微服务实例的心跳，EurekaServer将会注销该实例(默认90秒)。 但是当网络分区故障发生时，微服务与Eureka之间无法正常通行，以上行为可能变得非常危险了---- 因为微服务本身其实是健康的，此时本不应该注销这个服务。Eureka通过 自我保护机制来解决这个问题–当EurekaServer节点在短时间内丢失过多客户端时(可能发生了网络分区故障) , 那么这个节点就会进入自我保护模式。一旦进入该模式，EurekaServer就会保护服务注册表中的信息，不再删除服务注册表中的数据(也就是不会注销任何微服务) .当网络故障恢复后，该EurekaServer节 点会自动退出自我保护模式。    在自我保护模式中，EurekaServer会保护服务注册表中的信息， 不再注销任何服务实例。当它收到的心跳数重新恢复到阈值以上时，该EurekaServer节点就会 自动退出自我保护模式。它的设计哲学就是宁可保留错误的服务注册信息，也不盲目注销任何可能健康的服务实例。一句话:好死不如赖活着    综上，自我保护模式是-种应对网络异常的安全保护措施。它的架构哲学是宁可同时保留所有微服务(健康的微服务和不健康的微服务都会保留)，也不盲目注销任何健康的微服务。使用自我保护模式，可以让Eureka集群更加的健壮和稳定    在SpringCloud中, 可以使用 eureka. server. enable-self-preservation = false 禁用自我保护模式[不推荐关闭自我保护机制]</code></pre>]]></content>
      
      
      <categories>
          
          <category> Eureka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Eureka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Cloud</title>
      <link href="/2018/10/08/Spring%20Cloud/"/>
      <url>/2018/10/08/Spring%20Cloud/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="SpringCloud-基于SpringBoot提供了-套微服务解决方案-包括服务注册与发现，配置中心，全链路监控-服务网关，负载均衡，熔断器等组件，除了基于NetFlix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。"><a href="#SpringCloud-基于SpringBoot提供了-套微服务解决方案-包括服务注册与发现，配置中心，全链路监控-服务网关，负载均衡，熔断器等组件，除了基于NetFlix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。" class="headerlink" title="SpringCloud,基于SpringBoot提供了-套微服务解决方案,包括服务注册与发现，配置中心，全链路监控,服务网关，负载均衡，熔断器等组件，除了基于NetFlix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。"></a>SpringCloud,基于SpringBoot提供了-套微服务解决方案,包括服务注册与发现，配置中心，全链路监控,服务网关，负载均衡，熔断器等组件，除了基于NetFlix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。</h2><h3 id="SpringCloud和SpringBoot关系"><a href="#SpringCloud和SpringBoot关系" class="headerlink" title="SpringCloud和SpringBoot关系"></a>SpringCloud和SpringBoot关系</h3><pre><code>SpringBoot专注于快速方便的开发单个个体微服务。SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一 个个单体微服务整合并管理起来,为各个微服务之间提供:配置管理，服务发现，断路器，路由，微代理，事件总线，全局锁，决策竞选，分布式会话等等集成服务。SpringBoot可以离开SpringClooud独立使用，开发项目，但是SpringCloud离不开SpringBoot, 属于依赖关系SpringBoot专注于快速、方便的开发单个个体微服务, SpringCloud关注 全局 的服务治理框架</code></pre><h3 id="Dubbo和SpringCloud对比"><a href="#Dubbo和SpringCloud对比" class="headerlink" title="Dubbo和SpringCloud对比"></a>Dubbo和SpringCloud对比</h3><pre><code>                    Dubbo                            Spring    服务注册中心    Zookeeper                    Spring Cloud Netfilx Eureka    服务调用中心    RPC                            REST API    服务监控        Dubbo - monitor                Spring Boot Admin    断路器           不完善                        Spring Cloud Netflix Hystrix    服务网关        无                            Spring Cloud Netflix Zuul    分布式配置        无                            Spring Cloud Config    服务跟踪        无                            Spring Cloud Sleuth    消息总线        无                            Spring Cloud Bus    数据流            无                            Spring Cloud Stream    批量任务        无                            Spring Cloud Task最大区别: SpringCloud抛弃 了Dubbo的RPC通信,采用的是基于HTTP的REST方式。</code></pre><h3 id="SpringCloud实现功能"><a href="#SpringCloud实现功能" class="headerlink" title="SpringCloud实现功能"></a>SpringCloud实现功能</h3><pre><code>Distributed/versioned configuration (分布式/版本控制配置)Service registration and discovery (服务注册与发现)Routing (路由)Service-to-service calls (服务到服务的调用)Load balancing (负载均衡配置)Circuit Breakers (断路器)Distributed messaging (分布式消息管理)</code></pre><h3 id="SpringCloud下载"><a href="#SpringCloud下载" class="headerlink" title="SpringCloud下载"></a>SpringCloud下载</h3><pre><code>官网：http://projects.spring.io/spring-cloud/注意SpringCloud和Springboot有版本对应关系，可参考官网</code></pre><h3 id="SpringCloud一般有如下几个模块"><a href="#SpringCloud一般有如下几个模块" class="headerlink" title="SpringCloud一般有如下几个模块"></a>SpringCloud一般有如下几个模块</h3><pre><code>microservicecloud-api [封装的整体entity/接口/公共配置等]microservicecloud-provider [服务提供者]microservicecloud-consumer [服务消费者]springcloud-eureka-7001 [Eureka注册中心]</code></pre><h3 id="CAP是什么"><a href="#CAP是什么" class="headerlink" title="CAP是什么"></a>CAP是什么</h3><pre><code> C (Consistency) 强一致性 A (Availabilty)可用性 P (Partition tolerance)分区容错性 CAP的三进二: CA、AP、 CP</code></pre><p><img src="/image/CPA.png" alt="效果图预览">  </p><h3 id="CAP理论的核心"><a href="#CAP理论的核心" class="headerlink" title="CAP理论的核心"></a>CAP理论的核心</h3><pre><code>一个分布式系统不可能同时很好的满足-致性,可用性和分区容错性这三个需求根据CAP原理，将NoSQL数据库分成了满足CA原则，满足CP原则和满足AP原则三大类:    CA:单点集群，满足-致性，可用性的系统，通常可扩展性较差    CP: 满足- -致性，分区容错性的系统，通常性能不是特别高    AP:满足可用性。分区容错性的系统，通常可能对一致性要求低一些</code></pre>]]></content>
      
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据加密方式</title>
      <link href="/2018/07/10/%E6%95%B0%E6%8D%AE%E5%8A%A0%E5%AF%86%E6%96%B9%E5%BC%8F/"/>
      <url>/2018/07/10/%E6%95%B0%E6%8D%AE%E5%8A%A0%E5%AF%86%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="数字签名、信息加密-是前后端开发都经常需要使用到的技术，应用场景包括了用户登入、交易、信息通讯、oauth-等等，不同的应用场景也会需要使用到不同的签名加密算法，或者需要搭配不一样的-签名加密算法-来达到业务目标。"><a href="#数字签名、信息加密-是前后端开发都经常需要使用到的技术，应用场景包括了用户登入、交易、信息通讯、oauth-等等，不同的应用场景也会需要使用到不同的签名加密算法，或者需要搭配不一样的-签名加密算法-来达到业务目标。" class="headerlink" title="数字签名、信息加密 是前后端开发都经常需要使用到的技术，应用场景包括了用户登入、交易、信息通讯、oauth 等等，不同的应用场景也会需要使用到不同的签名加密算法，或者需要搭配不一样的 签名加密算法 来达到业务目标。"></a>数字签名、信息加密 是前后端开发都经常需要使用到的技术，应用场景包括了用户登入、交易、信息通讯、oauth 等等，不同的应用场景也会需要使用到不同的签名加密算法，或者需要搭配不一样的 签名加密算法 来达到业务目标。</h2><h3 id="一、数字签名"><a href="#一、数字签名" class="headerlink" title="一、数字签名"></a>一、数字签名</h3><pre><code>数字签名，简单来说就是通过提供 可鉴别 的 数字信息 验证 自身身份 的一种方式。一套 数字签名 通常定义两种 互补 的运算，一个用于 签名，另一个用于 验证。分别由 发送者 持有能够 代表自己身份 的 私钥 (私钥不可泄露),由 接受者 持有与私钥对应的 公钥 ，能够在 接受 到来自发送者信息时用于 验证 其身份。</code></pre><h3 id="二、加密和解密"><a href="#二、加密和解密" class="headerlink" title="二、加密和解密"></a>二、加密和解密</h3><pre><code>2.1. 加密    数据加密 的基本过程，就是对原来为 明文 的文件或数据按 某种算法 进行处理，使其成为 不可读 的一段代码，通常称为 “密文”。通过这样的途径，来达到 保护数据 不被 非法人窃取、阅读的目的。2.2. 解密    加密 的 逆过程 为 解密，即将该 编码信息 转化为其 原来数据 的过程。</code></pre><h3 id="三、对称加密和非对称加密"><a href="#三、对称加密和非对称加密" class="headerlink" title="三、对称加密和非对称加密"></a>三、对称加密和非对称加密</h3><pre><code>加密算法分 对称加密 和 非对称加密，其中对称加密算法的加密与解密 密钥相同，非对称加密算法的加密密钥与解密 密钥不同，此外，还有一类 不需要密钥 的 散列算法。常见的 对称加密 算法主要有 DES、3DES、AES 等，常见的 非对称算法 主要有 RSA、DSA 等，散列算法 主要有 SHA-1、MD5 等3.1 对称加密     对称加密算法 是应用较早的加密算法，又称为 共享密钥加密算法。在 对称加密算法 中，使用的密钥只有一个，发送 和 接收 双方都使用这个密钥对数据进行 加密 和 解密。这就要求加密和解密方事先都必须知道加密的密钥。</code></pre><p> <img src="/image/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png" alt="效果图预览"></p><pre><code>数据加密过程：在对称加密算法中，数据发送方 将 明文 (原始数据) 和 加密密钥 一起经过特殊 加密处理，生成复杂的 加密密文 进行发送。数据解密过程：数据接收方 收到密文后，若想读取原数据，则需要使用 加密使用的密钥 及相同算法的 逆算法 对加密的密文进行解密，才能使其恢复成 可读明文。3.2. 非对称加密     非对称加密算法，又称为 公开密钥加密算法。它需要两个密钥，一个称为 公开密钥 (public key)，即 公钥，另一个称为 私有密钥 (private key)，即 私钥。    因为 加密 和 解密 使用的是两个不同的密钥，所以这种算法称为 非对称加密算法。</code></pre><p> <img src="/image/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86.png" alt="效果图预览"></p><pre><code>    如果使用 公钥 对数据 进行加密，只有用对应的 私钥 才能 进行解密。    如果使用 私钥 对数据 进行加密，只有用对应的 公钥 才能 进行解密。</code></pre><h3 id="四、常见的签名加密算法"><a href="#四、常见的签名加密算法" class="headerlink" title="四、常见的签名加密算法"></a>四、常见的签名加密算法</h3><pre><code>4.1. MD5算法    MD5 用的是 哈希函数，它的典型应用是对一段信息产生 信息摘要，以 防止被篡改。严格来说，MD5 不是一种 加密算法 而是 摘要算法。无论是多长的输入，MD5 都会输出长度为 128bits 的一个串 (通常用 16 进制 表示为 32 个字符)。    public static final byte[] computeMD5(byte[] content) {    try {        MessageDigest md5 = MessageDigest.getInstance(&quot;MD5&quot;);        return md5.digest(content);    } catch (NoSuchAlgorithmException e) {        throw new RuntimeException(e);    }}4.2. SHA1算法    SHA1 是和 MD5 一样流行的 消息摘要算法，然而 SHA1 比 MD5 的 安全性更强。对于长度小于 2 ^ 64 位的消息，SHA1 会产生一个 160 位的 消息摘要。基于 MD5、SHA1 的信息摘要特性以及 不可逆 (一般而言)，可以被应用在检查 文件完整性 以及 数字签名 等场景。    public static byte[] computeSHA1(byte[] content) {        try {            MessageDigest sha1 = MessageDigest.getInstance(&quot;SHA1&quot;);            return sha1.digest(content);        } catch (NoSuchAlgorithmException e) {            throw new RuntimeException(e);        }    }4.3. HMAC算法    HMAC 是密钥相关的 哈希运算消息认证码（Hash-based Message Authentication Code），HMAC 运算利用 哈希算法 (MD5、SHA1 等)，以 一个密钥 和 一个消息 为输入，生成一个 消息摘要 作为 输出。    HMAC 发送方 和 接收方 都有的 key 进行计算，而没有这把 key 的第三方，则是 无法计算 出正确的 散列值的，这样就可以 防止数据被篡改。    package net.pocrd.util;    import net.pocrd.annotation.NotThreadSafe;    import net.pocrd.define.ConstField;    import org.slf4j.Logger;    import org.slf4j.LoggerFactory;    import javax.crypto.Mac;    import javax.crypto.SecretKey;    import javax.crypto.spec.SecretKeySpec;    import java.util.Arrays;    @NotThreadSafe    public class HMacHelper {        private static final Logger logger = LoggerFactory.getLogger(HMacHelper.class);        private Mac mac;        /**        * MAC算法可选以下多种算法        * HmacMD5/HmacSHA1/HmacSHA256/HmacSHA384/HmacSHA512        */        private static final String KEY_MAC = &quot;HmacMD5&quot;;        public HMacHelper(String key) {            try {                SecretKey secretKey = new SecretKeySpec(key.getBytes(ConstField.UTF8), KEY_MAC);                mac = Mac.getInstance(secretKey.getAlgorithm());                mac.init(secretKey);            } catch (Exception e) {                logger.error(&quot;create hmac helper failed.&quot;, e);            }        }        public byte[] sign(byte[] content) {            return mac.doFinal(content);        }        public boolean verify(byte[] signature, byte[] content) {            try {                byte[] result = mac.doFinal(content);                return Arrays.equals(signature, result);            } catch (Exception e) {                logger.error(&quot;verify sig failed.&quot;, e);            }            return false;        }    }4.4. AES/DES/3DES算法    AES、DES、3DES 都是 对称 的 块加密算法，加解密 的过程是 可逆的。常用的有 AES128、AES192、AES256 (默认安装的 JDK 尚不支持 AES256，需要安装对应的 jce 补丁进行升级 jce1.7，jce1.8)。    4.4.1. DES算法        DES 加密算法是一种 分组密码，以 64 位为 分组对数据 加密，它的 密钥长度 是 56 位，加密解密 用 同一算法。        DES 加密算法是对 密钥 进行保密，而 公开算法，包括加密和解密算法。这样，只有掌握了和发送方 相同密钥 的人才能解读由 DES加密算法加密的密文数据。因此，破译 DES 加密算法实际上就是 搜索密钥的编码。对于 56 位长度的 密钥 来说，如果用 穷举法 来进行搜索的话，其运算次数为 2 ^ 56 次。    4.4.2. 3DES算法        是基于 DES 的 对称算法，对 一块数据 用 三个不同的密钥 进行 三次加密，强度更高。    4.4.3. AES算法        AES 加密算法是密码学中的 高级加密标准，该加密算法采用 对称分组密码体制，密钥长度的最少支持为 128 位、 192 位、256 位，分组长度 128 位，算法应易于各种硬件和软件实现。这种加密算法是美国联邦政府采用的 区块加密标准。        AES 本身就是为了取代 DES 的，AES 具有更好的 安全性、效率 和 灵活性。        import net.pocrd.annotation.NotThreadSafe;        import javax.crypto.Cipher;        import javax.crypto.KeyGenerator;        import javax.crypto.spec.IvParameterSpec;        import javax.crypto.spec.SecretKeySpec;        import java.security.SecureRandom;        @NotThreadSafe        public class AesHelper {            private SecretKeySpec keySpec;            private IvParameterSpec iv;            public AesHelper(byte[] aesKey, byte[] iv) {                if (aesKey == null || aesKey.length &lt; 16 || (iv != null &amp;&amp; iv.length &lt; 16)) {                    throw new RuntimeException(&quot;错误的初始密钥&quot;);                }                if (iv == null) {                    iv = Md5Util.compute(aesKey);                }                keySpec = new SecretKeySpec(aesKey, &quot;AES&quot;);                this.iv = new IvParameterSpec(iv);            }            public AesHelper(byte[] aesKey) {                if (aesKey == null || aesKey.length &lt; 16) {                    throw new RuntimeException(&quot;错误的初始密钥&quot;);                }                keySpec = new SecretKeySpec(aesKey, &quot;AES&quot;);                this.iv = new IvParameterSpec(Md5Util.compute(aesKey));            }            public byte[] encrypt(byte[] data) {                byte[] result = null;                Cipher cipher = null;                try {                    cipher = Cipher.getInstance(&quot;AES/CFB/NoPadding&quot;);                    cipher.init(Cipher.ENCRYPT_MODE, keySpec, iv);                    result = cipher.doFinal(data);                } catch (Exception e) {                    throw new RuntimeException(e);                }                return result;            }            public byte[] decrypt(byte[] secret) {                byte[] result = null;                Cipher cipher = null;                try {                    cipher = Cipher.getInstance(&quot;AES/CFB/NoPadding&quot;);                    cipher.init(Cipher.DECRYPT_MODE, keySpec, iv);                    result = cipher.doFinal(secret);                } catch (Exception e) {                    throw new RuntimeException(e);                }                return result;            }            public static byte[] randomKey(int size) {                byte[] result = null;                try {                    KeyGenerator gen = KeyGenerator.getInstance(&quot;AES&quot;);                    gen.init(size, new SecureRandom());                    result = gen.generateKey().getEncoded();                } catch (Exception e) {                    throw new RuntimeException(e);                }                return result;            }        }4.5. RSA算法    RSA 加密算法是目前最有影响力的 公钥加密算法，并且被普遍认为是目前 最优秀的公钥方案 之一。RSA 是第一个能同时用于 加密 和 数字签名 的算法，它能够 抵抗 到目前为止已知的 所有密码攻击，已被 ISO 推荐为公钥数据加密标准。    import net.pocrd.annotation.NotThreadSafe;    import org.bouncycastle.jce.provider.BouncyCastleProvider;    import org.slf4j.Logger;    import org.slf4j.LoggerFactory;    import javax.crypto.Cipher;    import java.io.ByteArrayOutputStream;    import java.security.KeyFactory;    import java.security.Security;    import java.security.Signature;    import java.security.interfaces.RSAPrivateCrtKey;    import java.security.interfaces.RSAPublicKey;    import java.security.spec.PKCS8EncodedKeySpec;    import java.security.spec.X509EncodedKeySpec;    @NotThreadSafe    public class RsaHelper {        private static final Logger logger = LoggerFactory.getLogger(RsaHelper.class);        private RSAPublicKey publicKey;        private RSAPrivateCrtKey privateKey;        static {            Security.addProvider(new BouncyCastleProvider()); //使用bouncycastle作为加密算法实现        }        public RsaHelper(String publicKey, String privateKey) {            this(Base64Util.decode(publicKey), Base64Util.decode(privateKey));        }        public RsaHelper(byte[] publicKey, byte[] privateKey) {            try {                KeyFactory keyFactory = KeyFactory.getInstance(&quot;RSA&quot;);                if (publicKey != null &amp;&amp; publicKey.length &gt; 0) {                    this.publicKey = (RSAPublicKey)keyFactory.generatePublic(new X509EncodedKeySpec(publicKey));                }                if (privateKey != null &amp;&amp; privateKey.length &gt; 0) {                    this.privateKey = (RSAPrivateCrtKey)keyFactory.generatePrivate(new PKCS8EncodedKeySpec(privateKey));                }            } catch (Exception e) {                throw new RuntimeException(e);            }        }        public RsaHelper(String publicKey) {            this(Base64Util.decode(publicKey));        }        public RsaHelper(byte[] publicKey) {            try {                KeyFactory keyFactory = KeyFactory.getInstance(&quot;RSA&quot;);                if (publicKey != null &amp;&amp; publicKey.length &gt; 0) {                    this.publicKey = (RSAPublicKey)keyFactory.generatePublic(new X509EncodedKeySpec(publicKey));                }            } catch (Exception e) {                throw new RuntimeException(e);            }        }        public byte[] encrypt(byte[] content) {            if (publicKey == null) {                throw new RuntimeException(&quot;public key is null.&quot;);            }            if (content == null) {                return null;            }            try {                Cipher cipher = Cipher.getInstance(&quot;RSA/ECB/PKCS1Padding&quot;);                cipher.init(Cipher.ENCRYPT_MODE, publicKey);                int size = publicKey.getModulus().bitLength() / 8 - 11;                ByteArrayOutputStream baos = new ByteArrayOutputStream((content.length + size - 1) / size * (size + 11));                int left = 0;                for (int i = 0; i &lt; content.length; ) {                    left = content.length - i;                    if (left &gt; size) {                        cipher.update(content, i, size);                        i += size;                    } else {                        cipher.update(content, i, left);                        i += left;                    }                    baos.write(cipher.doFinal());                }                return baos.toByteArray();            } catch (Exception e) {                throw new RuntimeException(e);            }        }        public byte[] decrypt(byte[] secret) {            if (privateKey == null) {                throw new RuntimeException(&quot;private key is null.&quot;);            }            if (secret == null) {                return null;            }            try {                Cipher cipher = Cipher.getInstance(&quot;RSA/ECB/PKCS1Padding&quot;);                cipher.init(Cipher.DECRYPT_MODE, privateKey);                int size = privateKey.getModulus().bitLength() / 8;                ByteArrayOutputStream baos = new ByteArrayOutputStream((secret.length + size - 12) / (size - 11) * size);                int left = 0;                for (int i = 0; i &lt; secret.length; ) {                    left = secret.length - i;                    if (left &gt; size) {                        cipher.update(secret, i, size);                        i += size;                    } else {                        cipher.update(secret, i, left);                        i += left;                    }                    baos.write(cipher.doFinal());                }                return baos.toByteArray();            } catch (Exception e) {                logger.error(&quot;rsa decrypt failed.&quot;, e);            }            return null;        }        public byte[] sign(byte[] content) {            if (privateKey == null) {                throw new RuntimeException(&quot;private key is null.&quot;);            }            if (content == null) {                return null;            }            try {                Signature signature = Signature.getInstance(&quot;SHA1WithRSA&quot;);                signature.initSign(privateKey);                signature.update(content);                return signature.sign();            } catch (Exception e) {                throw new RuntimeException(e);            }        }        public boolean verify(byte[] sign, byte[] content) {            if (publicKey == null) {                throw new RuntimeException(&quot;public key is null.&quot;);            }            if (sign == null || content == null) {                return false;            }            try {                Signature signature = Signature.getInstance(&quot;SHA1WithRSA&quot;);                signature.initVerify(publicKey);                signature.update(content);                return signature.verify(sign);            } catch (Exception e) {                logger.error(&quot;rsa verify failed.&quot;, e);            }            return false;        }    }4.6. ECC算法    ECC 也是一种 非对称加密算法，主要优势是在某些情况下，它比其他的方法使用 更小的密钥，比如 RSA 加密算法，提供 相当的或更高等级 的安全级别。不过一个缺点是 加密和解密操作 的实现比其他机制 时间长 (相比 RSA 算法，该算法对 CPU 消耗严重)。    import net.pocrd.annotation.NotThreadSafe;    import org.bouncycastle.jcajce.provider.asymmetric.ec.BCECPrivateKey;    import org.bouncycastle.jcajce.provider.asymmetric.ec.BCECPublicKey;    import org.bouncycastle.jce.provider.BouncyCastleProvider;    import org.slf4j.Logger;    import org.slf4j.LoggerFactory;    import javax.crypto.Cipher;    import java.io.ByteArrayOutputStream;    import java.security.KeyFactory;    import java.security.Security;    import java.security.Signature;    import java.security.spec.PKCS8EncodedKeySpec;    import java.security.spec.X509EncodedKeySpec;    @NotThreadSafe    public class EccHelper {        private static final Logger logger = LoggerFactory.getLogger(EccHelper.class);        private static final int SIZE = 4096;        private BCECPublicKey  publicKey;        private BCECPrivateKey privateKey;        static {            Security.addProvider(new BouncyCastleProvider());        }        public EccHelper(String publicKey, String privateKey) {            this(Base64Util.decode(publicKey), Base64Util.decode(privateKey));        }        public EccHelper(byte[] publicKey, byte[] privateKey) {            try {                KeyFactory keyFactory = KeyFactory.getInstance(&quot;EC&quot;, &quot;BC&quot;);                if (publicKey != null &amp;&amp; publicKey.length &gt; 0) {                    this.publicKey = (BCECPublicKey)keyFactory.generatePublic(new X509EncodedKeySpec(publicKey));                }                if (privateKey != null &amp;&amp; privateKey.length &gt; 0) {                    this.privateKey = (BCECPrivateKey)keyFactory.generatePrivate(new PKCS8EncodedKeySpec(privateKey));                }            } catch (ClassCastException e) {                throw new RuntimeException(&quot;&quot;, e);            } catch (Exception e) {                throw new RuntimeException(e);            }        }        public EccHelper(String publicKey) {            this(Base64Util.decode(publicKey));        }        public EccHelper(byte[] publicKey) {            try {                KeyFactory keyFactory = KeyFactory.getInstance(&quot;EC&quot;, &quot;BC&quot;);                if (publicKey != null &amp;&amp; publicKey.length &gt; 0) {                    this.publicKey = (BCECPublicKey)keyFactory.generatePublic(new X509EncodedKeySpec(publicKey));                }            } catch (Exception e) {                throw new RuntimeException(e);            }        }        public byte[] encrypt(byte[] content) {            if (publicKey == null) {                throw new RuntimeException(&quot;public key is null.&quot;);            }            try {                Cipher cipher = Cipher.getInstance(&quot;ECIES&quot;, &quot;BC&quot;);                cipher.init(Cipher.ENCRYPT_MODE, publicKey);                int size = SIZE;                ByteArrayOutputStream baos = new ByteArrayOutputStream((content.length + size - 1) / size * (size + 45));                int left = 0;                for (int i = 0; i &lt; content.length; ) {                    left = content.length - i;                    if (left &gt; size) {                        cipher.update(content, i, size);                        i += size;                    } else {                        cipher.update(content, i, left);                        i += left;                    }                    baos.write(cipher.doFinal());                }                return baos.toByteArray();            } catch (Exception e) {                throw new RuntimeException(e);            }        }        public byte[] decrypt(byte[] secret) {            if (privateKey == null) {                throw new RuntimeException(&quot;private key is null.&quot;);            }            try {                Cipher cipher = Cipher.getInstance(&quot;ECIES&quot;, &quot;BC&quot;);                cipher.init(Cipher.DECRYPT_MODE, privateKey);                int size = SIZE + 45;                ByteArrayOutputStream baos = new ByteArrayOutputStream((secret.length + size + 44) / (size + 45) * size);                int left = 0;                for (int i = 0; i &lt; secret.length; ) {                    left = secret.length - i;                    if (left &gt; size) {                        cipher.update(secret, i, size);                        i += size;                    } else {                        cipher.update(secret, i, left);                        i += left;                    }                    baos.write(cipher.doFinal());                }                return baos.toByteArray();            } catch (Exception e) {                logger.error(&quot;ecc decrypt failed.&quot;, e);            }            return null;        }        public byte[] sign(byte[] content) {            if (privateKey == null) {                throw new RuntimeException(&quot;private key is null.&quot;);            }            try {                Signature signature = Signature.getInstance(&quot;SHA1withECDSA&quot;, &quot;BC&quot;);                signature.initSign(privateKey);                signature.update(content);                return signature.sign();            } catch (Exception e) {                throw new RuntimeException(e);            }        }        public boolean verify(byte[] sign, byte[] content) {            if (publicKey == null) {                throw new RuntimeException(&quot;public key is null.&quot;);            }            try {                Signature signature = Signature.getInstance(&quot;SHA1withECDSA&quot;, &quot;BC&quot;);                signature.initVerify(publicKey);                signature.update(content);                return signature.verify(sign);            } catch (Exception e) {                logger.error(&quot;ecc verify failed.&quot;, e);            }            return false;        }    }</code></pre><h3 id="加密算法对比"><a href="#加密算法对比" class="headerlink" title="加密算法对比"></a>加密算法对比</h3><pre><code>5.1. 散列算法比较    名称           安全性            速度    SHA-1            高                慢    MD5            中                快5.2. 对称加密算法比较    名称    密钥名称           运行速度        安全性    资源消耗    DES        56位                 较快        低        中    3DES    112位或168位          慢        中      高    AES        128、192、256位          快          高        低5.3. 非对称加密算法比较    名称    成熟度    安全性    运算速度    资源消耗    RSA          高    高        中            中    ECC          高    高        慢            高5.4. 对称算法与非对称加密算法    5.4.1. 对称算法    密钥管理：比较难，不适合互联网，一般用于内部系统    安全性：中    加密速度：快好 几个数量级 (软件加解密速度至少快 100 倍，每秒可以加解密数 M 比特 数据)，适合大数据量的加解密处理    5.4.2. 非对称算法    密钥管理：密钥容易管理    安全性：高    加密速度：比较慢，适合 小数据量 加解密或数据签名</code></pre>]]></content>
      
      
      <categories>
          
          <category> 加密 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 加密 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HashMap</title>
      <link href="/2018/05/01/HashMap/"/>
      <url>/2018/05/01/HashMap/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><h3 id="1-HashMap-中的hash-方法为什么要右移-16-位异或"><a href="#1-HashMap-中的hash-方法为什么要右移-16-位异或" class="headerlink" title="1.HashMap 中的hash 方法为什么要右移 16 位异或"></a>1.HashMap 中的hash 方法为什么要右移 16 位异或</h3><p>   是为了减少碰撞，进一步降低hash冲突的几率。int类型的数值是4个字节的，右移16位异或可以同时保留高16位于低16位的特征</p><p>   当数组的长度很短时，只有低位数的hashcode值能参与运算。而让高16位参与运算可以更好的均匀散列，减少碰撞，进一步降低hash冲突的几率。并且使得高16位和低16位的信息都被保留了。</p><h3 id="2-HashMap-是怎么解决哈希冲突的"><a href="#2-HashMap-是怎么解决哈希冲突的" class="headerlink" title="2.HashMap 是怎么解决哈希冲突的"></a>2.HashMap 是怎么解决哈希冲突的</h3><h4 id="什么是Hash算法"><a href="#什么是Hash算法" class="headerlink" title="什么是Hash算法"></a>什么是Hash算法</h4><pre><code>（1）Hash算法，就是把任意长度的输入，通过散列算法，变成固定长度的输出，这个输出结果是散列值。（2）Hash表又叫做“散列表”，它是通过key直接访问在内存存储位置的数据结构，在具体实现上，我们通过hash函数把key映射到表中的某个位置，来获取这个位置的数据，从而加快查找速度。</code></pre><h4 id="什么hash冲突"><a href="#什么hash冲突" class="headerlink" title="什么hash冲突"></a>什么hash冲突</h4><pre><code> 是由于哈希算法被计算的数据是无限的，而计算后的结果范围有限，所以总会存在不同的数据经过计算后得到的值相同，这就是哈希冲突。</code></pre><h4 id="解决hash冲突的方法"><a href="#解决hash冲突的方法" class="headerlink" title="解决hash冲突的方法"></a>解决hash冲突的方法</h4><pre><code> 通常解决hash冲突的方法有4种。（1）开放定址法，也称为线性探测法，就是从发生冲突的那个位置开始，按照一定的次序从hash表中找到一个空闲的位置，然后把发生冲突的元素存入到这个空闲位置中。ThreadLocal就用到了线性探测法来解决hash冲突的。在hash表索引1的位置存了一个key=name，当再次添加key=hobby时，hash计算得到的索引也是1，这个就是hash冲突。而开放定址法，就是按顺序向前找到一个空闲的位置来存储冲突的key。（2）链式寻址法，这是一种非常常见的方法，简单理解就是把存在hash冲突的key，以单向链表的方式来存储，比如HashMap就是采用链式寻址法来实现的。存在冲突的key直接以单向链表的方式进行存储。（3）再hash法，就是当通过某个hash函数计算的key存在冲突时，再用另外一个hash函数对这个key做hash，一直运算直到不再产生冲突。这种方式会增加计算时间，性能影响较大。（4）建立公共溢出区， 就是把hash表分为基本表和溢出表两个部分，凡是存在冲突的元素，一律放入到溢出表中。</code></pre><h3 id="3-HashMap链表转化为红黑树"><a href="#3-HashMap链表转化为红黑树" class="headerlink" title="3.HashMap链表转化为红黑树"></a>3.HashMap链表转化为红黑树</h3><pre><code>在Java的HashMap实现中，当哈希桶中的单链表长度超过一定阈值（默认为8），它会将这个链表转化为红黑树。这个策略是为了提高HashMap在处理大量元素时的性能，尤其是在高负载因子情况下（即哈希桶中元素数量相对于容量较多）。</code></pre><h3 id="4-HashMap-扩容因子："><a href="#4-HashMap-扩容因子：" class="headerlink" title="4.HashMap 扩容因子："></a>4.HashMap 扩容因子：</h3><pre><code> 为了在容量和性能之间实现平衡，HashMap 将加载因子设置为 0.75。这一设定旨在维持合适的容器大小，以兼顾性能和空间的最佳折中。 链表退化：当哈希表中的哈希碰撞（多个键被映射到相同的哈希桶位置）较多时，链表可能会变得很长，导致在查找元素时的性能下降。长链表的查找时间复杂度为 O(n)，其中n是链表的长度。当链表长度超过一定阈值时，它可能会退化为一个非常长的链表，因此需要一种更高效的数据结构。 红黑树效率：红黑树是一种自平衡的二叉搜索树，它的查找、插入和删除操作的时间复杂度是O(log n)，其中n是树的节点数。相比于长链表，红黑树更适合用于高负载的情况，因为它能够保持较低的时间复杂度。 防止DoS攻击：将链表转化为红黑树可以有效防止一些哈希碰撞导致的性能下降。攻击者可能会故意创建具有相同哈希值的键，以使它们都被放入同一个桶中，并且长链表会使查找时间变得非常长。通过将链表转化为红黑树，这些攻击会受到一定的限制，因为树的高度受到了控制。</code></pre><h3 id="5-HashMap-啥时候扩容，为什么扩容"><a href="#5-HashMap-啥时候扩容，为什么扩容" class="headerlink" title="5.HashMap 啥时候扩容，为什么扩容"></a>5.HashMap 啥时候扩容，为什么扩容</h3><pre><code> HashMap在元素数量达到阈值时会进行扩容。这个阈值通常是HashMap容量的0.75倍，也就是说，当HashMap中的元素数量超过了容量的75%时，就会触发扩容操作。 扩容的原因是为了减少哈希冲突，提高查询效率。当HashMap中的元素数量过多，哈希冲突的概率就会增大，这会导致查询效率降低。通过扩容，可以使得元素分布到更多的桶中，降低哈希冲突的概率，提高查询效率。 扩容的过程是这样的：首先，会创建一个新的数组，其容量是原数组的两倍，然后重新计算原数组中所有元素的哈希值，并将它们放入新的数组。这个过程需要一定的计算资源，因此扩容是一个相对耗时的操作。</code></pre>]]></content>
      
      
      <categories>
          
          <category> HashMap </category>
          
          <category> Map </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HashMap </tag>
            
            <tag> Map </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注解</title>
      <link href="/2018/03/17/java%E4%B8%AD%E6%B3%A8%E8%A7%A3/"/>
      <url>/2018/03/17/java%E4%B8%AD%E6%B3%A8%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>  注解.</p><a id="more"></a><h3 id="一Java定义的元注解："><a href="#一Java定义的元注解：" class="headerlink" title="一Java定义的元注解："></a>一Java定义的元注解：</h3><pre><code> java.lang.annotation 提供了四种元注解，专门注解其他的注解（在自定义注解的时候，需要使用到元注解）：        @Documented – 注解是否将包含在JavaDoc中        @Retention – 什么时候使用该注解        @Target – 注解用于什么地方        @Inherited – 是否允许子类继承该注解  @Target, @Retention, @Documented, @Inherited    这些类型和它们所支持的类在java.lang.annotation包中可以找到。  @Target：        @Target说明了Annotation所修饰的对象范围：Annotation可被用于 packages、types（类、接口、枚举、Annotation类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数和本地变量（如循环变量、catch参数）。在Annotation类型的声明中使用了target可更加明晰其修饰的目标。     作用：用于描述注解的使用范围（即：被描述的注解可以用在什么地方）           取值(ElementType)有：     　　　　1.CONSTRUCTOR:用于描述构造器     　　　　2.FIELD:用于描述域     　　　　3.LOCAL_VARIABLE:用于描述局部变量     　　　　4.METHOD:用于描述方法     　　　　5.PACKAGE:用于描述包     　　　　6.PARAMETER:用于描述参数     　　　　7.TYPE:用于描述类、接口(包括注解类型) 或enum声明  @Retention：        @Retention定义了该Annotation被保留的时间长短：某些Annotation仅出现在源代码中，而被编译器丢弃；而另一些却被编译在class文件中；编译在class文件中的Annotation可能会被虚拟机忽略，而另一些在class被装载时将被读取（请注意并不影响class的执行，因为Annotation与class在使用上是被分离的）。使用这个meta-Annotation可以对 Annotation的“生命周期”限制。          取值（RetentionPoicy）有：     　　　　1.SOURCE:在源文件中有效（即源文件保留）     　　　　2.CLASS:在class文件中有效（即class保留）     　　　　3.RUNTIME:在运行时有效（即运行时保留）  @Documented:        @Documented用于描述其它类型的annotation应该被作为被标注的程序成员的公共API，因此可以被例如javadoc此类的工具文档化。Documented是一个标记注解，没有成员。  @Inherited：        @Inherited 元注解是一个标记注解，@Inherited阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited修饰的annotation类型被用于一个class，则这个annotation将被用于该class的子类。        注意：@Inherited annotation类型是被标注过的class的子类所继承。类并不从它所实现的接口继承annotation，方法并不从它所重载的方法继承annotation。</code></pre><p>　　         </p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> 注解 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 注解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker基础</title>
      <link href="/2018/03/15/docker/"/>
      <url>/2018/03/15/docker/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Docker是一种虚拟化技术，它可以将应用程序及其所依赖的库、框架等打包到一个称为Docker镜像的文件中，使得应用程序可以在任何地方都能够快速、可靠地运行，而无需担心环境配置的问题。</p><a id="more"></a><h3 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h3><pre><code>1. yum包更新到最新sudo yum update2. 安装需要的软件包sudo yum install -y yum-utils device-mapper-persistent-data lvm23. 设置yum源为阿里云sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo4.安装docker-cesudo yum install docker-ce5.查看当前docker版本docker -v</code></pre><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><pre><code>在使用 Docker 时，应注意以下事项：  在部署 Docker 容器时，需要配置正确的端口映射等参数，以保证容器能够正常访问。  在使用 Docker 时，需要注意安全问题，通过配置合适的镜像源等方法提高安全性。  容器的版本需要和宿主机的版本匹配，否则可能会出现兼容性问题。  需要注意容器的网络连接，以确保容器内的应用程序能够正常访问外部资源。</code></pre><h3 id="安装常见文件处理解决"><a href="#安装常见文件处理解决" class="headerlink" title="安装常见文件处理解决"></a>安装常见文件处理解决</h3><pre><code>  1.Docker 无法启动      可能的原因：Docker 服务未启动或启动失败、内存不足等。      解决方案：      确认 Docker 服务已正确启动。      检查内存是否足够，可以尝试增加内存并重启 Docker。  2.Docker 容器无法访问外部网络      可能的原因：容器网络配置不正确、防火墙设置等。      解决方案：      确认容器网络配置是否正确，例如是否开启了端口映射等。      检查防火墙设置，确保容器能够正常连接外部网络。  3.无法使用 Docker 命令      可能的原因：未安装 Docker、未添加 Docker 用户等。      解决方案：      确认 Docker 是否正确安装，并检查 Docker 版本是否与当前系统版本兼容。      确认当前用户是否已被添加到 Docker 用户组中，若未添加，则使用以下命令将当前用户添加到 Docker 用户组中：      sudo usermod -aG docker &lt;your-user&gt;        注：&lt;your-user&gt;为当前登录的用户名。  5.镜像无法构建      可能的原因：Dockerfile 文件错误、网络问题等。      解决方案：      确认 Dockerfile 文件是否正确，可使用 docker build 命令进行构建并检查报错信息。      检查网络连接是否正常，尝试更换国内镜像源。</code></pre><h3 id="docker命令"><a href="#docker命令" class="headerlink" title="docker命令"></a>docker命令</h3><pre><code>启动容器：  docker start &lt;container-name&gt;停止容器：  docker stop &lt;container-name&gt;搜索镜像:  docker search &lt;image-name&gt;获取镜像:  docker pull &lt;image-name&gt;列出本地镜像:  docker images删除本地镜像:  docker rmi &lt;image-name&gt;构建镜像:  docker build -t &lt;image-name&gt; &lt;dockerfile-path&gt;  例如：docker build -t my-image:latest .推送镜像到远程仓库：  docker push &lt;image-name&gt;</code></pre><h3 id="Docker容器操作"><a href="#Docker容器操作" class="headerlink" title="Docker容器操作"></a>Docker容器操作</h3><pre><code>运行容器  docker run &lt;image-name&gt; [command]列出正在运行的容器  docker ps列出所有容器（包括已停止的）  docker ps -a停止容器  docker stop &lt;container-id&gt;启动已停止的容器  docker start &lt;container-id&gt;进入容器  docker exec -it &lt;container-id&gt; /bin/bash导出容器  docker export &lt;container-id&gt; &gt; &lt;file-name&gt;.tar删除容器  docker rm &lt;container-id&gt;</code></pre><h3 id="Docker仓库操作"><a href="#Docker仓库操作" class="headerlink" title="Docker仓库操作"></a>Docker仓库操作</h3><pre><code>登录到Docker Hub  docker login拉取镜像  docker pull &lt;image-name&gt;推送镜像  docker push &lt;image-name&gt;删除镜像  docker rmi &lt;image-name&gt;</code></pre><h3 id="Docker网络管理"><a href="#Docker网络管理" class="headerlink" title="Docker网络管理"></a>Docker网络管理</h3><h4 id="Docker容器网络模式"><a href="#Docker容器网络模式" class="headerlink" title="Docker容器网络模式"></a>Docker容器网络模式</h4><pre><code>Docker容器网络模式指的是容器与宿主机或其他容器之间相互通信的方式。Docker提供了多种不同的网络模式，包括以下几种：  bridge模式：默认的网络模式，所有容器共享一个网络命名空间。  host模式：容器使用宿主机网络命名空间，直接绑定宿主机的IP地址。  none模式：容器没有网络连接，只能通过管道等方式与宿主机通信。可以使用命令&quot;docker network ls&quot;列出当前系统中存在的网络列表。启动两个名为web1和web2的容器，并将它们加入到同一个自定义网络中：    docker network create my-net    docker run --name web1 --network my-net -d nginx    docker run --name web2 --network my-net -d nginx此时，在web1容器内部执行&quot;ping web2&quot;命令，就可以直接访问web2容器。这是因为Docker自带的DNS服务器已经自动将容器名称解析为对应的IP地址。在一个Docker Swarm集群中，创建一个名为my-overlay的overlay网络：    docker network create -d overlay my-overlay在该网络上启动两个服务，并设置它们的副本数为2：    docker service create --name my-web --network my-overlay --replicas 2 nginx    docker service create --name my-app --network my-overlay --replicas 2 my-app-image即可实现my-web容器和my-app容器之间的跨主机通信。除了自带的网络模式外，Docker还支持各种第三方网络插件，用于增强Docker容器网络功能。 以下是一些常见的网络插件：  Calico: 一个开源的、高性能的容器网络和安全性隔离网络插件，支持IP路由和BGP协议。  Flannel: 一个简单而轻量级的容器网络插件，以VXLAN或UDP方式实现容器之间的通信。  Weave Net: 一个面向容器的网络插件，通过虚拟网络的方式将Docker容器连接起来，支持自动发现和配置网络。  Cilium: 一个新一代的容器网络和安全性插件，可用于实现API层面的安全性和网络隔离。  Contiv: 一个企业级的网络插件，支持多个容器编排工具，并提供了网络控制和安全性管理的功能。  Canal: 一个基于Flannel和Calico的网络插件，用于构建Kubernetes集群。  Macvlan: 一种比较特殊的网络插件，可以使得容器直接绑定到宿主机的物理网络接口上，从而获得与宿主机相同的网络性能。  每种网络插件都有其各自的特点和优势，需要根据具体的场景和需求进行选择和配置。安装Calico：  curl -L https://docs.projectcalico.org/manifests/calico.yaml -o calico.yaml  kubectl apply -f calico.yaml将Docker容器绑定到Calico网络：  docker run --net=calico-net -d nginx</code></pre><h3 id="Docker存储管理"><a href="#Docker存储管理" class="headerlink" title="Docker存储管理"></a>Docker存储管理</h3><h4 id="Docker数据卷"><a href="#Docker数据卷" class="headerlink" title="Docker数据卷"></a>Docker数据卷</h4><pre><code>Docker数据卷是一种用于在Docker容器和主机之间共享文件和目录的机制，它使得容器中的数据持久化存储，并且可以在容器被删除后仍然保留下来。Docker数据卷有以下几个特点：  数据卷可以在容器创建时进行绑定，也可以在容器运行时动态创建。  在容器中使用数据卷时，数据卷对应的目录会被挂载到容器中，并且在容器内外部都可以访问。  可以为数据卷指定权限和用户组，以便实现更灵活的访问控制。  同一个数据卷可以被多个容器同时挂载，实现数据共享和协作。要对Docker数据卷进行管理，可以使用以下命令：  创建数据卷    使用&quot;-v&quot;参数指定宿主机目录映射到容器的目录：    docker run -d -v /path/to/hostdir:/path/to/containerdir image_name    使用&quot;docker volume create&quot;命令创建一个数据卷，并将其挂载到容器：    docker volume create myvolume    docker run -d -v myvolume:/path/to/containerdir image_name  查看数据卷    使用&quot;docker volume ls&quot;命令可以列出当前所有的数据卷。    $ docker volume ls    DRIVER              VOLUME NAME    local               myvolume    使用&quot;docker volume inspect&quot;命令可以查看指定数据卷的详细信息。     $ docker volume inspect myvolume      [          {              &quot;CreatedAt&quot;: &quot;2021-11-01T12:34:56+08:00&quot;,              &quot;Driver&quot;: &quot;local&quot;,              &quot;Labels&quot;: {},              &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/myvolume/_data&quot;,              &quot;Name&quot;: &quot;myvolume&quot;,              &quot;Options&quot;: {},              &quot;Scope&quot;: &quot;local&quot;          }      ]  删除数据卷    使用&quot;docker volume rm&quot;命令可以删除指定的数据卷。    docker volume rm myvolume</code></pre><h4 id="Docker数据卷容器"><a href="#Docker数据卷容器" class="headerlink" title="Docker数据卷容器"></a>Docker数据卷容器</h4><pre><code>  创建数据卷容器    使用&quot;docker run&quot;命令创建一个数据卷容器，同时指定其挂载的数据卷：    docker run -d -v /data --name datavolume ubuntu:latest  查看数据卷容器    使用&quot;docker ps&quot;命令可以列出当前所有的容器，包括数据卷容器。    $ docker ps    CONTAINER ID   IMAGE           COMMAND                  CREATED          STATUS          PORTS     NAMES    0123456789ab   ubuntu:latest   &quot;/bin/bash&quot;              10 minutes ago   Up 10 minutes             datavolume  删除数据卷容器    使用&quot;docker rm&quot;命令可以删除指定的容器。    docker rm datavolume</code></pre><h4 id="Docker存储驱动"><a href="#Docker存储驱动" class="headerlink" title="Docker存储驱动"></a>Docker存储驱动</h4><pre><code>  查看当前存储驱动    使用&quot;docker info&quot;命令可以查看当前Docker使用的存储驱动。    $ docker info | grep &#39;Storage Driver&#39;    Storage Driver: overlay2  更改存储驱动    停止Docker服务：    sudo systemctl stop docker     编辑Docker配置文件&quot;daemon.json&quot;：     sudo vi /etc/docker/daemon.json     在该文件中添加以下内容：        {            &quot;storage-driver&quot;: &quot;aufs&quot;        }  启动Docker服务：      sudo systemctl start docker</code></pre><h3 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h3><p>  Docker Compose是一个用于定义和运行多容器Docker应用程序的工具。通过使用Docker Compose，可以利用YAML文件定义各个容器之间的依赖关系、共享卷等信息，然后使用简单的命令启动、停止和管理这些容器。</p><h4 id="Docker-Compose文件结构"><a href="#Docker-Compose文件结构" class="headerlink" title="Docker Compose文件结构"></a>Docker Compose文件结构</h4><pre><code>Docker Compose文件是一个YAML文件，包含了Docker Compose服务的配置信息，它通常包括以下几个主要部分：    version: 指定Compose文件格式的版本。    services: 定义每个服务的配置信息，包括映像名称、容器名称、端口映射、环境变量、共享卷等。    networks: 定义Docker网络的配置信息，包括网络名称、IP地址范围、子网掩码等。    volumes: 定义共享卷的配置信息，包括名称、驱动程序类型、选项等。  version: 指定Compose文件格式的版本。  services: 定义每个服务的配置信息，包括映像名称、容器名称、端口映射、环境变量、共享卷等。  networks: 定义Docker网络的配置信息，包括网络名称、IP地址范围、子网掩码等。  volumes: 定义共享卷的配置信息，包括名称、驱动程序类型、选项等。  build: 指定构建镜像时使用的Dockerfile路径。  image: 指定使用的镜像名称。</code></pre><h3 id="Docker-Swarm"><a href="#Docker-Swarm" class="headerlink" title="Docker Swarm"></a>Docker Swarm</h3><p>  Docker Swarm是Docker原生的集群管理工具，可以让我们轻松创建和管理跨越多个主机的Docker容器集群。它通过将多个Docker守护进程连接起来，形成一个虚拟的Docker引擎，从而允许用户在集群中启动、终止和管理应用程序。</p><h4 id="Docker-Swarm集群搭建"><a href="#Docker-Swarm集群搭建" class="headerlink" title="Docker Swarm集群搭建"></a>Docker Swarm集群搭建</h4><p>   步骤1：安装Docker<br>    curl -fsSL <a href="https://get.docker.com" target="_blank" rel="noopener">https://get.docker.com</a> -o get-docker.sh<br>    sudo sh get-docker.sh<br>   步骤2：创建Swarm Manager节点<br>    docker swarm init –advertise-addr <MANAGER_IP><br>   步骤3：加入Worker节点<br>    docker swarm join –token <TOKEN> <MANAGER_IP>:2377<br>   步骤4：创建服务<br>    docker service create –replicas 3 –name web nginx:latest<br>   步骤5：扩展服务<br>    docker service update –replicas 5 web</p><h3 id="Docker安全"><a href="#Docker安全" class="headerlink" title="Docker安全"></a>Docker安全</h3><h4 id="Docker安全策略"><a href="#Docker安全策略" class="headerlink" title="Docker安全策略"></a>Docker安全策略</h4><pre><code>Docker作为一种虚拟化技术，主要有以下几个安全隐患：    镜像安全：Docker镜像可能包含恶意代码或漏洞，导致安全问题。    进程间隔离：容器之间的进程隔离可能会被攻击者破坏，从而突破容器的安全隔离。    特权访问：容器中的特权访问可能遭到滥用，攻击者可以通过它来获得主机上的root权限。为了保护Docker环境的安全性，我们需要采取一些措施来加强Docker的安全性。这些措施包括：    安全镜像管理：使用安全的基础镜像、周期性地更新镜像并且验证镜像来源。    限制容器资源：控制容器对CPU、内存、网络等资源的访问，从而防止恶意容器消耗过多的系统资源。    限制特权访问：禁用容器中的特权模式，并限制容器的文件系统访问权限。    网络隔离：使用Docker的网络隔离功能，将容器与主机和其他容器隔离开来，限制容器之间的通信。</code></pre><h4 id="Docker权限管理"><a href="#Docker权限管理" class="headerlink" title="Docker权限管理"></a>Docker权限管理</h4><pre><code>Docker提供了一些权限控制机制，可以帮助我们限制用户对Docker的访问和操作。这些机制包括：    用户组：将用户添加到&quot;docker&quot;用户组中，可以允许他们在不使用sudo的情况下运行Docker命令。    访问控制列表（ACL）：使用ACL可以对Docker API进行细粒度的权限控制，从而限制用户对Docker的操作。    SELinux和AppArmor：这两种安全模块可以帮助我们进一步限制容器的文件系统和进程访问权限。</code></pre><h4 id="Docker网络安全"><a href="#Docker网络安全" class="headerlink" title="Docker网络安全"></a>Docker网络安全</h4><pre><code>Docker网络是Docker生态系统的重要组成部分，但它也存在着一些安全问题。以下是一些限制Docker网络安全的实践：    使用与主机不同的网络：默认情况下，Docker容器使用和主机相同的网络，在许多情况下，这可能会增加攻击面。因此，最好使用与主机不同的网络。    控制容器之间的通信：可以使用Docker的网络隔离功能，限制容器之间的通信。例如，我们可以使用&quot;docker network create&quot;命令创建一个自定义网络，并使用&quot;--internal&quot;选项禁用容器之间的外部通信。    限制端口映射：将容器内部端口映射到主机端口是非常方便的，但也会增加安全风险。最好只映射必要的端口，而不是将所有端口都映射到主机上。</code></pre><h3 id="Docker高级应用案例"><a href="#Docker高级应用案例" class="headerlink" title="Docker高级应用案例"></a>Docker高级应用案例</h3><h4 id="Docker化Web应用"><a href="#Docker化Web应用" class="headerlink" title="Docker化Web应用"></a>Docker化Web应用</h4><pre><code>创建Dockerfile    在项目根目录中创建一个名为Dockerfile的文件，其内容如下：    FROM node:latest    WORKDIR /app    COPY . .    RUN npm install    EXPOSE 3000    CMD [&quot;npm&quot;, &quot;start&quot;]  该Dockerfile使用Node.js作为基础镜像，并将应用程序复制到工作目录/app中，并运行npm install安装所有依赖项。然后它暴露3000端口并通过npm start命令启动应用程序。构建镜像  在项目根目录中运行以下命令构建镜像：  docker build -t my-web-app .运行容器  docker run -p 3000:3000 -d my-web-app 该命令将启动一个名为&quot;my-web-app&quot;的容器，并将主机的3000端口映射到容器的3000端口上。在浏览器中通过localhost:3000访问您的Web应用程序。</code></pre>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集合</title>
      <link href="/2018/03/06/%E9%9B%86%E5%90%88/"/>
      <url>/2018/03/06/%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><pre><code>在Java中，集合是一种非常重要的数据结构，用于存储一组元素。</code></pre><hr><h3 id="集合框架"><a href="#集合框架" class="headerlink" title="集合框架"></a>集合框架</h3><p><img src="/image/%E9%9B%86%E5%90%88.png" alt="效果图预览"></p><h3 id="集合简介"><a href="#集合简介" class="headerlink" title="集合简介"></a>集合简介</h3><p>  （1）集合有两个父接口 Collection、Map<br>  （2）Collection有两个子接口 List、set<br>  （3）List有两个常见的实现类 ArrayList、LinkedList<br>  （4）Set有两个常见的实现类 HashSet、TreeSet<br>  （5）Map有两个常见的实现类 HashMap、HashTable</p><h3 id="不同集合的特点"><a href="#不同集合的特点" class="headerlink" title="不同集合的特点"></a>不同集合的特点</h3><p>   （1）List             特点：有序、可重复<br>   （2）Set              特点：无序、不可重复<br>   （3）Collection       特点：无序、可重复<br>   （4）Map              特点：无序，不可重复，存放【键值对】（key 键 – value 值）</p><h3 id="Fail-safe和Fail-fast"><a href="#Fail-safe和Fail-fast" class="headerlink" title="Fail-safe和Fail-fast"></a>Fail-safe和Fail-fast</h3><pre><code>Fail-fast ： 表示快速失败，在集合遍历过程中，一旦发现容器中的数据被修改了，会立刻抛出ConcurrentModificationException异常，从而导致遍历失败。java.util包下的集合类都是快速失败机制的。Fail-safe：表示失败安全，也就是在这种机制下，出现集合元素的修改，不会抛出ConcurrentModificationException。原因是采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，常见的的使用Fail-safe方式遍历的容器有ConcerrentHashMap和CopyOnWriteArrayList等。</code></pre><h3 id="Arraylist-的去重机制"><a href="#Arraylist-的去重机制" class="headerlink" title="Arraylist 的去重机制"></a>Arraylist 的去重机制</h3><pre><code>contains判断去重(有序)迭代器去重(无序)HashSet去重(无序)LinkedHashSet去重(有序)TreeSet去重(无序)Stream去重(有序)</code></pre><h3 id="流"><a href="#流" class="headerlink" title="流"></a>流</h3><p>  从支持数据处理操作的源生成元素序列.数据源可以是集合,数组或IO资源。</p><p>  从操作角度来看,流与集合是不同的. 流不存储数据值; 流的目的是处理数据,它是关于算法与计算的。</p><p>  Stream可以由数组或集合创建，对流的操作分为两种：<br>    中间操作，每次返回一个新的流，可以有多个。<br>    终端操作，每个流只能进行一次终端操作，终端操作结束后流无法再次使用。终端操作会产生一个新的集合或值。</p><h3 id="流的分类"><a href="#流的分类" class="headerlink" title="流的分类"></a>流的分类</h3><p> <img src="/image/%E6%B5%81.png" alt="效果图预览">  </p>]]></content>
      
      
      <categories>
          
          <category> 集合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos7上搭建ftp</title>
      <link href="/2017/09/25/Centos7%E4%B8%8A%E6%90%AD%E5%BB%BAftp/"/>
      <url>/2017/09/25/Centos7%E4%B8%8A%E6%90%AD%E5%BB%BAftp/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>  记录一次在centos服务器上搭建ftp过程。</p><a id="more"></a><h3 id="第一步：使用xshell连上远程服务器，安装vsftp"><a href="#第一步：使用xshell连上远程服务器，安装vsftp" class="headerlink" title="第一步：使用xshell连上远程服务器，安装vsftp"></a>第一步：使用xshell连上远程服务器，安装vsftp</h3><pre><code> yum install -y vsftpd</code></pre><h3 id="第二步：设置开机启动"><a href="#第二步：设置开机启动" class="headerlink" title="第二步：设置开机启动"></a>第二步：设置开机启动</h3><pre><code> systemctl enable vsftpd</code></pre><h3 id="第三步：启动ftp服务"><a href="#第三步：启动ftp服务" class="headerlink" title="第三步：启动ftp服务"></a>第三步：启动ftp服务</h3><pre><code>   systemctl start vsftpd.service</code></pre><h3 id="第四步：打开防火墙"><a href="#第四步：打开防火墙" class="headerlink" title="第四步：打开防火墙"></a>第四步：打开防火墙</h3><pre><code> firewall-cmd --zone=public --add-port=21/tcp --permanent firewall-cmd --permanent --zone=public --add-service=ftp firewall-cmd --reload</code></pre><h3 id="第五步：添加用户"><a href="#第五步：添加用户" class="headerlink" title="第五步：添加用户"></a>第五步：添加用户</h3><pre><code> useradd -g root -d /home/data -s /sbin/nologin test 新建test用户 添加到root组 但是不允许用户登录，仅仅可以ftp登录 ftp登录后的默认目录是/home/data</code></pre><h3 id="第六步：设置用户密码"><a href="#第六步：设置用户密码" class="headerlink" title="第六步：设置用户密码"></a>第六步：设置用户密码</h3><pre><code>passwd test</code></pre><h3 id="第七步：设置权限"><a href="#第七步：设置权限" class="headerlink" title="第七步：设置权限"></a>第七步：设置权限</h3><pre><code> chown -R test:root /home/data setsebool -P ftpd_full_access on</code></pre><h3 id="第八步：修改vsftp配置文件，禁止匿名登录"><a href="#第八步：修改vsftp配置文件，禁止匿名登录" class="headerlink" title="第八步：修改vsftp配置文件，禁止匿名登录"></a>第八步：修改vsftp配置文件，禁止匿名登录</h3><pre><code> vi /etc/vsftpd/vsftpd.conf 把：anonymous_enable=YES 改为： anonymous_enable=NO 输入---&gt; :wq! 保存退出</code></pre><h3 id="第九步：在本地电脑上按下win-R键，输入cmd，进入命令行"><a href="#第九步：在本地电脑上按下win-R键，输入cmd，进入命令行" class="headerlink" title="第九步：在本地电脑上按下win+R键，输入cmd，进入命令行"></a>第九步：在本地电脑上按下win+R键，输入cmd，进入命令行</h3><p><img src="/image/ftp.jpg" alt="效果图预览"></p><pre><code>  输入ftp、输入open命令 ，输入ftp服务器地址，输入登录名，密码。回车。 出现 230 Login successful.表示ftp服务器搭建成功。</code></pre>]]></content>
      
      
      <categories>
          
          <category> ftp </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ftp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>log4j日志管理</title>
      <link href="/2017/09/21/log4j%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"/>
      <url>/2017/09/21/log4j%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>log4j是java主流的日志框架，在线上生产环境下，有很多问题都是通过查看日志发觉的，日志的重要性不言而喻。</p><h3 id="1、log4j说明"><a href="#1、log4j说明" class="headerlink" title="1、log4j说明"></a>1、log4j说明</h3><p> log4j提供各种类型，各种存储，各种格式，多样化的日志服务。Log4j根据日志信息的重要程度，分OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL这7类。一般只使用其中的4个级别，优先级从高到低分别是 ERROR、WARN、INFO、DEBUG。日志配置的级别较高，就不会把低级别的日志打印出来。比如配置的日志级别是ERROR，就不会将WARN、INFO、DEBUG级别的日志打印出来。</p><h3 id="2、引入依赖"><a href="#2、引入依赖" class="headerlink" title="2、引入依赖"></a>2、引入依赖</h3><p> 在pom.xml文件中引入依赖<br><dependency><br>    <groupId>log4j</groupId><br>    <artifactId>log4j</artifactId><br>    <version>1.2.17</version><br></dependency></p><h3 id="2、新建文件log4j-properties"><a href="#2、新建文件log4j-properties" class="headerlink" title="2、新建文件log4j.properties"></a>2、新建文件log4j.properties</h3><p>在项目resources目录下新建一个文件log4j.properties。将配置放入文件中</p><p>log4j.rootLogger=DEBUG, Console ,FIEL ,DailyRollingFile ,RollingFile #Console log4j.appender.Console=org.apache.log4j.ConsoleAppender log4j.appender.Console.layout=org.apache.log4j.TTCCLayout #FIEL log4j.appender.FIEL = org.apache.log4j.FileAppender log4j.appender.FIEL.File = D://WorkProject//SpringBoot//logs//log.log log4j.appender.FIEL.layout = org.apache.log4j.PatternLayout log4j.appender.FIEL.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n #DailyRollingFile log4j.appender.DailyRollingFile = org.apache.log4j.DailyRollingFileAppender log4j.appender.DailyRollingFile.File = D://WorkProject//SpringBoot//logs//springbootcrud-log.log log4j.appender.DailyRollingFile.layout = org.apache.log4j.PatternLayout log4j.appender.DailyRollingFile.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n #RollingFile log4j.appender.RollingFile = org.apache.log4j.RollingFileAppender log4j.appender.RollingFile.File = D://WorkProject//SpringBoot//logs//springbootcrud-date.log log4j.appender.RollingFile.MaxFileSize=100KB log4j.appender.RollingFile.MaxBackupIndex=10 log4j.appender.RollingFile.layout = org.apache.log4j.PatternLayout log4j.appender.RollingFile.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n</p><p>说明：<br>   log4j.rootLogger中DEBUG代表配置的日志级别是DEBUG。<br>   log4j.appender.FIEL.File 中的配置代表日志输出到那个文件下<br>   log4j.appender.DailyRollingFile.File中的配置代表每天的日志输出到那个文件下（主要是为了防止文件日志太大）<br>   log4j.appender.RollingFile.File中的配置代表如果日志文件超过了设定的值，日志输出到那个文件下。</p><h3 id="3、代码中使用log4j"><a href="#3、代码中使用log4j" class="headerlink" title="3、代码中使用log4j"></a>3、代码中使用log4j</h3><p>在代码中使用日志，在要使用日志的类中定义日志变量。<br>private static Logger logger=Logger.getLogger(PersonController.class);</p><p>说明：<br>    PersonController是类名。</p><p>在要打印日志的地方调用日志类的方法输出日志<br>    logger.info(“普通Info信息”); logger.debug(“调试debug信息”); logger.error(“报错error信息”); logger.warn(“警告warn信息”); logger.fatal(“严重错误fatal信息”);</p><h3 id="4、效果图"><a href="#4、效果图" class="headerlink" title="4、效果图"></a>4、效果图</h3><p><img src="/image/log4j.png" alt="效果图预览"></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> 插件 </category>
          
          <category> log4j </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 插件 </tag>
            
            <tag> log4j </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分页插件pagehelper的使用</title>
      <link href="/2017/09/15/%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6pagehelper%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2017/09/15/%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6pagehelper%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><p>在java开发的过程中，我们经常会查询列表数据。但是不可能将所有的数据都查询出来，都查询出来，对服务器的内存是很大的浪费，其次，页面上也不需要一次性展示这么多数据。通常我们会在查询语句里边拼接分页sql,这样做虽然能解决分页问题，但是拼接sql，sql语句显得极其凌乱。更重要的是，如果因为参数问题，拼接的sql极有可能不是我们想要的sql,执行时会报错。分页插件pagehelper很好的解决了这一问题，并且使用起来也很简单。</p><h3 id="1、引入依赖"><a href="#1、引入依赖" class="headerlink" title="1、引入依赖"></a>1、引入依赖</h3><p> 在pom.xml文件中引入依赖<br><dependency><br>   <groupId>com.github.pagehelper</groupId><br>   <artifactId>pagehelper</artifactId><br>   <version>5.1.2</version><br></dependency></p><h3 id="2、使用PageHelper"><a href="#2、使用PageHelper" class="headerlink" title="2、使用PageHelper"></a>2、使用PageHelper</h3><p>在service类中执行查询语句时将PageHelper插件引入。<br>    public PageInfo selectPersonAll(Integer pageNum, Integer pageSize) {<br>        PageHelper.startPage(pageNum,pageSize);<br>        List<Person> list =personDao.selectPersonAll();<br>        PageInfo pageInfo = new PageInfo(list);<br>        return pageInfo;<br>    }</p><p>在执行查询语句时，先执行一句PageHelper.startPage(pageNum,pageSize);<br>pageNum为当前页，pageSize为每页要显示的数据量，执行了该语句后会默认对下一句查询语句分页。</p><p>List<Person> list =personDao.selectPersonAll();//调用dao层执行查询语句。<br>PageInfo pageInfo = new PageInfo(list);//将查询的语句放入PageInfo中，PageInfo会将分页参数那些全部计算好返回，无需自己在计算。PageInfo 是PageHelper中自带的类。</p><p>dao层代码：<br>    public interface PersonDao {<br>    List<Person> selectPersonAll();<br>    }</p><p>mapper文件中sql:<br>    <select id="selectPersonAll" resultType="com.example.business.person.entity.Person"><br>        select * from T_PERSON<br>    </select></p><h3 id="3、PageHelper中PageInfo类说明"><a href="#3、PageHelper中PageInfo类说明" class="headerlink" title="3、PageHelper中PageInfo类说明"></a>3、PageHelper中PageInfo类说明</h3><p>PageHelper中PageInfo类说明：<br>    public class PageInfo<T> implements Serializable {<br>        private static final long serialVersionUID = 1L;<br>        //当前页<br>        private int pageNum;<br>        //每页的数量<br>        private int pageSize;<br>        //当前页的数量<br>        private int size;<br>        //当前页面第一个元素在数据库中的行号<br>        private int startRow;<br>        //当前页面最后一个元素在数据库中的行号<br>        private int endRow;<br>        //总记录数<br>        private long total;<br>        //总页数<br>        private int pages;<br>        //结果集<br>        private List<T> list;<br>        //前一页<br>        private int prePage;<br>        //下一页<br>        private int nextPage;<br>        //是否为第一页<br>        private boolean isFirstPage = false;<br>        //是否为最后一页<br>        private boolean isLastPage = false;<br>        //是否有前一页<br>        private boolean hasPreviousPage = false;<br>        //是否有下一页<br>        private boolean hasNextPage = false;<br>        //导航页码数<br>        private int navigatePages;<br>        //所有导航页号<br>        private int[] navigatepageNums;<br>        //导航条上的第一页<br>        private int navigateFirstPage;<br>        //导航条上的最后一页<br>        private int navigateLastPage;<br>    }</p><p>数据存放在list中，前台可通过el表达式或其他方式将数据取出展示。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> 插件 </category>
          
          <category> pagehelper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 插件 </tag>
            
            <tag> pagehelpe </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot中集成swagger</title>
      <link href="/2017/09/09/SpringBoot%E4%B8%AD%E9%9B%86%E6%88%90swagger/"/>
      <url>/2017/09/09/SpringBoot%E4%B8%AD%E9%9B%86%E6%88%90swagger/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>swagger主要是用来解决实际接口与接口文档不一致问题。因为需求变动或者一些其他的原因导致后台接口出现了变动，但是却没有及时的更新接口文档，调用方拿到的文档不是最新的文档。swagger能够根据后台接口实时生成文档。</p><a id="more"></a><h3 id="1、新建springboot项目"><a href="#1、新建springboot项目" class="headerlink" title="1、新建springboot项目"></a>1、新建springboot项目</h3><p> 新建一个springboot项目，在pom.xml文件中增加swagger的依赖。<br><dependency><br><groupId>io.springfox</groupId><br><artifactId>springfox-swagger2</artifactId><br><version>2.6.1</version><br></dependency><br><dependency><br><groupId>io.springfox</groupId><br><artifactId>springfox-swagger-ui</artifactId><br><version>2.6.1</version><br></dependency></p><h3 id="2、新建swagger配置类"><a href="#2、新建swagger配置类" class="headerlink" title="2、新建swagger配置类"></a>2、新建swagger配置类</h3><pre><code>@Configuration@EnableSwagger2public class SwaggerConfig {    @Bean    public Docket api() {        return new Docket(DocumentationType.SWAGGER_2)        .apiInfo(apiInfo())        .select()        .apis(RequestHandlerSelectors.basePackage(&quot;com.example&quot;))        .paths(PathSelectors.any())        .build();    }    private ApiInfo apiInfo() {        return new ApiInfoBuilder()        .title(&quot;Springboot使用swagger在线文档&quot;)        .description(&quot;swagger UI接入教程&quot;)        .version(&quot;1.0&quot;)        .build();    }}</code></pre><h3 id="3、接口上加上注解ApiOperation"><a href="#3、接口上加上注解ApiOperation" class="headerlink" title="3、接口上加上注解ApiOperation"></a>3、接口上加上注解ApiOperation</h3><pre><code>修改接口，在接口上加上注解ApiOperation，接口修改后如下。@ApiOperation(value = &quot;获取所有人员信息接口(分页)&quot;,notes = &quot;获取所有人员信息接口(分页)&quot;)@RequestMapping(value =&quot;/selectPersonAll&quot;, method = RequestMethod.GET)public PageInfo selectPersonAll(@RequestParam Integer pageNum, @RequestParam Integer pageSize){    return personService.selectPersonAll(pageNum,pageSize);}</code></pre><h3 id="4、重启项目"><a href="#4、重启项目" class="headerlink" title="4、重启项目"></a>4、重启项目</h3><p>重启项目，在浏览器地址栏中输入项目地址，在加上/swagger-ui.html，点击回车。就能够看到对应的接口文档了，还可以直接在页面中测试接口。<br><img src="/image/swagger.png" alt="效果图预览"></p>]]></content>
      
      
      <categories>
          
          <category> springboot </category>
          
          <category> swagger </category>
          
      </categories>
      
      
        <tags>
            
            <tag> springboot </tag>
            
            <tag> swagger </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux</title>
      <link href="/2017/07/17/linux%E4%B8%8B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2017/07/17/linux%E4%B8%8B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><a id="more"></a><h3 id="1-linux下重启oracle服务步骤："><a href="#1-linux下重启oracle服务步骤：" class="headerlink" title="1.linux下重启oracle服务步骤："></a>1.linux下重启oracle服务步骤：</h3><pre><code> 1.使用Xshell连接linux服务器。 2.以oracle身份登录数据库，命令：su – oracle 3.进入Sqlplus控制台，命令：sqlplus /nolog 4.以系统管理员登录，命令：connect / as sysdba 5.关闭数据库，命令：shutdown immediate 6.退出sqlplus控制台，命令：exithexO 7.进入监听器控制台，命令：lsnrctl 8.启动监听器，命令：start 9.退出监听器控制台，命令：exit</code></pre><h3 id="2-linux下日志查找："><a href="#2-linux下日志查找：" class="headerlink" title="2.linux下日志查找："></a>2.linux下日志查找：</h3><pre><code>cat 文件名|grep &#39;关键字&#39;</code></pre><h3 id="3-windows下关闭占用端口的进程："><a href="#3-windows下关闭占用端口的进程：" class="headerlink" title="3.windows下关闭占用端口的进程："></a>3.windows下关闭占用端口的进程：</h3><pre><code>netstat -aon|findstr &quot;端口&quot;tasklist|findstr &quot;pid&quot;</code></pre><h3 id="4-windows下使用telnet："><a href="#4-windows下使用telnet：" class="headerlink" title="4.windows下使用telnet："></a>4.windows下使用telnet：</h3><pre><code> win + R 进入命令行窗口 telnet 127.0.0.1 10001    ctrl + ]    send 数据</code></pre><h3 id="5-端口"><a href="#5-端口" class="headerlink" title="5.端口"></a>5.端口</h3><pre><code>0 – 1023： 常用端口和系统端口1024 – 49151： 软件的注册端口49152 – 65535： 动态端口或私有端口</code></pre><h4 id="5-1-使用-ss-命令"><a href="#5-1-使用-ss-命令" class="headerlink" title="5.1 使用 ss 命令"></a>5.1 使用 ss 命令</h4><pre><code># ss -tnlp | grep sshLISTEN 0 128 *:22 *:* users:((&quot;sshd&quot;,pid=997,fd=3))LISTEN 0 128 :::22 :::* users:((&quot;sshd&quot;,pid=997,fd=4))# ss -tnlp | grep &quot;:22&quot;LISTEN 0 128 *:22 *:* users:((&quot;sshd&quot;,pid=997,fd=3))LISTEN 0 128 :::22 :::* users:((&quot;sshd&quot;,pid=997,fd=4))</code></pre><h4 id="5-2使用-netstat-命令"><a href="#5-2使用-netstat-命令" class="headerlink" title="5.2使用 netstat 命令"></a>5.2使用 netstat 命令</h4><pre><code># netstat -tnlp | grep sshtcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 997/sshdtcp6 0 0 :::22 :::* LISTEN 997/sshd# netstat -tnlp | grep &quot;:22&quot;tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1208/sshdtcp6 0 0 :::22 :::* LISTEN 1208/sshd</code></pre><h4 id="5-3使用-lsof-命令"><a href="#5-3使用-lsof-命令" class="headerlink" title="5.3使用 lsof 命令"></a>5.3使用 lsof 命令</h4><pre><code># lsof -i -P | grep sshCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 11584 root 3u IPv4 27625 0t0 TCP *:22 (LISTEN)sshd 11584 root 4u IPv6 27627 0t0 TCP *:22 (LISTEN)sshd 11592 root 3u IPv4 27744 0t0 TCP vps.2daygeek.com:ssh-&gt;103.5.134.167:49902 (ESTABLISHED)# lsof -i tcp:22COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 1208 root 3u IPv4 20919 0t0 TCP *:ssh (LISTEN)sshd 1208 root 4u IPv6 20921 0t0 TCP *:ssh (LISTEN)sshd 11592 root 3u IPv4 27744 0t0 TCP vps.2daygeek.com:ssh-&gt;103.5.134.167:49902 (ESTABLISHED)</code></pre><h4 id="5-4使用-fuser-命令"><a href="#5-4使用-fuser-命令" class="headerlink" title="5.4使用 fuser 命令"></a>5.4使用 fuser 命令</h4><pre><code># fuser -v 22/tcpUSER PID ACCESS COMMAND22/tcp: root 1208 F.... sshdroot 12388 F.... sshdroot 49339 F.... sshd</code></pre><h4 id="5-5使用-nmap-命令"><a href="#5-5使用-nmap-命令" class="headerlink" title="5.5使用 nmap 命令"></a>5.5使用 nmap 命令</h4><pre><code># nmap -sV -p 22 localhostStarting Nmap 6.40 ( http://nmap.org ) at 2018-09-23 12:36 ISTNmap scan report for localhost (127.0.0.1)Host is up (0.000089s latency).Other addresses for localhost (not scanned): 127.0.0.1PORT STATE SERVICE VERSION22/tcp open ssh OpenSSH 7.4 (protocol 2.0)Service detection performed. Please report any incorrect results at http://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 0.44 seconds</code></pre><h4 id="5-6使用-systemctl-命令"><a href="#5-6使用-systemctl-命令" class="headerlink" title="5.6使用 systemctl 命令"></a>5.6使用 systemctl 命令</h4><pre><code># systemctl status sshd● sshd.service - OpenSSH server daemonLoaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled)Active: active (running) since Sun 2018-09-23 02:08:56 EDT; 6h 11min agoDocs: man:sshd(8)man:sshd_config(5)Main PID: 11584 (sshd)CGroup: /system.slice/sshd.service└─11584 /usr/sbin/sshd -DSep 23 02:08:56 vps.2daygeek.com systemd[1]: Starting OpenSSH server daemon...Sep 23 02:08:56 vps.2daygeek.com sshd[11584]: Server listening on 0.0.0.0 port 22.Sep 23 02:08:56 vps.2daygeek.com sshd[11584]: Server listening on :: port 22.Sep 23 02:08:56 vps.2daygeek.com systemd[1]: Started OpenSSH server daemon.Sep 23 02:09:15 vps.2daygeek.com sshd[11589]: Connection closed by 103.5.134.167 port 49899 [preauth]Sep 23 02:09:41 vps.2daygeek.com sshd[11592]: Accepted password for root from 103.5.134.167 port 49902 ssh2</code></pre><h3 id="6-阅读文件"><a href="#6-阅读文件" class="headerlink" title="6.阅读文件"></a>6.阅读文件</h3><p>   less和more命令用于在 Linux 中查看文件的内容，而不必完全打开文件。它们用来逐一查看文件的一部分，使开发者更容易阅读大型文件。</p><pre><code>    less：可以使用箭头键滚动文件，并随时退出。    more：类似于 less，它也只显示一屏文本。可以通过按空格键转到下一屏，并在完成后退出。这两个命令在想快速检查文件内容而无需立即阅读整个内容时很有用。</code></pre><h3 id="7-创建和编辑文件"><a href="#7-创建和编辑文件" class="headerlink" title="7.创建和编辑文件"></a>7.创建和编辑文件</h3><pre><code>touch命令仅执行一项任务 -您创建空文件。另一方面，nano更像是一个文本编辑器。它不仅创建文件，还支持在那里写入和编辑文件内容。因此，touch可以提供一个空文件，而nano进一步允许在该文件中添加和修改文本。</code></pre><h3 id="8-文件和查找命令"><a href="#8-文件和查找命令" class="headerlink" title="8.文件和查找命令"></a>8.文件和查找命令</h3><p>   grep “keyword” filename</p><p>   grep -r “keyword” /path/to/search</p><h3 id="9-查看本机Ip"><a href="#9-查看本机Ip" class="headerlink" title="9.查看本机Ip"></a>9.查看本机Ip</h3><p>   curl ifconfig.me</p><h3 id="10-内存溢出"><a href="#10-内存溢出" class="headerlink" title="10.内存溢出"></a>10.内存溢出</h3><pre><code>grep &quot;Out of memory&quot; /var/log/messagesegrep -i -r &#39;killed process&#39; /var/log</code></pre>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
          <category> centos </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos </tag>
            
            <tag> linux </tag>
            
            <tag> oracle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>过滤器和拦截器</title>
      <link href="/2017/06/15/%E8%BF%87%E6%BB%A4%E5%99%A8%E5%92%8C%E6%8B%A6%E6%88%AA%E5%99%A8/"/>
      <url>/2017/06/15/%E8%BF%87%E6%BB%A4%E5%99%A8%E5%92%8C%E6%8B%A6%E6%88%AA%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><h3 id="过滤器-Filter"><a href="#过滤器-Filter" class="headerlink" title="过滤器 (Filter)"></a>过滤器 (Filter)</h3><pre><code>过滤器的配置比较简单，直接实现Filter 接口即可，也可以通过@WebFilter注解实现对特定URL拦截，看到Filter 接口中定义了三个方法。init() ：该方法在容器启动初始化过滤器时被调用，它在 Filter 的整个生命周期只会被调用一次。注意：这个方法必须执行成功，否则过滤器会不起作用。doFilter() ：容器中的每一次请求都会调用该方法， FilterChain 用来调用下一个过滤器 Filter。destroy()： 当容器销毁 过滤器实例时调用该方法，一般在方法中销毁或关闭资源，在过滤器 Filter 的整个生命周期也只会被调用一次</code></pre><h3 id="拦截器-Interceptor"><a href="#拦截器-Interceptor" class="headerlink" title="拦截器 (Interceptor)"></a>拦截器 (Interceptor)</h3><pre><code>拦截器它是链式调用，一个应用中可以同时存在多个拦截器Interceptor， 一个请求也可以触发多个拦截器 ，而每个拦截器的调用会依据它的声明顺序依次执行。首先编写一个简单的拦截器处理类，请求的拦截是通过HandlerInterceptor 来实现，看到HandlerInterceptor 接口中也定义了三个方法。preHandle() ：这个方法将在请求处理之前进行调用。注意：如果该方法的返回值为false ，将视为当前请求结束，不仅自身的拦截器会失效，还会导致其他的拦截器也不再执行。postHandle()：只有在 preHandle() 方法返回值为true 时才会执行。会在Controller 中的方法调用之后，DispatcherServlet 返回渲染视图之前被调用。 有意思的是：postHandle() 方法被调用的顺序跟 preHandle() 是相反的，先声明的拦截器 preHandle() 方法先执行，而postHandle()方法反而会后执行。afterCompletion()：只有在 preHandle() 方法返回值为true 时才会执行。在整个请求结束之后， DispatcherServlet 渲染了对应的视图之后执行。</code></pre><h3 id="过滤器和拦截器不同"><a href="#过滤器和拦截器不同" class="headerlink" title="过滤器和拦截器不同"></a>过滤器和拦截器不同</h3><h4 id="实现原理不同"><a href="#实现原理不同" class="headerlink" title="实现原理不同"></a>实现原理不同</h4><pre><code>过滤器和拦截器 底层实现方式大不相同，过滤器 是基于函数回调的，拦截器 则是基于Java的反射机制（动态代理）实现的。</code></pre><h4 id="使用范围不同"><a href="#使用范围不同" class="headerlink" title="使用范围不同"></a>使用范围不同</h4><pre><code>过滤器 实现的是 javax.servlet.Filter 接口，而这个接口是在Servlet规范中定义的，也就是说过滤器Filter 的使用要依赖于Tomcat等容器，导致它只能在web程序中使用。拦截器(Interceptor) 它是一个Spring组件，并由Spring容器管理，并不依赖Tomcat等容器，是可以单独使用的。不仅能应用在web程序中，也可以用于Application、Swing等程序中。</code></pre><h4 id="触发时机不同"><a href="#触发时机不同" class="headerlink" title="触发时机不同"></a>触发时机不同</h4><p><img src="/image/%E5%AE%B9%E5%99%A8.png" alt="效果图预览"><br>     过滤器Filter是在请求进入容器后，但在进入servlet之前进行预处理，请求结束是在servlet处理完以后。<br>     拦截器 Interceptor 是在请求进入servlet后，在进入Controller之前进行预处理的，Controller 中渲染了对应的视图之后请求结束</p><h4 id="拦截的请求范围不同"><a href="#拦截的请求范围不同" class="headerlink" title="拦截的请求范围不同"></a>拦截的请求范围不同</h4><pre><code>执行顺序 ：Filter 处理中 -&gt; Interceptor 前置 -&gt; 我是controller -&gt; Interceptor 处理中 -&gt; Interceptor 处理后</code></pre><h4 id="注入Bean情况不同"><a href="#注入Bean情况不同" class="headerlink" title="注入Bean情况不同"></a>注入Bean情况不同</h4><pre><code>拦截器加载的时间点在springcontext之前，而Bean又是由spring进行管理。解决方案也很简单，在注册拦截器之前，先将Interceptor 手动进行注入。注意：在registry.addInterceptor()注册的是getMyInterceptor() 实例。</code></pre><h4 id="控制执行顺序不同"><a href="#控制执行顺序不同" class="headerlink" title="控制执行顺序不同"></a>控制执行顺序不同</h4><pre><code>过滤器用@Order注解控制执行顺序，通过@Order控制过滤器的级别拦截器默认的执行顺序，就是它的注册顺序，也可以通过Order手动设置控制，值越小越先执行。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 过滤器、拦截器 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 过滤器、拦截器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos7上搭建nexus</title>
      <link href="/2017/03/08/Centos7%E4%B8%8A%E6%90%AD%E5%BB%BAnexus/"/>
      <url>/2017/03/08/Centos7%E4%B8%8A%E6%90%AD%E5%BB%BAnexus/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>  记录一次在centos服务器上搭建私服过程，要使用nexus服务需要安装jdk和maven，jdk已经安装过，只需要安装maven.</p><a id="more"></a><h3 id="第一步：安装maven"><a href="#第一步：安装maven" class="headerlink" title="第一步：安装maven"></a>第一步：安装maven</h3><pre><code>使用xshell连接远程服务器，进入到目录 /usr/local    cd /usr/local新建目录 maven     mkdir maven将安装包上传到这个目录下使用命令 tar -zxvf 解压文件    tar -zxvf apache-maven-3.6.3-bin.tar.gz配置环境变量    vim /etc/profile在文件后边追加如下内容    export PATH=$PATH:/usr/local/maven/apache-maven-3.6.3/bin让配置生效    source /etc/profile查看maven版本    mvn -v</code></pre><p>  maven版本信息<br>   <img src="/image/maven.jpg" alt="效果图预览">        </p><h3 id="第二步：安装nexus"><a href="#第二步：安装nexus" class="headerlink" title="第二步：安装nexus"></a>第二步：安装nexus</h3><pre><code>使用xshell连接远程服务器，进入到目录 /usr/local    cd /usr/local新建目录 nexus     mkdir nexus将安装包上传到这个目录下使用命令 tar -zxvf 解压文件    tar -zxvf nexus-3.13.0-01-unix.tar.gz解压后又两个目录    nexus-3.13.0-01：包含了 Nexus 运行所需要的文件。是 Nexus 运行必须的    sonatype-work： 包含了 Nexus 生成的配置文件、日志文件、仓库文件等。当我们需要备份 Nexus 的时候默认备份此目录即可修改环境变量    vim /etc/profile在文件后边追加文本  export NEXUS_HOME=/usr/local/nexus/nexus-3.13.0  export PATH=$PATH:$NEXUS_HOME/bin让配置生效   source /etc/profile进入到nexus目录下,启动nexus    cd  /usr/local/nexus/nexus-3.13.0-01/bin启动nexus    ./nexus start查看nexus状态    ./nexus status 开放8081端口，nexus默认使用的端口是8081   firewall-cmd --zone=public --add-port=8081/tcp --permanent</code></pre><p>在浏览器中输入<a href="http://120.27.248.244:8081/" target="_blank" rel="noopener">http://120.27.248.244:8081/</a><br>    <img src="/image/nexus1.jpg" alt="效果图预览"></p><h3 id="第三步：配置nexus"><a href="#第三步：配置nexus" class="headerlink" title="第三步：配置nexus"></a>第三步：配置nexus</h3><p>使用admin登录私服</p><p>   <img src="/image/nexus2.jpg" alt="效果图预览"></p><p>创建 3rdPart  Repositories<br>   <img src="/image/nexus3.jpg" alt="效果图预览"><br>   <img src="/image/nexus4.jpg" alt="效果图预览"> </p><p>创建 alyun-proxy  Repositories<br>   <img src="/image/nexus5.jpg" alt="效果图预览"><br>   <img src="/image/nexus6.jpg" alt="效果图预览">  </p><p>调整 Repositories 的位置<br>   <img src="/image/nexus7.jpg" alt="效果图预览"><br>   <img src="/image/nexus8.jpg" alt="效果图预览">  </p><p>私服搭建完毕，效果如下<br>    <img src="/image/nexus9.jpg" alt="效果图预览">  </p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> centos </category>
          
          <category> linux </category>
          
          <category> nexus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> centos </tag>
            
            <tag> linux </tag>
            
            <tag> nexus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>类加载</title>
      <link href="/2017/02/17/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"/>
      <url>/2017/02/17/%E7%B1%BB%E5%8A%A0%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="java基础知识"><a href="#java基础知识" class="headerlink" title="java基础知识"></a>java基础知识</h2><h3 id="整体的流程"><a href="#整体的流程" class="headerlink" title="整体的流程"></a>整体的流程</h3><pre><code>Java 中的所有类，必须被装载到 jvm 中才能运行，这个装载工作是由 jvm 中的类加载器完成的，类加载器所做的工作实质是把类文件从硬盘读取到内存中，JVM 在加载类的时候，都是通过 ClassLoader 的 loadClass（）方法来加载 class 的，loadClass 使用双亲委派模型。</code></pre><p> <img src="/image/%E7%B1%BB%E5%8A%A0%E8%BD%BD.png" alt="效果图预览"></p><h4 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h4><pre><code>通过一个类的全限定名来获取定义此类的二进制字节流将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构在内存中生成一个代表该类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口</code></pre><h4 id="连接-验证"><a href="#连接-验证" class="headerlink" title="连接 - 验证"></a>连接 - 验证</h4><pre><code>文件格式验证、元数据验证、字节码验证、符号引用验证。</code></pre><h4 id="连接-准备"><a href="#连接-准备" class="headerlink" title="连接 - 准备"></a>连接 - 准备</h4><pre><code>准备阶段是正式为类变量（static 修饰的变量）分配内存并设置类变量初始值的极端，这些变量所使用的内存都将在方法区中进行分配。</code></pre><h4 id="连接-解析"><a href="#连接-解析" class="headerlink" title="连接 - 解析"></a>连接 - 解析</h4><pre><code>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。符号引用：只包含语义信息，不涉及具体实现，以一组符号来描述引用目标，是字面量；符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。直接引用：与具体实现息息相关，是直接指向目标的指针；直接引用是可以直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。</code></pre><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><pre><code>初始化阶段，才真正开始执行类中定义的 Java 程序代码（或者说是字节码）</code></pre><h3 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h3><p> <img src="/image/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E7%9A%84%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B.png" alt="效果图预览"><br>    双亲委派模型的工作过程：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。</p><h3 id="双亲委派模型是如何实现的"><a href="#双亲委派模型是如何实现的" class="headerlink" title="双亲委派模型是如何实现的"></a>双亲委派模型是如何实现的</h3><pre><code>实现双亲委派的代码都几种在 java.lang.ClassLoader 的 loadClass() 方法中：先检查是否已经被加载过，若没有加载则调用父加载器的 loadClass() 方法，若父加载器为空则默认使用启动类加载器作为父加载器。如果父加载器加载失败，抛出 ClassNotFoundException 异常后，再调用自己的 findClass() 方法进行加载。（看源码后发现这里的抛出异常是被吞了，catch 之后不会做任何操作）</code></pre><h3 id="破坏双亲委派模型"><a href="#破坏双亲委派模型" class="headerlink" title="破坏双亲委派模型"></a>破坏双亲委派模型</h3><pre><code> 重写 loadClass() 方法 逆向使用类加载器，引入线程上下文类加载器 追求程序的动态性：代码热替换、模块热部署等技术</code></pre><h3 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h3><pre><code>启动类加载器（Bootstrap ClassLoader）： 这个类加载器复杂将存放在 JAVA_HOME/lib 目录中的，或者被-Xbootclasspath 参数所指定的路径种的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录下也不会重载）。扩展类加载器（Extension ClassLoader）： 这个类加载器由sun.misc.Launcher$ExtClassLoader实现，它负责夹杂JAVA_HOME/lib/ext 目录下的，或者被java.ext.dirs 系统变量所指定的路径种的所有类库。开发者可以直接使用扩展类加载器。应用程序类加载器（Application ClassLoader）： 这个类加载器由sun.misc.Launcher$AppClassLoader实现。由于这个类加载器是ClassLoader 种的getSystemClassLoader方法的返回值，所以也成为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库。开发者可以直接使用这个类加载器，如果应用中没有定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器</code></pre>]]></content>
      
      
      <categories>
          
          <category> 类加载 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 类加载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos7上搭建web应用环境</title>
      <link href="/2017/02/10/Centos7%E4%B8%8A%E6%90%AD%E5%BB%BAweb%E7%8E%AF%E5%A2%83/"/>
      <url>/2017/02/10/Centos7%E4%B8%8A%E6%90%AD%E5%BB%BAweb%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>  记录一次在centos服务器上搭建web应用环境过程。</p><a id="more"></a><h3 id="第一步：安装jdk"><a href="#第一步：安装jdk" class="headerlink" title="第一步：安装jdk"></a>第一步：安装jdk</h3><pre><code> 在java官网上下载jdk。 使用xshell连接上远程服务器，进入到目录/usr/local/下   cd   /usr/local/ 新建目录 java 作为java的安装目录   mkdir java 将安装包上传到java 目录下，使用命令将安装包解压   tar -zxvf  jdk-8u221-linux-x64.tar.gz 修改系统环境变量    vim /etc/profile 在文件中追加如下内容   export JAVA_HOME=/usr/local/java/jdk1.8.0_221   export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar   export PATH=$PATH:$JAVA_HOME/bin 保存退出编辑后运行下面命令让配置生效   source /etc/profile 查看jdk配置是否成功   java -version 出现java版本信息说明安装成功。</code></pre><h3 id="第二步：安装tomcat"><a href="#第二步：安装tomcat" class="headerlink" title="第二步：安装tomcat"></a>第二步：安装tomcat</h3><pre><code>  在官网上下载tomcat。 使用xshell连接上远程服务器，进入到目录/usr/local/下   cd   /usr/local/ 新建目录 tomcat 作为tomcat的安装目录   mkdir tomcat 将安装包上传到tomcat 目录下，使用命令将安装包解压    tar -zxvf  apache-tomcat-7.0.96.tar.gz 进入server目录下，修改端口为80    cd  /usr/local/tomcat/apache-tomcat-7.0.96/conf    vim  server.xml 修改端口为80后，保存退出 进入到webapps目录下    cd  /usr/local/tomcat/apache-tomcat-7.0.96/webapps 将应用程序包放到webapps目录下。</code></pre><h3 id="第三步：开放80端口"><a href="#第三步：开放80端口" class="headerlink" title="第三步：开放80端口"></a>第三步：开放80端口</h3><pre><code>开放80端口   firewall-cmd --zone=public --add-port=80/tcp --permanent查询端口号80 是否开启  firewall-cmd --query-port=80/tcp重启防火墙   firewall-cmd --reload查询有哪些端口是开启的   firewall-cmd --list-port</code></pre><p>在浏览器上输入地址就可以访问到项目。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> centos </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> centos </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Oracle数据库修改表结构</title>
      <link href="/2017/01/10/oracle%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BF%AE%E6%94%B9%E8%A1%A8%E7%BB%93%E6%9E%84/"/>
      <url>/2017/01/10/oracle%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BF%AE%E6%94%B9%E8%A1%A8%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>   开发过程中经常回遇到需求变动,现有表结构不能满足现有需求，我们需要修改表结构。最常见的就是增加删除字段、修改字段类型、建立索引等。</p><a id="more"></a><h3 id="一-创建一个表"><a href="#一-创建一个表" class="headerlink" title="一.创建一个表"></a>一.创建一个表</h3><pre><code>表结构如下：   create table test(        id varchar2(50) not null,        registTime varchar2(80) not null    );  </code></pre><h3 id="二-新增字段"><a href="#二-新增字段" class="headerlink" title="二.新增字段"></a>二.新增字段</h3><pre><code> 使用下面这句sql新增 alter table test add (name varchar2(30) default &#39;不详&#39;);  说明：    test 是要修改的表名，    name 是要新增字段的名字，    varchar2(30)是新增字段的类型，    default &#39;不详&#39; 是这个新增字段的默认值，在插入数据时，如果name字段为空，会自动赋值“不详”。</code></pre><h3 id="三-修改字段"><a href="#三-修改字段" class="headerlink" title="三.修改字段"></a>三.修改字段</h3><pre><code>使用下面这句sql修改 alter table test modify (registTime date); 说明：   test 是要修改的表名，   registTime 是要修改字段的名字，   date是修改后字段的类型。 </code></pre><h3 id="四-删除字段"><a href="#四-删除字段" class="headerlink" title="四.删除字段"></a>四.删除字段</h3><pre><code> 使用下面这句sql删除  alter table test drop column name;说明：  test 是要修改的表名，  name 是要删除字段的名字。</code></pre><h3 id="五-设置主键"><a href="#五-设置主键" class="headerlink" title="五.设置主键"></a>五.设置主键</h3><pre><code>使用下面这句sql设置alter table test add constraint pk_test primary key(id);说明：  test是表名，  id是要设置主键的字段，  pk_test 是主键的名称</code></pre><h3 id="六-设置索引"><a href="#六-设置索引" class="headerlink" title="六.设置索引"></a>六.设置索引</h3><pre><code>使用下面这句sql设置create index iden_idnumber on test(id);说明：   test是表名，   id是要设置索引的字段，   iden_idnumber 是索引的名称（oracle中主键默认有索引）</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Oracle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Oracle数据库</title>
      <link href="/2017/01/09/oracle%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>/2017/01/09/oracle%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>   开发人员导入导出，备份数据库是基本技能。虽然记得怎么做，但好记性不如乱笔头，还是做下笔记，防止自己忘记。不会导库的人员也可以参考一下，利人利己。</p><a id="more"></a><h3 id="一-导出数据库"><a href="#一-导出数据库" class="headerlink" title="一.导出数据库"></a>一.导出数据库</h3><pre><code>第一步：先使用plsql连上数据库，点击file-&gt;new-&gt;sql window,新建一个窗口。   执行下面这句sql   select &#39;alter table &#39;||table_name||&#39; allocate extent;&#39; from user_tables where num_rows=0;   执行这句sql是为了到出库时，能把空表也导出。第二步：按下WIN+R键，输入cmd，进入到dos窗口。   在dos窗口下执行下面这句命令导出库即可   exp sys/oracle@127.0.0.1:1521/orcl file=D:\test.dmp    说明：    sys：是数据库用户的用户名    oracle：数据库用户的密码    127.0.0.1:1521/orcl：是远程数据库的地址    D:\test.dmp：是导出数据库要保存的地址</code></pre><h3 id="二-导入数据库"><a href="#二-导入数据库" class="headerlink" title="二.导入数据库"></a>二.导入数据库</h3><pre><code>第一步：先使用plsql连上数据库，点击file-&gt;new-&gt;sql window,新建一个窗口。第二步：使用下边这句sql创建表空间    create tablespace TEST_BIZ datafile &#39;E:\TEST_BIZ.dbf&#39; size 50M autoextend on next 10M maxsize unlimited;    说明：    TEST_BIZ ：是要创建表空间的名字    E:\TEST_BIZ.dbf：是表空间放在那里第三步：使用下面这句sql创建用户    create user TEST_USER identified by TEST_PASSWORD default tablespace TEST_BIZ;    说明：    TEST_USER ：创建的用户名    TEST_PASSWORD ：创建的用户密码    TEST_BIZ：这个用户使用的表空间第四步：使用下面的sql为用户授权    grant dba to TEST_USER;第五步：按下WIN+R键，输入cmd，进入到dos窗口。      在dos窗口下执行下面的命令    imp TEST_USER/TEST_PASSWORD@127.0.0.1:1521/orcl file=D:\test.dmp full=y ignore=y        说明：        TEST_USER：用户名        TEST_PASSWORD：密码        127.0.0.1:1521/orcl：远程主机的地址        D:\test.dmp：dmp文件的位置</code></pre>]]></content>
      
      
      <categories>
          
          <category> Oracle </category>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Oracle </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java基础</title>
      <link href="/2016/12/28/java%E5%9F%BA%E7%A1%80/"/>
      <url>/2016/12/28/java%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="java基础知识"><a href="#java基础知识" class="headerlink" title="java基础知识"></a>java基础知识</h2><h3 id="1-java三大特性"><a href="#1-java三大特性" class="headerlink" title="1.java三大特性"></a>1.java三大特性</h3><pre><code>   抽象：抽象是将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象两方面。抽象只关注对象有哪些属性和行为，并不关注这些行为的细节是什么。    继承：继承是从已有类得到继承信息创建新类的过程。提供继承信息的类被称为父类（超类、基类）；得到继承信息的类被称为子类（派生类）。   封装：通常认为封装是把数据和操作数据的方法绑定起来，对数据的访问只能通过已定义的接口。面向对象的本质就是将现实世界描绘成一系列完全自治、封闭的对象。我们在类中编写的方法就是对实现细节的一种封装；我们编写一个类就是对数据和数据操作的封装。</code></pre><h3 id="2-java修饰符"><a href="#2-java修饰符" class="headerlink" title="2.java修饰符"></a>2.java修饰符</h3><p><img src="/image/decorate.jpg" alt="效果图预览"> </p><h3 id="3-Java-原始类型大小"><a href="#3-Java-原始类型大小" class="headerlink" title="3.Java 原始类型大小"></a>3.Java 原始类型大小</h3><pre><code>boolean    1字节byte       1字节char       2字节short      2字节int        4字节float      4字节double     8字节long       8字节</code></pre><h3 id="4-构造器（constructor）是否可被重写（override）"><a href="#4-构造器（constructor）是否可被重写（override）" class="headerlink" title="4.构造器（constructor）是否可被重写（override）"></a>4.构造器（constructor）是否可被重写（override）</h3><pre><code>构造器不能被继承，因此不能被重写，但可以被重载。</code></pre><h3 id="5-String和StringBuilder、StringBuffer的区别"><a href="#5-String和StringBuilder、StringBuffer的区别" class="headerlink" title="5.String和StringBuilder、StringBuffer的区别"></a>5.String和StringBuilder、StringBuffer的区别</h3><pre><code>Java平台提供了两种类型的字符串：String和StringBuffer/StringBuilder，它们可以储存和操作字符串。其中String是只读字符串，也就意味着String引用的字符串内容是不能被改变的。而StringBuffer/StringBuilder类表示的字符串对象可以直接进行修改。StringBuilder是Java 5中引入的，它和StringBuffer的方法完全相同，区别在于它是在单线程环境下使用的，因为它的所有方面都没有被synchronized修饰，因此它的效率也比StringBuffer要高。</code></pre><h3 id="6-重载（Overload）和重写（Override）的区别"><a href="#6-重载（Overload）和重写（Override）的区别" class="headerlink" title="6.重载（Overload）和重写（Override）的区别"></a>6.重载（Overload）和重写（Override）的区别</h3><pre><code>方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载；重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。重载对返回类型没有特殊的要求。</code></pre><h3 id="7-JVM加载class文件的原理机制"><a href="#7-JVM加载class文件的原理机制" class="headerlink" title="7.JVM加载class文件的原理机制"></a>7.JVM加载class文件的原理机制</h3><pre><code> JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。 类的加载是指把类的.class文件中的数据读入到内存中，通常是创建一个字节数组读入.class文件，然后产生与所加载类对应的Class对象。加载完成后，Class对象还不完整，所以此时的类还不可用。当类被加载后就进入连接阶段，这一阶段包括验证、准备（为静态变量分配内存并设置默认的初始值）和解析（将符号引用替换为直接引用）三个步骤。 最后JVM对类进行初始化，包括：1)如果类存在直接的父类并且这个类还没有被初始化，那么就先初始化父类；2)如果类中存在初始化语句，就依次执行这些初始化语句。</code></pre><h3 id="8-垃圾回收相关的JVM参数"><a href="#8-垃圾回收相关的JVM参数" class="headerlink" title="8.垃圾回收相关的JVM参数"></a>8.垃圾回收相关的JVM参数</h3><pre><code> -Xms / -Xmx — 堆的初始大小 / 堆的最大大小 -Xmn — 堆中年轻代的大小 -XX:-DisableExplicitGC — 让System.gc()不产生任何作用 -XX:+PrintGCDetails — 打印GC的细节 -XX:+PrintGCDateStamps — 打印GC操作的时间戳 -XX:NewSize / XX:MaxNewSize — 设置新生代大小/新生代最大大小 -XX:NewRatio — 可以设置老生代和新生代的比例 -XX:PrintTenuringDistribution — 设置每次新生代GC后输出幸存者乐园中对象年龄的分布 -XX:InitialTenuringThreshold / -XX:MaxTenuringThreshold：设置老年代阀值的初始值和最大值 -XX:TargetSurvivorRatio：设置幸存区的目标使用率</code></pre><h3 id="9-Error和Exception有什么区别"><a href="#9-Error和Exception有什么区别" class="headerlink" title="9.Error和Exception有什么区别"></a>9.Error和Exception有什么区别</h3><pre><code>Error表示系统级的错误和程序不必处理的异常，是恢复不是不可能但很困难的情况下的一种严重问题；比如内存溢出，不可能指望程序能处理这样的情况；Exception表示需要捕捉或者需要程序进行处理的异常，是一种设计或实现问题；也就是说，它表示如果程序运行正常，从不会发生的情况。</code></pre><h3 id="10-Thread类的sleep-方法和对象的wait-方法都可以让线程暂停执行，它们有什么区别"><a href="#10-Thread类的sleep-方法和对象的wait-方法都可以让线程暂停执行，它们有什么区别" class="headerlink" title="10.Thread类的sleep()方法和对象的wait()方法都可以让线程暂停执行，它们有什么区别"></a>10.Thread类的sleep()方法和对象的wait()方法都可以让线程暂停执行，它们有什么区别</h3><pre><code>sleep()方法（休眠）是线程类（Thread）的静态方法，调用此方法会让当前线程暂停执行指定的时间，将执行机会（CPU）让给其他线程，但是对象的锁依然保持，因此休眠时间结束后会自动恢复（线程回到就绪状态，请参考第66题中的线程状态转换图）。wait()是Object类的方法，调用对象的wait()方法导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的notify()方法（或notifyAll()方法）时才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进入就绪状态。</code></pre><h3 id="11-事务的ACID是指什么"><a href="#11-事务的ACID是指什么" class="headerlink" title="11.事务的ACID是指什么"></a>11.事务的ACID是指什么</h3><pre><code> 原子性(Atomic)：事务中各项操作，要么全做要么全不做，任何一项操作的失败都会导致整个事务的失败；  一致性(Consistent)：事务结束后系统状态是一致的；  隔离性(Isolated)：并发执行的事务彼此无法看到对方的中间状态；  持久性(Durable)：事务完成后所做的改动都会被持久化，即使发生灾难性的失败。通过日志和同步备份可以在故障发生后重建数据。 脏读（Dirty Read）：A事务读取B事务尚未提交的数据并在此基础上操作，而B事务执行回滚，那么A读取到的数据就是脏数据。 不可重复读（Unrepeatable Read）：事务A重新读取前面读取过的数据，发现该数据已经被另一个已提交的事务B修改过了。 幻读（Phantom Read）：事务A重新执行一个查询，返回一系列符合查询条件的行，发现其中插入了被事务B提交的行。</code></pre><h3 id="12-获得一个类的类对象有哪些方式"><a href="#12-获得一个类的类对象有哪些方式" class="headerlink" title="12.获得一个类的类对象有哪些方式"></a>12.获得一个类的类对象有哪些方式</h3><pre><code> 方法1：类型.class，例如：String.class  方法2：对象.getClass()，例如：&quot;hello&quot;.getClass()  方法3：Class.forName()，例如：Class.forName(&quot;java.lang.String&quot;)</code></pre><h3 id="13-如何通过反射创建对象"><a href="#13-如何通过反射创建对象" class="headerlink" title="13.如何通过反射创建对象"></a>13.如何通过反射创建对象</h3><pre><code> 方法1：通过类对象调用newInstance()方法，例如：String.class.newInstance()  方法2：通过类对象的getConstructor()或getDeclaredConstructor()方法获得构造器（Constructor）对象并调用其newInstance()方法创建对象，例如：String.class.getConstructor(String.class).newInstance(&quot;Hello&quot;);</code></pre><h3 id="14-java中wait和sleep有什么区别"><a href="#14-java中wait和sleep有什么区别" class="headerlink" title="14.java中wait和sleep有什么区别"></a>14.java中wait和sleep有什么区别</h3><pre><code> 最大区别是等待时wait会释放锁，而sleep会一直持有锁，wait通常用于线程时交互，sleep通常被用于暂停执行</code></pre><h3 id="15-HTTP请求方法get和post有什么区别"><a href="#15-HTTP请求方法get和post有什么区别" class="headerlink" title="15. HTTP请求方法get和post有什么区别"></a>15. HTTP请求方法get和post有什么区别</h3><pre><code> 1：Post传输数据时，不需要在URL中显示出来，而Get方法要在URL中显示。 2：Post传输的数据量大，可以达到2M，而Get方法由于受到URL长度限制,只能传递大约1024字节. 3：Post就是为了将数据传送到服务器段,Get就是为了从服务器段取得数据.而Get 之所以也能传送数据,只是用来设计告诉服务器,你到底需要什么样的数据.Post的信息作为http请求的内容，而Get是在Http头部传输的。</code></pre><h3 id="16-java中代码块执行顺序"><a href="#16-java中代码块执行顺序" class="headerlink" title="16. java中代码块执行顺序"></a>16. java中代码块执行顺序</h3><p>   父类中静态代码块-》子类中静态代码块-》父类中普通代码块-》父类中构造函数-》子类中普通代码块-》子类中构造函数</p><h3 id="17-为什么hashmap的长度要是2-N"><a href="#17-为什么hashmap的长度要是2-N" class="headerlink" title="17.为什么hashmap的长度要是2^N"></a>17.为什么hashmap的长度要是2^N</h3><pre><code>hash&amp;length-1)只有hashmap的长度为2^N,length-1转化成二进制才全是1，按位与才能均匀的分布到每个桶中。</code></pre><h3 id="18-网络架构"><a href="#18-网络架构" class="headerlink" title="18. 网络架构"></a>18. 网络架构</h3><p><img src="/image/%E7%BD%91%E7%BB%9C%E5%9B%BE.jpg" alt="效果图预览"></p><h3 id="19-三次握手"><a href="#19-三次握手" class="headerlink" title="19. 三次握手"></a>19. 三次握手</h3><p><img src="/image/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt="效果图预览"></p><h3 id="20-Error和Exception的区别"><a href="#20-Error和Exception的区别" class="headerlink" title="20. Error和Exception的区别"></a>20. Error和Exception的区别</h3><pre><code>Error：程序无法处理的系统错误，编译器不做检查；</code></pre><p>　　Exception：程序可以处理的异常，捕获后可能恢复；<br>   总结：前者是程序无法处理的错误，后者是可以处理的异常。</p><pre><code>Error：属于JVM需要负担的责任；</code></pre><p>　　Exception：<br>           RuntimeException（非受检异常）是程序应该负担的责任；<br>　　　　　　Checked Exception （受检异常）可检查异常时Java编译器应该负担的责任。<br>      RuntimeException：<br>        　　1、NullPropagation：空指针异常；<br>        　　2、ClassCastException：类型强制转换异常<br>        　　3、IllegalArgumentException：传递非法参数异常<br>        　　4、IndexOutOfBoundsException：下标越界异常<br>        　　5、NumberFormatException：数字格式异常</p><pre><code>    非RuntimeException：    　　1、ClassNotFoundException：找不到指定class的异常    　　2、IOException：IO操作异常    Error：    　　1、NoClassDefFoundError：找不到class定义的异常    　　2、StackOverflowError：深递归导致栈被耗尽而抛出的异常    　　3、OutOfMemoryError：内存溢出异常</code></pre><h3 id="21-Executors创建线程池"><a href="#21-Executors创建线程池" class="headerlink" title="21.Executors创建线程池"></a>21.Executors创建线程池</h3><pre><code>   只需要调用Executors中相应的便捷方法即可，比如Executors.newFixedThreadPool(int nThreads)，但是便捷不仅隐藏了复杂性，也为我们埋下了潜在的隐患（OOM，线程耗尽）。   方法名                            功能newFixedThreadPool(int nThreads)    创建固定大小的线程池newSingleThreadExecutor()    创建只有一个线程的线程池newCachedThreadPool()    创建一个不限线程数上限的线程池，任何提交的任务都将立即执行    // Java线程池的完整构造函数    public ThreadPoolExecutor(            int corePoolSize, // 线程池长期维持的线程数，即使线程处于Idle状态，也不会回收。            int maximumPoolSize, // 线程数的上限            long keepAliveTime, // 超过corePoolSize的线程的idle时长，             TimeUnit unit, // 超过这个时间，多余的线程会被回收。            BlockingQueue&lt;Runnable&gt; workQueue, // 任务的排队队列            ThreadFactory threadFactory, // 新线程的产生方式            RejectedExecutionHandler handler) // 拒绝策略拒绝策略    CallerRunsPolicy：处理策略：不管线程池死活，来任务了，我就执行，不管你能不能真的执行。注意：这里的执行就是执行ThreadPoolExecutor.execute()。    AbortPolicy：处理策略：抛异常。这个是默认处理策略。    DiscardPolicy：处理策略：什么都不做。相当于放弃了当前任务的执行。    DiscardOldestPolicy：处理策略：移出任务队列头部的任务，然后执行当前线程。相当于放弃了任务队列头部的任务。</code></pre><h3 id="22、公平锁和非公平锁"><a href="#22、公平锁和非公平锁" class="headerlink" title="22、公平锁和非公平锁"></a>22、公平锁和非公平锁</h3><pre><code>公平锁：多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁    优点：所有的线程都能得到资源，不会饿死在队列中。    缺点：吞吐量会下降很多，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销会很大。非公平锁：多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。    优点：可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。    缺点：你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁，导致饿死。</code></pre><h3 id="23、ReentrantLook实现原理"><a href="#23、ReentrantLook实现原理" class="headerlink" title="23、ReentrantLook实现原理"></a>23、ReentrantLook实现原理</h3><pre><code>ReentrantLock主要利用CAS+AQS队列来实现。它支持公平锁和非公平锁，两者的实现类似。CAS：Compare and Swap，比较并交换。CAS有3个操作数：内存值V、预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。该操作是一个原子操作，被广泛的应用在Java的底层实现中。在Java中，CAS主要是由sun.misc.Unsafe这个类通过JNI调用CPU底层指令实现。AQS使用一个FIFO的队列表示排队等待锁的线程，队列头节点称作“哨兵节点”或者“哑节点”，它不与任何线程关联。其他的节点与等待线程关联，每个节点维护一个等待状态waitStatus.ReentrantLock的基本实现可以概括为：先通过CAS尝试获取锁。如果此时已经有线程占据了锁，那就加入AQS队列并且被挂起。当锁被释放之后，排在CLH队列队首的线程会被唤醒，然后CAS再次尝试获取锁。</code></pre><h3 id="24、线程的生命周期"><a href="#24、线程的生命周期" class="headerlink" title="24、线程的生命周期"></a>24、线程的生命周期</h3><pre><code> 新建：就是刚使用new方法，new出来的线程； 就绪：就是调用的线程的start()方法后，这时候线程处于等待CPU分配资源阶段，谁先抢的CPU资源，谁开始执行; 运行：当就绪的线程被调度并获得CPU资源时，便进入运行状态，run方法定义了线程的操作和功能; 阻塞：在运行状态的时候，可能因为某些原因导致运行状态的线程变成了阻塞状态，比如sleep()、wait()之后线程就处于了阻塞状态，这个时候需要其他机制将处于阻塞状态的线程唤醒，比如调用notify或者notifyAll()方法。唤醒的线程不会立刻执行run方法，它们要再次等待CPU分配资源进入运行状态; 销毁：如果线程正常执行完毕后或线程被提前强制性的终止或出现异常导致结束，那么线程就要被销毁，释放资源;</code></pre><h3 id="25-分布式事务"><a href="#25-分布式事务" class="headerlink" title="25.分布式事务"></a>25.分布式事务</h3><pre><code>atomikos</code></pre><h3 id="26-GC原理和G1算法"><a href="#26-GC原理和G1算法" class="headerlink" title="26.GC原理和G1算法"></a>26.GC原理和G1算法</h3><pre><code>  从最高层看，G1的collector一侧其实就是两个大部分：    全局并发标记（global concurrent marking）    拷贝存活对象（evacuation）非并发，暂停拷贝而这两部分可以相对独立的执行。</code></pre><h3 id="27-jvm调优"><a href="#27-jvm调优" class="headerlink" title="27.jvm调优"></a>27.jvm调优</h3><pre><code> 不管是YGC还是Full GC,GC过程中都会对导致程序运行中中断,正确的选择不同的GC策略,调整JVM、GC的参数，可以极大的减少由于GC工作，而导致的程序运行中断方面的问题，进而适当的提高Java程序的工作效率。但是调整GC是以个极为复杂的过程，由于各个程序具备不同的特点，如：web和GUI程序就有很大区别（Web可以适当的停顿，但GUI停顿是客户无法接受的），而且由于跑在各个机器上的配置不同（主要cup个数，内存不同），所以使用的GC种类也会不同(如何选择见GC种类及如何选择)。本文将注重介绍JVM、GC的一些重要参数的设置来提高系统的性能。 JVM内存组成及GC相关内容请见之前的文章:JVM内存组成 GC策略&amp;内存申请。JVM参数的含义 实例见实例分析参数名称    含义    默认值     -Xms    初始堆大小    物理内存的1/64(&lt;1GB)    默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制.-Xmx    最大堆大小    物理内存的1/4(&lt;1GB)    默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制-Xmn    年轻代大小(1.4or lator)         注意：此处的大小是（eden+ 2 survivor space).与jmap -heap中显示的New gen是不同的。整个堆大小=年轻代大小 + 年老代大小 + 持久代大小.增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8-XX:NewSize    设置年轻代大小(for 1.3/1.4)          -XX:MaxNewSize    年轻代最大值(for 1.3/1.4)          -XX:PermSize    设置持久代(perm gen)初始值    物理内存的1/64     -XX:MaxPermSize    设置持久代最大值    物理内存的1/4     -Xss    每个线程的堆栈大小         JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.更具应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右一般小的应用， 如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（校长）和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:&quot;”-Xss is translated in a VM flag named ThreadStackSize”一般设置这个值就可以了。-XX:ThreadStackSize    Thread Stack Size         (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.]-XX:NewRatio    年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代)         -XX:NewRatio=4表示年轻代与年老代所占比值为1:4,年轻代占整个堆栈的1/5Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。-XX:SurvivorRatio    Eden区与Survivor区的大小比值         设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10-XX:LargePageSizeInBytes    内存页的大小不可设置过大， 会影响Perm的大小         =128m-XX:+UseFastAccessorMethods    原始类型的快速优化          -XX:+DisableExplicitGC    关闭System.gc()         这个参数需要严格的测试-XX:MaxTenuringThreshold    垃圾最大年龄         如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率.如果将此值设置为一个较大值,则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活 时间,增加在年轻代即被回收的概率该参数只有在串行GC时才有效.-XX:+AggressiveOpts    加快编译          -XX:+UseBiasedLocking    锁机制的性能改善          -Xnoclassgc    禁用垃圾回收          -XX:SoftRefLRUPolicyMSPerMB    每兆堆空闲空间中SoftReference的存活时间    1s    softly reachable objects will remain alive for some amount of time after the last time they were referenced. The default value is one second of lifetime per free megabyte in the heap-XX:PretenureSizeThreshold    对象超过多大是直接在旧生代分配    0    单位字节 新生代采用Parallel Scavenge GC时无效另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象.-XX:TLABWasteTargetPercent    TLAB占eden区的百分比    1%     -XX:+CollectGen0First    FullGC时是否先YGC    false     并行收集器相关参数-XX:+UseParallelGC    Full GC采用parallel MSC(此项待验证)         选择垃圾收集器为并行收集器.此配置仅对年轻代有效.即上述配置下,年轻代使用并发收集,而年老代仍旧使用串行收集.(此项待验证)-XX:+UseParNewGC    设置年轻代为并行收集         可与CMS收集同时使用JDK5.0以上,JVM会根据系统配置自行设置,所以无需再设置此值-XX:ParallelGCThreads    并行收集器的线程数         此值最好配置与处理器数目相等 同样适用于CMS-XX:+UseParallelOldGC    年老代垃圾收集方式为并行收集(Parallel Compacting)         这个是JAVA 6出现的参数选项-XX:MaxGCPauseMillis    每次年轻代垃圾回收的最长时间(最大暂停时间)         如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值.-XX:+UseAdaptiveSizePolicy    自动选择年轻代区大小和相应的Survivor区比例         设置此选项后,并行收集器会自动选择年轻代区大小和相应的Survivor区比例,以达到目标系统规定的最低相应时间或者收集频率等,此值建议使用并行收集器时,一直打开.-XX:GCTimeRatio    设置垃圾回收时间占程序运行时间的百分比         公式为1/(1+n)-XX:+ScavengeBeforeFullGC    Full GC前调用YGC    true    Do young generation GC prior to a full GC. (Introduced in 1.4.1.)CMS相关参数-XX:+UseConcMarkSweepGC    使用CMS内存收集         测试中配置这个以后,-XX:NewRatio=4的配置失效了,原因不明.所以,此时年轻代大小最好用-Xmn设置.???-XX:+AggressiveHeap              试图是使用大量的物理内存长时间大内存使用的优化，能检查计算资源（内存， 处理器数量）至少需要256MB内存大量的CPU／内存， （在1.4.1在4CPU的机器上已经显示有提升）-XX:CMSFullGCsBeforeCompaction    多少次后进行内存压缩         由于并发收集器不对内存空间进行压缩,整理,所以运行一段时间以后会产生&quot;碎片&quot;,使得运行效率降低.此值设置运行多少次GC以后对内存空间进行压缩,整理.-XX:+CMSParallelRemarkEnabled    降低标记停顿          -XX+UseCMSCompactAtFullCollection    在FULL GC的时候， 对年老代的压缩         CMS是不会移动内存的， 因此， 这个非常容易产生碎片， 导致内存不够用， 因此， 内存的压缩这个时候就会被启用。 增加这个参数是个好习惯。可能会影响性能,但是可以消除碎片-XX:+UseCMSInitiatingOccupancyOnly    使用手动定义初始化定义开始CMS收集         禁止hostspot自行触发CMS GC-XX:CMSInitiatingOccupancyFraction=70    使用cms作为垃圾回收使用70％后开始CMS收集    92    为了保证不出现promotion failed(见下面介绍)错误,该值的设置需要满足以下公式CMSInitiatingOccupancyFraction计算公式-XX:CMSInitiatingPermOccupancyFraction    设置Perm Gen使用到达多少比率时触发    92     -XX:+CMSIncrementalMode    设置为增量模式         用于单CPU情况-XX:+CMSClassUnloadingEnabled               辅助信息-XX:+PrintGC              输出形式:[GC 118250K-&gt;113543K(130112K), 0.0094143 secs][Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs]-XX:+PrintGCDetails              输出形式:[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs][GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs]-XX:+PrintGCTimeStamps               -XX:+PrintGC:PrintGCTimeStamps              可与-XX:+PrintGC -XX:+PrintGCDetails混合使用输出形式:11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs]-XX:+PrintGCApplicationStoppedTime    打印垃圾回收期间程序暂停的时间.可与上面混合使用         输出形式:Total time for which application threads were stopped: 0.0468229 seconds-XX:+PrintGCApplicationConcurrentTime    打印每次垃圾回收前,程序未中断的执行时间.可与上面混合使用         输出形式:Application time: 0.5291524 seconds-XX:+PrintHeapAtGC    打印GC前后的详细堆栈信息          -Xloggc:filename    把相关日志信息记录到文件以便分析.与上面几个配合使用          -XX:+PrintClassHistogramgarbage collects before printing the histogram.          -XX:+PrintTLAB    查看TLAB空间的使用情况          XX:+PrintTenuringDistribution    查看每次minor GC后新的存活周期的阈值         Desired survivor size 1048576 bytes, new threshold 7 (max 15)new threshold 7即标识新的存活周期的阈值为7。GC性能方面的考虑    对于GC的性能主要有2个方面的指标：吞吐量throughput（工作时间不算gc的时间占总的时间比）和暂停pause（gc发生时app对外显示的无法响应）。1. Total Heap    默认情况下，vm会增加/减少heap大小以维持free space在整个vm中占的比例，这个比例由MinHeapFreeRatio和MaxHeapFreeRatio指定。一般而言，server端的app会有以下规则：对vm分配尽可能多的memory；将Xms和Xmx设为一样的值。如果虚拟机启动时设置使用的内存比较小，这个时候又需要初始化很多对象，虚拟机就必须重复地增加内存。处理器核数增加，内存也跟着增大。2. The Young Generation    另外一个对于app流畅性运行影响的因素是young generation的大小。young generation越大，minor collection越少；但是在固定heap size情况下，更大的young generation就意味着小的tenured generation，就意味着更多的major collection(major collection会引发minor collection)。    NewRatio反映的是young和tenured generation的大小比例。NewSize和MaxNewSize反映的是young generation大小的下限和上限，将这两个值设为一样就固定了young generation的大小（同Xms和Xmx设为一样）。    如果希望，SurvivorRatio也可以优化survivor的大小，不过这对于性能的影响不是很大。SurvivorRatio是eden和survior大小比例。一般而言，server端的app会有以下规则：首先决定能分配给vm的最大的heap size，然后设定最佳的young generation的大小；如果heap size固定后，增加young generation的大小意味着减小tenured generation大小。让tenured generation在任何时候够大，能够容纳所有live的data（留10%-20%的空余）。经验&amp;&amp;规则年轻代大小选择响应时间优先的应用:尽可能设大,直到接近系统的最低响应时间限制(根据实际情况选择).在此种情况下,年轻代收集发生的频率也是最小的.同时,减少到达年老代的对象.吞吐量优先的应用:尽可能的设置大,可能到达Gbit的程度.因为对响应时间没有要求,垃圾收集可以并行进行,一般适合8CPU以上的应用.避免设置过小.当新生代设置过小时会导致:1.YGC次数更加频繁 2.可能导致YGC对象直接进入旧生代,如果此时旧生代满了,会触发FGC.年老代大小选择响应时间优先的应用:年老代使用并发收集器,所以其大小需要小心设置,一般要考虑并发会话率和会话持续时间等一些参数.如果堆设置小了,可以会造成内存碎 片,高回收频率以及应用暂停而使用传统的标记清除方式;如果堆大了,则需要较长的收集时间.最优化的方案,一般需要参考以下数据获得:并发垃圾收集信息、持久代并发收集次数、传统GC信息、花在年轻代和年老代回收上的时间比例。吞吐量优先的应用:一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代.原因是,这样可以尽可能回收掉大部分短期对象,减少中期的对象,而年老代尽存放长期存活对象.较小堆引起的碎片问题因为年老代的并发收集器使用标记,清除算法,所以不会对堆进行压缩.当收集器回收时,他会把相邻的空间进行合并,这样可以分配给较大的对象.但是,当堆空间较小时,运行一段时间以后,就会出现&quot;碎片&quot;,如果并发收集器找不到足够的空间,那么并发收集器将会停止,然后使用传统的标记,清除方式进行回收.如果出现&quot;碎片&quot;,可能需要进行如下配置:-XX:+UseCMSCompactAtFullCollection:使用并发收集器时,开启对年老代的压缩.-XX:CMSFullGCsBeforeCompaction=0:上面配置开启的情况下,这里设置多少次Full GC后,对年老代进行压缩用64位操作系统，Linux下64位的jdk比32位jdk要慢一些，但是吃得内存更多，吞吐量更大XMX和XMS设置一样大，MaxPermSize和MinPermSize设置一样大，这样可以减轻伸缩堆大小带来的压力使用CMS的好处是用尽量少的新生代，经验值是128M－256M， 然后老生代利用CMS并行收集， 这样能保证系统低延迟的吞吐效率。 实际上cms的收集停顿时间非常的短，2G的内存， 大约20－80ms的应用程序停顿时间系统停顿的时候可能是GC的问题也可能是程序的问题，多用jmap和jstack查看，或者killall -3 java，然后查看java控制台日志，能看出很多问题。(相关工具的使用方法将在后面的blog中介绍)仔细了解自己的应用，如果用了缓存，那么年老代应该大一些，缓存的HashMap不应该无限制长，建议采用LRU算法的Map做缓存，LRUMap的最大长度也要根据实际情况设定。采用并发回收时，年轻代小一点，年老代要大，因为年老大用的是并发回收，即使时间长点也不会影响其他程序继续运行，网站不会停顿JVM参数的设置(特别是 –Xmx –Xms –Xmn -XX:SurvivorRatio  -XX:MaxTenuringThreshold等参数的设置没有一个固定的公式，需要根据PV old区实际数据 YGC次数等多方面来衡量。为了避免promotion faild可能会导致xmn设置偏小，也意味着YGC的次数会增多，处理并发访问的能力下降等问题。每个参数的调整都需要经过详细的性能测试，才能找到特定应用的最佳配置。promotion failed:垃圾回收时promotion failed是个很头痛的问题，一般可能是两种原因产生，第一个原因是救助空间不够，救助空间里的对象还不应该被移动到年老代，但年轻代又有很多对象需要放入救助空间；第二个原因是年老代没有足够的空间接纳来自年轻代的对象；这两种情况都会转向Full GC，网站停顿时间较长。解决方方案一：第一个原因我的最终解决办法是去掉救助空间，设置-XX:SurvivorRatio=65536 -XX:MaxTenuringThreshold=0即可，第二个原因我的解决办法是设置CMSInitiatingOccupancyFraction为某个值（假设70），这样年老代空间到70%时就开始执行CMS，年老代有足够的空间接纳来自年轻代的对象。解决方案一的改进方案：又有改进了，上面方法不太好，因为没有用到救助空间，所以年老代容易满，CMS执行会比较频繁。我改善了一下，还是用救助空间，但是把救助空间加大，这样也不会有promotion failed。具体操作上，32位Linux和64位Linux好像不一样，64位系统似乎只要配置MaxTenuringThreshold参数，CMS还是有暂停。为了解决暂停问题和promotion failed问题，最后我设置-XX:SurvivorRatio=1 ，并把MaxTenuringThreshold去掉，这样即没有暂停又不会有promotoin failed，而且更重要的是，年老代和永久代上升非常慢（因为好多对象到不了年老代就被回收了），所以CMS执行频率非常低，好几个小时才执行一次，这样，服务器都不用重启了。-Xmx4000M -Xms4000M -Xmn600M -XX:PermSize=500M -XX:MaxPermSize=500M -Xss256K -XX:+DisableExplicitGC -XX:SurvivorRatio=1 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 -XX:+CMSClassUnloadingEnabled -XX:LargePageSizeInBytes=128M -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=80 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+PrintClassHistogram -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -Xloggc:log/gc.logCMSInitiatingOccupancyFraction值与Xmn的关系公式上面介绍了promontion faild产生的原因是EDEN空间不足的情况下将EDEN与From survivor中的存活对象存入To survivor区时,To survivor区的空间不足，再次晋升到old gen区，而old gen区内存也不够的情况下产生了promontion faild从而导致full gc.那可以推断出：eden+from survivor &lt; old gen区剩余内存时，不会出现promontion faild的情况，即：(Xmx-Xmn)*(1-CMSInitiatingOccupancyFraction/100)&gt;=(Xmn-Xmn/(SurvivorRatior+2))  进而推断出：CMSInitiatingOccupancyFraction &lt;=((Xmx-Xmn)-(Xmn-Xmn/(SurvivorRatior+2)))/(Xmx-Xmn)*100例如：当xmx=128 xmn=36 SurvivorRatior=1时 CMSInitiatingOccupancyFraction&lt;=((128.0-36)-(36-36/(1+2)))/(128-36)*100 =73.913当xmx=128 xmn=24 SurvivorRatior=1时 CMSInitiatingOccupancyFraction&lt;=((128.0-24)-(24-24/(1+2)))/(128-24)*100=84.615…当xmx=3000 xmn=600 SurvivorRatior=1时  CMSInitiatingOccupancyFraction&lt;=((3000.0-600)-(600-600/(1+2)))/(3000-600)*100=83.33CMSInitiatingOccupancyFraction低于70% 需要调整xmn或SurvivorRatior值。再上实际的参数我们分析下-XX:+UseParallelGC -XX:ParallelGCThreads=4 -XX:+UseParallelOldGC -XX:YoungGenerationSizeIncrement=20 -XX:TenuredGenerationSizeIncrement=20</code></pre><h3 id="28-spring-bean的生命周期"><a href="#28-spring-bean的生命周期" class="headerlink" title="28.spring bean的生命周期"></a>28.spring bean的生命周期</h3><p>实例化 -&gt; 属性赋值 -&gt; 初始化 -&gt; 销毁</p><h3 id="29-Servlet生命周期详解"><a href="#29-Servlet生命周期详解" class="headerlink" title="29.Servlet生命周期详解"></a>29.Servlet生命周期详解</h3><p>加载-》初始化-》服务-》销毁-》卸载</p><pre><code>加载Servlet    Web容器负责加载Servlet，当web容器启东时或者在第一次使用这个Servlet的时候，容器会负责创建Servlet实例，但是用户必须通过web.xml指定Servlet的位置，成功加载后，Web容器会通过反射的方式对Servlet进行实例化。初始化    当一个servlet被实例化之后，容器将调用init()方法初始化这个对象，以便在处理请求之前完成一些动作。服务    执行方法销毁   大部分web容器关闭或者检测到一个servlet要从容器中被删除时，会自动调用destory方法。卸载   当一个servlet调用玩destory后，此实例将被垃圾回收，当需要再次使用时，将会重新调用init方法。需要注意的是，在正常情况下，Servlet只会初始化一次，但是当Servlet长时间不使用的话，也会被容器自动销毁，而如果需要再次使用时，会重新进行初始化操作，即在特殊情况下初始化操作和销毁操作也会执行多次。</code></pre><h3 id="30-web-xml中load-on-startup的作用"><a href="#30-web-xml中load-on-startup的作用" class="headerlink" title="30.web.xml中load-on-startup的作用"></a>30.web.xml中load-on-startup的作用</h3><pre><code>1)load-on-startup元素标记容器是否在启动的时候就加载这个servlet(实例化并调用其init()方法)。2)它的值必须是一个整数，表示servlet应该被载入的顺序2)当值为0或者大于0时，表示容器在应用启动时就加载并初始化这个servlet；3)当值小于0或者没有指定时，则表示容器在该servlet被选择时才会去加载。4)正数的值越小，该servlet的优先级越高，应用启动时就越先加载。5)当值相同时，容器就会自己选择顺序来加载。所以，&lt;load-on-startup&gt;x&lt;/load-on-startup&gt;，中x的取值1，2，3，4，5代表的是优先级，而非启动延迟时间。</code></pre><h3 id="31-java中拦截器和过滤器"><a href="#31-java中拦截器和过滤器" class="headerlink" title="31.java中拦截器和过滤器"></a>31.java中拦截器和过滤器</h3><p><img src="/image/%E8%BF%87%E6%BB%A4%E5%99%A8%E5%92%8C%E6%8B%A6%E6%88%AA%E5%99%A8.png" alt="效果图预览">  </p><p> 过滤器可以简单的理解为“取你所想取”，过滤器关注的是web请求；拦截器可以简单的理解为“拒你所想拒”，拦截器关注的是方法调用，比如拦截敏感词汇。<br> 拦截器是基于java反射机制来实现的，而过滤器是基于函数回调来实现的。（有人说，拦截器是基于动态代理来实现的）<br> 拦截器不依赖servlet容器，过滤器依赖于servlet容器。<br> 拦截器只对Action起作用，过滤器可以对所有请求起作用。<br> 拦截器可以访问Action上下文和值栈中的对象，过滤器不能。<br> 在Action的生命周期中，拦截器可以多次调用，而过滤器只能在容器初始化时调用一次。</p><h3 id="32-synchronized与lock不同"><a href="#32-synchronized与lock不同" class="headerlink" title="32.synchronized与lock不同"></a>32.synchronized与lock不同</h3><pre><code>   synchronized是关键字，lock是接口   synchronized能自动释放锁，lock是接口不能   synchronized不知道有没有拿到锁，而lock可以   synchronized 能锁住方法和代码块，而lock只能锁住代码块   synchronized是非公平锁，而ReentrantLock可以控制。</code></pre><h3 id="33-java并发内存模型以及内存操作规则"><a href="#33-java并发内存模型以及内存操作规则" class="headerlink" title="33.java并发内存模型以及内存操作规则"></a>33.java并发内存模型以及内存操作规则</h3><pre><code>  lock(锁定)：作用于主内存，它把一个变量标记为一条线程独占状态；  unlock(解锁)：作用于主内存，它将一个处于锁定状态的变量释放出来，释放后的变量才能够被其他线程锁定；  read(读取)：作用于主内存，它把变量值从主内存传送到线程的工作内存中，以便随后的load动作使用；  load(载入)：作用于工作内存，它把read操作的值放入工作内存中的变量副本中；  use(使用)：作用于工作内存，它把工作内存中的值传递给执行引擎，每当虚拟机遇到一个需要使用这个变量的指令时候，将会执行这个动作；  assign(赋值)：作用于工作内存，它把从执行引擎获取的值赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的指令时候，执行该操作；  store(存储)：作用于工作内存，它把工作内存中的一个变量传送给主内存中，以备随后的write操作使用；  write(写入)：作用于主内存，它把store传送值放到主内存中的变量中。</code></pre><h3 id="34-二叉树的深度优先遍历和广度优先遍历"><a href="#34-二叉树的深度优先遍历和广度优先遍历" class="headerlink" title="34.二叉树的深度优先遍历和广度优先遍历"></a>34.二叉树的深度优先遍历和广度优先遍历</h3><pre><code>二叉树的深度优先遍历的非递归的通用做法是采用栈，广度优先遍历的非递归的通用做法是采用队列。先序遍历：对任一子树，先访问根，然后遍历其左子树，最后遍历其右子树。中序遍历：对任一子树，先遍历其左子树，然后访问根，最后遍历其右子树。后序遍历：对任一子树，先遍历其左子树，然后遍历其右子树，最后访问根。广度优先遍历：又叫层次遍历，从上往下对每一层依次访问，在每一层中，从左往右（也可以从右往左）访问结点，访问完一层就进入下一层，直到没有结点可以访问为止。</code></pre><h3 id="35-对象内存布局"><a href="#35-对象内存布局" class="headerlink" title="35.对象内存布局"></a>35.对象内存布局</h3><pre><code>我们都知道对象在堆里存放的，那么它的内部结构是怎样的呢，下面以64为操作系统来说明首先对象包含对象头，实例数据，对齐填充。对象头：包含mark word 和 Klass 指针 ，在64位下，mark word 占 8个字节，Klass占8个字节如果对象是数组类型还会有一块标志数组长度的数据是4个字节实例数据：对象中包含的实例变量，不包括静态变量，静态变量不属于对象对齐填充：对象的大小都必须是8的整数倍，如果前两者不是8的整数倍就会在这里填充字节，使对象达到8的整数倍</code></pre><h3 id="36-深拷贝和浅拷贝"><a href="#36-深拷贝和浅拷贝" class="headerlink" title="36.深拷贝和浅拷贝"></a>36.深拷贝和浅拷贝</h3><pre><code> 深拷贝实现方式：   序列化实现深拷贝，实现Serializable接口。 流式处理实现深拷贝：    Streams 的一个常见模式是将数据源中的所有元素收集到一个新的集合中</code></pre><h3 id="37-Java-有几种文件拷贝方式"><a href="#37-Java-有几种文件拷贝方式" class="headerlink" title="37.Java 有几种文件拷贝方式"></a>37.Java 有几种文件拷贝方式</h3><pre><code>第一种，使用java.io包下的库，使用FileInputStream读取，再使用FileOutputStream写出。第二种，利用java.nio包下的库，使用transferTo或transfFrom方法实现。第三种，Java 标准类库本身已经提供了 Files.copy 的实现。</code></pre><h3 id="38-HTTPS和HTTP"><a href="#38-HTTPS和HTTP" class="headerlink" title="38.HTTPS和HTTP"></a>38.HTTPS和HTTP</h3><pre><code>HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。</code></pre><p>　　HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。</p><pre><code>HTTPS和HTTP的区别主要如下：　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。　　2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。　　4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。</code></pre><h3 id="39-TCP连接"><a href="#39-TCP连接" class="headerlink" title="39.TCP连接"></a>39.TCP连接</h3><pre><code>    现在的终端设备（手机、PC）之所以能够使用网络的原因是因为在设备的底层实现了TCP/IP协议，可以使终端通过无线网络建立TCP连接。TCP协议可以对上层网络提供接口，使上层网络数据的传输建立在“无差别”的网络之上。    三次握手过程详解：    建立起一个TCP连接需要经过“三次握手”：        第一次握手：客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；        第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；        第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。</code></pre><h3 id="40-UDP"><a href="#40-UDP" class="headerlink" title="40.UDP"></a>40.UDP</h3><pre><code>UDP（User Datagram Protocol），用户数据包协议，是一个简单的面向数据报的通信协议，即对应用层交下来的报文，不合并，不拆分，只是在其上面加上首部后就交给了下面的网络层也就是说无论应用层交给UDP多长的报文，它统统发送，一次发送一个报文而对接收方，接到后直接去除首部，交给上面的应用层就完成任务特点如下：    UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务    传输途中出现丢包，UDP 也不负责重发    当包的到达顺序出现乱序时，UDP没有纠正的功能。    并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为</code></pre><h3 id="41-建立连接是三次握手，关闭连接确是四次挥手"><a href="#41-建立连接是三次握手，关闭连接确是四次挥手" class="headerlink" title="41.建立连接是三次握手，关闭连接确是四次挥手"></a>41.建立连接是三次握手，关闭连接确是四次挥手</h3><pre><code>建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次</code></pre><h3 id="42-五层网络协议体系"><a href="#42-五层网络协议体系" class="headerlink" title="42.五层网络协议体系"></a>42.五层网络协议体系</h3><p>  <img src="/image/%E4%BA%94%E5%B1%82%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE.png" alt="效果图预览"></p><pre><code>1. 应用层应用层（application-layer）的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等。我们把应用层交互的数据单元称为报文。2. 运输层运输层（transport layer）的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。3. 网络层在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP / IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报，简称数据报。4. 数据链路层数据链路层（data link layer）通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如：同步信息，地址信息，差错控制等）。在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。控制信息还使接收端能够检测到所收到的帧中有无差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。5. 物理层在物理层上所传送的数据单位是比特。物理层（physical layer）的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。</code></pre>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hello-world</title>
      <link href="/2016/11/23/hello-world/"/>
      <url>/2016/11/23/hello-world/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><hr><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> 通用 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 兴趣 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
